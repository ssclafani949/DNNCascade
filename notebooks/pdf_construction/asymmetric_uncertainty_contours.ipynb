{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#PDFs in BDT and sindec?\n",
    "import os\n",
    "\n",
    "# set env flags to catch BLAS used for scipy/numpy \n",
    "# to only use 1 cpu, n_cpus will be totally controlled by csky\n",
    "os.environ['MKL_NUM_THREADS'] = \"1\"\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = \"1\"\n",
    "os.environ['OMP_NUM_THREADS'] = \"1\"\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = \"1\"\n",
    "os.environ['VECLIB_MAXIMUM_THREADS'] = \"1\"\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.facecolor'] = 'w'\n",
    "mpl.rcParams['savefig.facecolor'] = 'w'\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors, cm\n",
    "import csky as cy\n",
    "from csky import cext\n",
    "import numpy as np\n",
    "import histlite as hl\n",
    "import healpy\n",
    "import pickle\n",
    "import socket\n",
    "healpy.disable_warnings()\n",
    "plt.rc('figure', facecolor = 'w')\n",
    "plt.rc('figure', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-overhead",
   "metadata": {},
   "source": [
    "## Define Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_version = 'version-001-p01'\n",
    "\n",
    "host_name = socket.gethostname()\n",
    "\n",
    "if 'cobalt' in host_name:\n",
    "    print('Working on Cobalts')\n",
    "    plot_dir = '/home/mhuennefeld/public_html/analyses/DNNCascade/plots/pdf_construction/asymmetric_uncertainty_contours'\n",
    "    \n",
    "else:\n",
    "    raise ValueError('Unknown host:', host_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir_path in [plot_dir]:\n",
    "    if not os.path.exists(dir_path):\n",
    "        print('Creating directory:', dir_path)\n",
    "        os.makedirs(dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-contact",
   "metadata": {},
   "source": [
    "## Define Toy MC\n",
    "\n",
    "We will create a toy MC simulation on a discrete 2D surface with coordinates x and y. \n",
    "Background will be evenly distributed on this surface.\n",
    "The events will have tunable uncertainties in x- and y-direction. \n",
    "For simplicity, these will be modelled by simple independent Gaussians.\n",
    "Essentially this allows us to tweak the uncertainty contours from symmetric circles to axis-aligned\n",
    "elongated ellipses.\n",
    "We will use this simulation to understand the importance of proper coverage as well as the impact\n",
    "of circularized vs proper elliptical uncertainty contours.\n",
    "In order to asses the performance in a quantitative way, we will compute the sensitivy \n",
    "(90% of trials with a test-statistic value above the median background test-statistic value) and the 3-sigma discovery potential (50% of trials with a test-statistic value above the test-statistic value corresponding to 3-sigma)\n",
    "for the various settings. \n",
    "The search itself will be performed in the binned 2D space by doing the following:\n",
    " 1. Convolve template with defined (estimated, i.e. not necessarily the true) uncertainty contours via a 2D convolution operation. The kernel will be the discretized Gaussian in x- and y-direction.\n",
    " 2. Maximize the PS likelihood: $L(n_s) = \\prod_i (\\frac{n_s}{N} \\cdot S_i(x_i, y_i) +  (1-\\frac{n_s}{N}) \\cdot B_i)$ with the signal PDF $S_i(x_i, y_i)$, defined by the convolved template and the background PDF $B_i = \\frac{1}{N_\\mathrm{bins}}$.\n",
    " 3. Compute test-statistic $\\tau = - 2 \\cdot \\ln \\frac{L(n_s=0)}{L(\\hat{n}_s)}$\n",
    "\n",
    "In the simulation we will be able to adjust:\n",
    " - Template that we are searching for\n",
    " - True uncertainty contours: $\\sigma_x$ and $\\sigma_y$\n",
    " - Estimated uncertainty contours: $\\hat{\\sigma}_x$ and $\\hat{\\sigma}_y$\n",
    " - Number of bins in x-y-plane\n",
    " - Background level\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-appraisal",
   "metadata": {},
   "source": [
    "#### Define simulation settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-sense",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "cfg_circularized = {\n",
    "    'bin_dims': (50, 40),\n",
    "    'n_background': 10000,\n",
    "    'cov_true': np.array([[0.02, 0.], [0., 0.08]]),  # true uncertainty contours\n",
    "    'cov_rec': np.array([[0.05, 0.], [0., 0.05]]),  # assumed uncertainty contours\n",
    "}\n",
    "cfg_perfect = deepcopy(cfg_circularized)\n",
    "cfg_perfect['cov_rec'] = cfg_perfect['cov_true']\n",
    "\n",
    "cfg_coverage = {\n",
    "    'bin_dims': (50, 40),\n",
    "    'n_background': 10000,\n",
    "    'cov_true': np.array([[0.05, 0.], [0., 0.05]]),  # true uncertainty contours\n",
    "    'cov_rec': np.array([[0.05, 0.], [0., 0.05]]),  # assumed uncertainty contours\n",
    "}\n",
    "\n",
    "cfg_dict = {\n",
    "    'Rec: circularized | True: elliptical': cfg_circularized,\n",
    "    'Rec: elliptical | True: elliptical': cfg_perfect,\n",
    "}\n",
    "\n",
    "\n",
    "# add configs for different coverages:\n",
    "if False:\n",
    "    for cov_factor in [0.1, 0.2, 0.5, 0.8, 1.0, 1.2, 2.0, 5., 10.]:\n",
    "        cfg_i = deepcopy(cfg_coverage)\n",
    "        cfg_i['cov_rec'] *= cov_factor\n",
    "        cfg_dict['Coverage x {:3.2f}'.format(cov_factor)] = cfg_i\n",
    "\n",
    "cfg_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-pearl",
   "metadata": {},
   "source": [
    "#### Define helper functions for simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-letters",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "\n",
    "def multivariate_gaussian(pos, mu, cov):\n",
    "    \"\"\"\n",
    "    Multivariate Gaussian distribution\n",
    "    \n",
    "    Computes the multivariate Gaussian in n-dimensional space.\n",
    "    Used variables:\n",
    "        N: number of samples/events\n",
    "        n: number of dimensions\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    pos: array_like\n",
    "        The positions in the n-dimensional space.\n",
    "        Shape: [N, n]\n",
    "    mu: array_like\n",
    "        The center of the n-d Gaussian.\n",
    "        Shape: [N, n]\n",
    "    cov: array_like\n",
    "        The covariance matrix.\n",
    "        Shape: [N, n, n]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    array_like\n",
    "        The n-dimensional Gaussian evaluated at pos.\n",
    "        Shape: [N] with the number of events N\n",
    "    \"\"\"\n",
    "    n = mu.shape[0]\n",
    "    cov_det = np.linalg.det(cov)\n",
    "    cov_inv = np.linalg.inv(cov)\n",
    "    N = np.sqrt((2*np.pi)**n * cov_det)\n",
    "\n",
    "    # This einsum call calculates (x-mu)T.cov-1.(x-mu) in a vectorized\n",
    "    # way across all the input variables.\n",
    "    fac = np.einsum('...k,...kl,...l->...', pos-mu, cov_inv, pos-mu)\n",
    "\n",
    "    return np.exp(-fac / 2) / N\n",
    "\n",
    "\n",
    "def get_coordinates(cfg):\n",
    "    x = np.linspace(-1, 1, cfg['bin_dims'][0])\n",
    "    y = np.linspace(-1, 1, cfg['bin_dims'][1])\n",
    "    \n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    # transpose: I like to use convention: first index into array is for x, second for y\n",
    "    X = X.T\n",
    "    Y = Y.T\n",
    "    X_flat = np.reshape(X, (-1))\n",
    "    Y_flat = np.reshape(Y, (-1))\n",
    "    \n",
    "    return X, Y, X_flat, Y_flat\n",
    "\n",
    "\n",
    "def idx_to_coordinates(x_idx, y_idx, cfg):\n",
    "    x_mids = np.linspace(-1, 1, cfg['bin_dims'][0])\n",
    "    y_mids = np.linspace(-1, 1, cfg['bin_dims'][1])\n",
    "    \n",
    "    x = x_mids[np.atleast_1d(x_idx)]\n",
    "    y = y_mids[np.atleast_1d(y_idx)]\n",
    "    return np.array((x, y)).T\n",
    "    \n",
    "def flat_idx_to_coordinates(flat_idx, cfg):\n",
    "    x_idx, y_idx = np.unravel_index(flat_idx, shape=cfg['bin_dims'])\n",
    "    return idx_to_coordinates(x_idx=x_idx, y_idx=y_idx, cfg=cfg)\n",
    "\n",
    "def coordinates_to_idx(x, y, cfg):\n",
    "    x_mids = np.linspace(-1, 1, cfg['bin_dims'][0])\n",
    "    y_mids = np.linspace(-1, 1, cfg['bin_dims'][1])\n",
    "    \n",
    "    x_diff = np.diff(x_mids)[0]\n",
    "    y_diff = np.diff(y_mids)[0]\n",
    "    x_edges = np.concatenate((\n",
    "        np.atleast_1d(-np.inf),\n",
    "        np.atleast_1d(x_mids[0] - x_diff * 0.5), \n",
    "        x_mids + x_diff * 0.5, \n",
    "        np.atleast_1d(np.inf),\n",
    "    ))\n",
    "    y_edges = np.concatenate((\n",
    "        np.atleast_1d(-np.inf),\n",
    "        np.atleast_1d(y_mids[0] - y_diff * 0.5), \n",
    "        y_mids + y_diff * 0.5, \n",
    "        np.atleast_1d(np.inf),\n",
    "    ))\n",
    "    x_idx = np.searchsorted(x_edges, x) - 2\n",
    "    y_idx = np.searchsorted(y_edges, y) - 2\n",
    "    \n",
    "    mask_inbound = np.logical_and(\n",
    "        x_idx >= 0,\n",
    "        x_idx < len(x_mids),\n",
    "    )\n",
    "    mask_inbound = np.logical_and(\n",
    "        mask_inbound,\n",
    "        y_idx >= 0,\n",
    "    )\n",
    "    mask_inbound = np.logical_and(\n",
    "        mask_inbound,\n",
    "        y_idx < len(y_mids),\n",
    "    )\n",
    "    \n",
    "    # compute flattened index\n",
    "    idx_flat = np.atleast_1d(np.zeros_like(x, dtype=int) - 1)\n",
    "    idx_flat[mask_inbound] = np.ravel_multi_index((x_idx[mask_inbound], y_idx[mask_inbound]), dims=cfg['bin_dims'])\n",
    "    \n",
    "    return x_idx, y_idx, idx_flat\n",
    "\n",
    "def get_template_from_gaussians(mu, cov, cfg):\n",
    "    \"\"\"Get template from multivariate Gaussian distributions\n",
    "    \n",
    "    Assumes x-y-plane is centered around 0 with extent -1 to 1\n",
    "    in x and y.\n",
    "    \n",
    "    Used variables:\n",
    "        N: number of samples/events\n",
    "        n: number of dimensions\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    mu: array_like\n",
    "        The center of the n-d Gaussian.\n",
    "        Shape: [N, n]\n",
    "    cov: array_like\n",
    "        The covariance matrix.\n",
    "        Shape: [N, n, n]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    array_like\n",
    "        The template PDF.\n",
    "        Shape: [bin_dims_x, bin_dims_y]\n",
    "    \"\"\"\n",
    "    X, Y, X_flat, Y_flat = get_coordinates(cfg)\n",
    "    \n",
    "    # Shape: [n_bins, 1, 2]\n",
    "    pos = np.empty((np.product(cfg['bin_dims']), 1, 2))\n",
    "    pos[:, 0, 0] = X_flat\n",
    "    pos[:, 0, 1] = Y_flat\n",
    "    \n",
    "    Z_flat = multivariate_gaussian(pos, mu=mu, cov=cov)\n",
    "    \n",
    "    # shape: [n_bins_x, n_bins_y, n_models]\n",
    "    Z = np.reshape(Z_flat, (*cfg['bin_dims'], len(mu)))\n",
    "    \n",
    "    # shape: [n_bins_x, n_bins_y]\n",
    "    Z = np.sum(Z, axis=-1)\n",
    "    \n",
    "    # now let's normalize the PDF over the bins\n",
    "    Z /= np.sum(Z)\n",
    "    \n",
    "    return Z\n",
    "\n",
    "\n",
    "def get_smeared_template(template, cov, cfg, normalize=True):\n",
    "    \n",
    "    # make sure cov has correct shape\n",
    "    # shape: [1, 2, 2]\n",
    "    cov = np.asarray(cov)\n",
    "    if len(cov.shape) == 2:\n",
    "        cov = cov[np.newaxis]\n",
    "    \n",
    "    # compute discretized gaussian kernel\n",
    "    unc_kernel = get_template_from_gaussians(\n",
    "        mu=np.array([[0, 0]]), \n",
    "        cov=cov, \n",
    "        cfg=cfg,\n",
    "    )\n",
    "    smeared_template = signal.convolve(template, unc_kernel, mode='same')\n",
    "    if normalize:\n",
    "        smeared_template[smeared_template < 0] = 0.\n",
    "        smeared_template /= np.sum(smeared_template)\n",
    "    return smeared_template\n",
    "\n",
    "\n",
    "def plot_template(\n",
    "            template, cfg, cb_label='Bin probability', \n",
    "            only_contours=False, plot_cbar=True, fig=None, \n",
    "            ax=None, \n",
    "            **kwargs\n",
    "        ):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    x = np.linspace(-1, 1, cfg['bin_dims'][0])\n",
    "    y = np.linspace(-1, 1, cfg['bin_dims'][1])\n",
    "    \n",
    "    if only_contours:\n",
    "        cf = ax.contour(x, y, np.transpose(template), **kwargs)\n",
    "    else:\n",
    "        cf = ax.contourf(x, y, np.transpose(template), **kwargs)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    \n",
    "    if plot_cbar:\n",
    "        cbar = fig.colorbar(cf)\n",
    "        cbar.ax.set_ylabel(cb_label)\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def plot_trial(template, cfg, **kwargs):\n",
    "    return plot_template(template=template, cfg=cfg, cb_label='Number of Events', **kwargs)\n",
    "\n",
    "\n",
    "def inject_events(cfg, n_sig, template, smearing='template', seed=None):\n",
    "    \n",
    "    if smearing not in ['template', 'event']:\n",
    "        raise ValueError(smearing)\n",
    "        \n",
    "    rng = np.random.RandomState(seed)\n",
    "    \n",
    "    assert template.shape == cfg['bin_dims'], (cfg['bin_dims'], template.shape)\n",
    "    \n",
    "    # get background\n",
    "    n_bins = np.product(cfg['bin_dims'])\n",
    "    n_bkg_per_bin = cfg['n_background'] / n_bins\n",
    "    bkg = rng.poisson(lam=n_bkg_per_bin, size=cfg['bin_dims'])\n",
    "    \n",
    "    # draw number of signal events\n",
    "    n_sig = rng.poisson(lam=n_sig)\n",
    "    \n",
    "    # sample locations according to template\n",
    "    if smearing == 'template':\n",
    "        # convolve template with true uncertainty\n",
    "        template_smeared = get_smeared_template(template, cov=cfg['cov_true'], cfg=cfg)\n",
    "        template = template_smeared\n",
    "    \n",
    "    template_flat = np.reshape(template, (-1))\n",
    "    sig_idx = rng.choice(np.arange(len(template_flat)), size=n_sig, p=template_flat, replace=True)\n",
    "    \n",
    "    # smear location of individual events according to true uncertainty\n",
    "    if smearing == 'event' and len(sig_idx) > 0:\n",
    "        \n",
    "        # True event locations\n",
    "        # Shape: [N_events, 2]\n",
    "        event_pos_true = flat_idx_to_coordinates(sig_idx, cfg)\n",
    "        \n",
    "        # smear locations\n",
    "        event_pos_reco = []\n",
    "        for pos in event_pos_true:\n",
    "            event_pos_reco.append(rng.multivariate_normal(mean=pos, cov=cfg['cov_true']))\n",
    "        event_pos_reco = np.array(event_pos_reco)\n",
    "        \n",
    "        # figure out which bin idx this belongs to\n",
    "        _, _, sig_idx_smeared = coordinates_to_idx(x=event_pos_reco[:, 0], y=event_pos_reco[:, 1], cfg=cfg)\n",
    "        \n",
    "        # only add those that are in bounds\n",
    "        sig_idx_smeared = sig_idx_smeared[sig_idx_smeared >= 0]\n",
    "        \n",
    "        # overwrite where to inject events\n",
    "        sig_idx = sig_idx_smeared\n",
    "        \n",
    "    sig_idx, sig_counts = np.unique(sig_idx, return_counts=True)\n",
    "    \n",
    "    sig_inj = np.zeros_like(bkg)\n",
    "    sig_inj_flat = np.reshape(sig_inj, (-1))\n",
    "    sig_inj_flat[sig_idx] += sig_counts\n",
    "    sig_inj = np.reshape(sig_inj_flat, cfg['bin_dims'])\n",
    "    \n",
    "    trial = bkg + sig_inj\n",
    "    \n",
    "    return trial, bkg, sig_inj\n",
    "\n",
    "# ---------------\n",
    "# Define Template\n",
    "# ---------------\n",
    "# calculate points of Gauss centers along function\n",
    "x = np.linspace(-0.5, 0.5, 100)\n",
    "y = 0.5*(x*2+1.5)**(-1) - .5\n",
    "mu = np.array([y, x]).T # flip x and y to be more elongated in y\n",
    "if False:\n",
    "    fix, ax = plt.subplots()\n",
    "    ax.plot(y, x)\n",
    "    ax.set_xlim(-1, 1)\n",
    "    ax.set_ylim(-1, 1)\n",
    "cov = np.diag([0.005, 0.005])[np.newaxis]\n",
    "print(cov.shape)\n",
    "template = get_template_from_gaussians(mu, cov, cfg=cfg_circularized)\n",
    "\n",
    "fig, ax = plot_template(template, cfg=cfg_circularized)\n",
    "ax.set_title('Template (Truth)')\n",
    "fig.savefig('{}/template.png'.format(plot_dir))\n",
    "\n",
    "# ---------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-dispatch",
   "metadata": {},
   "source": [
    "#### Plot smeared templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_smeared_true = get_smeared_template(\n",
    "    template, cov=cfg_circularized['cov_true'], cfg=cfg_circularized)\n",
    "template_smeared_rec = get_smeared_template(\n",
    "    template, cov=cfg_circularized['cov_rec'], cfg=cfg_circularized)\n",
    "\n",
    "fig, ax = plot_template(template_smeared_true, cfg=cfg_circularized)\n",
    "ax.set_title('Template Smeared (Truth)')\n",
    "fig.savefig('{}/template_smeared_true.png'.format(plot_dir))\n",
    "\n",
    "fig, ax = plot_template(template_smeared_rec, cfg=cfg_circularized)\n",
    "ax.set_title('Template Smeared (Reco)')\n",
    "fig.savefig('{}/template_smeared_rec.png'.format(plot_dir))\n",
    "\n",
    "# comparison\n",
    "levels = np.linspace(0, 0.006, 10)\n",
    "fig, ax = plot_template(template_smeared_rec, cfg=cfg_circularized, levels=levels)\n",
    "ax.set_title('Template Smeared (Comparison)')\n",
    "plot_template(template_smeared_true, cfg=cfg_circularized, only_contours=True, plot_cbar=False, fig=fig, ax=ax, levels=levels)\n",
    "fig.savefig('{}/template_rec_true_comparison.png'.format(plot_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "inject_events(cfg=cfg_circularized, n_sig=1000, template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-adelaide",
   "metadata": {},
   "source": [
    "#### Check if convolving template is equal to smearing individual events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-nebraska",
   "metadata": {},
   "outputs": [],
   "source": [
    "evts, bkg, sig = inject_events(cfg=cfg_circularized, n_sig=100000, smearing='event', template=template)\n",
    "\n",
    "smeared_template = get_smeared_template(template, cov=cfg_circularized['cov_true'], cfg=cfg_circularized)\n",
    "\n",
    "levels = np.linspace(0, 0.005, 10)\n",
    "fig, ax = plot_template(sig/np.sum(sig), cfg=cfg_circularized, levels=levels)\n",
    "plot_template(smeared_template, cfg=cfg_circularized, only_contours=True, plot_cbar=False, fig=fig, ax=ax, levels=levels)\n",
    "fig.savefig('{}/smearing_comparison.png'.format(plot_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-gross",
   "metadata": {},
   "source": [
    "## Define Likelihood and Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-emphasis",
   "metadata": {},
   "source": [
    "#### Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-dairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cycler import cycle\n",
    "from copy import deepcopy\n",
    "\n",
    "soft_colors = cy.plotting.soft_colors\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "def get_ls_cycler(ls_list=['-', '--', ':', '-.']):\n",
    "    return cycle(ls_list)\n",
    "\n",
    "def get_color_cycler(colors=colors):\n",
    "    return cycle(colors)\n",
    "\n",
    "def plot_ns_bias(ax, ntrue, ns, label=''):\n",
    "    \n",
    "    ntrue = np.reshape(ntrue, (-1))\n",
    "    ns = np.reshape(ns, (-1))\n",
    "    \n",
    "    n_sigs = np.unique(ntrue)\n",
    "    dns = np.mean(np.diff(n_sigs))\n",
    "    ns_bins = np.r_[n_sigs - 0.5*dns, n_sigs[-1] + 0.5*dns]\n",
    "    expect_kw = dict(color='C0', ls='--', lw=1, zorder=-10)\n",
    "\n",
    "    h = hl.hist((ntrue, ns), bins=(ns_bins, 100))\n",
    "    hl.plot1d(ax, h.contain_project(1),errorbands=True, \n",
    "              drawstyle='default', label=label)\n",
    "    lim = ns_bins[[0, -1]]\n",
    "    ax.set_xlim(ax.set_ylim(lim))\n",
    "    ax.plot(lim, lim, **expect_kw)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    ax.set_xlabel(r'$n_{inj}$')\n",
    "    ax.set_ylabel(r'$n_s$')\n",
    "    ax.grid()\n",
    "\n",
    "\n",
    "def plot_bkg_trials(\n",
    "            bg, fig=None, ax=None, \n",
    "            label='{} bg trials', \n",
    "            label_fit=r'$\\chi^2[{:.2f}\\mathrm{{dof}},\\ \\eta={:.3f}]$', \n",
    "            color=colors[0],\n",
    "            density=False,\n",
    "            bins=50,\n",
    "        ):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    \n",
    "    if density:\n",
    "        h = bg.get_hist(bins=bins).normalize()\n",
    "    else:\n",
    "        h = bg.get_hist(bins=bins)\n",
    "    if label is not None:\n",
    "        label = label.format(bg.n_total)\n",
    "    hl.plot1d(ax, h, crosses=True, color=color, label=label)\n",
    "\n",
    "    # compare with the chi2 fit:\n",
    "    if hasattr(bg, 'pdf'):\n",
    "        x = h.centers[0]\n",
    "        norm = h.integrate().values\n",
    "        if label_fit is not None:\n",
    "            label_fit = label_fit.format(bg.ndof, bg.eta)\n",
    "        if density:\n",
    "            ax.semilogy(x, bg.pdf(x), lw=1, ls='--', label=label_fit, color=color)\n",
    "        else:\n",
    "            ax.semilogy(x, norm * bg.pdf(x), lw=1, ls='--', label=label_fit, color=color)\n",
    "\n",
    "    ax.set_xlabel(r'TS')\n",
    "    if density:\n",
    "        ax.set_ylabel(r'Density')\n",
    "    else:\n",
    "        ax.set_ylabel(r'number of trials')\n",
    "    ax.legend()\n",
    "        \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-assembly",
   "metadata": {},
   "source": [
    "#### Minimizer and Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "def neg_log_likelihood(ns, evts, cfg, template):\n",
    "        \n",
    "    assert template.shape == cfg['bin_dims'], (cfg['bin_dims'], template.shape)\n",
    "    \n",
    "    n_events = float(np.sum(evts))\n",
    "    \n",
    "    # get background PDF\n",
    "    n_bins = np.product(cfg['bin_dims'])\n",
    "    pdf_bkg = 1./n_bins\n",
    "    \n",
    "    # convolve signal template with reconstructed uncertainty\n",
    "    template_smeared = get_smeared_template(template, cov=cfg['cov_rec'], cfg=cfg, normalize=True)\n",
    "    \n",
    "    # compute likelihood\n",
    "    sig_term = ns/n_events * template_smeared\n",
    "    bkg_term = (1 - ns/n_events) * pdf_bkg\n",
    "    eps = 1e-107\n",
    "    llh = np.log(sig_term + bkg_term + eps) * evts\n",
    "    mask = evts > 0\n",
    "    llh = np.sum(llh[mask])\n",
    "    \n",
    "    return -llh\n",
    "\n",
    "def fit_trial(evts, cfg, template):\n",
    "    \n",
    "    n_total = np.sum(evts)\n",
    "    \n",
    "    res = minimize(\n",
    "        fun=neg_log_likelihood,\n",
    "        x0=0.,\n",
    "        bounds=[(0., n_total)],\n",
    "        args=(evts, cfg, template),\n",
    "    )\n",
    "    return res.x\n",
    "\n",
    "def get_ts(evts, cfg, template):\n",
    "    ns = fit_trial(evts=evts, cfg=cfg, template=template)\n",
    "    neg_llh_fit = neg_log_likelihood(ns=ns, evts=evts, cfg=cfg, template=template) \n",
    "    neg_llh_h0 = neg_log_likelihood(ns=0, evts=evts, cfg=cfg, template=template) \n",
    "    ts = 2 * (neg_llh_h0 - neg_llh_fit)\n",
    "    return ts, ns\n",
    "\n",
    "def run_trial(n_sig, cfg, template, seed):\n",
    "    evts, bkg, sig = inject_events(cfg=cfg, n_sig=n_sig, template=template, seed=seed)\n",
    "    ts, ns = get_ts(evts=evts, cfg=cfg, template=template)\n",
    "    return ts, ns\n",
    "\n",
    "def _run_trial(args):\n",
    "    \"\"\"Wrapper for multiprocessing\"\"\"\n",
    "    n_sig, cfg, template, seed = args\n",
    "    return run_trial(n_sig=n_sig, cfg=cfg, template=template, seed=seed)\n",
    "\n",
    "def run_trials(n_trials, n_sig, cfg, template, seed, cpus=1, verbose=False):\n",
    "    ns_true = np.zeros(n_trials) + n_sig\n",
    "    ns = np.empty(n_trials)\n",
    "    ts = np.empty(n_trials)\n",
    "    seeds = np.arange(n_trials) + seed\n",
    "    \n",
    "    if cpus == 1:\n",
    "        for i in tqdm(range(n_trials), total=n_trials):\n",
    "            ts_i, ns_i = run_trial(n_sig=n_sig, cfg=cfg, template=template, seed=seeds[i])\n",
    "            ns[i] = ns_i\n",
    "            ts[i] = ts_i\n",
    "    else:\n",
    "        args = [(n_sig, cfg, template, seed) for seed in seeds]\n",
    "        with Pool(cpus) as p:\n",
    "            if verbose:\n",
    "                res = list(tqdm(p.imap(_run_trial, args), total=n_trials))\n",
    "            else:\n",
    "                res = p.map(_run_trial, args)\n",
    "        \n",
    "        res = np.array(res)\n",
    "        ts[:] = res[:, 0]\n",
    "        ns[:] = res[:, 1]\n",
    "            \n",
    "    return ts, ns, ns_true\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-supplier",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "described-anniversary",
   "metadata": {},
   "source": [
    "#### Check Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "cpus = 15\n",
    "n_points = 100\n",
    "n_trials = 100\n",
    "\n",
    "res_dict = {}\n",
    "\n",
    "for cfg_name, cfg_j in cfg_dict.items():\n",
    "    n_sig_vals = np.linspace(0, 300, n_points)\n",
    "    ntrue = np.empty((n_points, n_trials))\n",
    "    ntrue[:] = n_sig_vals[..., np.newaxis]\n",
    "    ns = np.empty((n_points, n_trials))\n",
    "    ts = np.empty((n_points, n_trials))\n",
    "\n",
    "    for i, n_sig in tqdm(enumerate(n_sig_vals), total=n_points):\n",
    "        ts_i, ns_i, ns_true = run_trials(n_trials=n_trials, n_sig=n_sig, cfg=cfg_j, template=template, seed=seed, cpus=cpus)\n",
    "        ns[i] = ns_i\n",
    "        ts[i] = ts_i\n",
    "            \n",
    "    res_dict[cfg_name] = (ts, ns, ntrue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "for cfg_name, (ts, ns, ntrue) in res_dict.items():\n",
    "    plot_ns_bias(ax=ax, ntrue=ntrue, ns=ns, label=cfg_name)\n",
    "ax.legend()\n",
    "fig.savefig('{}/ns_bias.png'.format(plot_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-support",
   "metadata": {},
   "source": [
    "#### Write Trial-Runner Wrapper to use existing csky Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrialRunner(cy.trial.TrialRunner):\n",
    "    \n",
    "    def __init__(self, cfg, template, mp_cpus=15):\n",
    "        self.cfg = cfg\n",
    "        self.template = template\n",
    "        self.mp_cpus = mp_cpus\n",
    "    \n",
    "    def get_many_fits(self, n_trials, n_sig=0, seed=0, cpus=None, verbose=False, **kwargs):\n",
    "        \n",
    "        if cpus is None:\n",
    "            cpus = self.mp_cpus\n",
    "            \n",
    "        ts, ns, ns_true = run_trials(\n",
    "            n_trials=n_trials, n_sig=n_sig, \n",
    "            cfg=self.cfg, template=self.template, \n",
    "            seed=seed, cpus=cpus, verbose=verbose,\n",
    "        )\n",
    "        \n",
    "        trials = cy.utils.Arrays(init={\n",
    "            'ts': ts,\n",
    "            'ns': ns,\n",
    "            'ns_true': ns_true,\n",
    "        })\n",
    "        return trials\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-steps",
   "metadata": {},
   "source": [
    "#### Run Background Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 100000\n",
    "\n",
    "bg_dict = {}\n",
    "for cfg_name, cfg in cfg_dict.items():\n",
    "    tr = TrialRunner(cfg=cfg, template=template)\n",
    "    trials = tr.get_many_fits(n_trials=n_trials, verbose=True)\n",
    "    bg_dict[cfg_name] = trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-kuwait",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "color_cycler = get_color_cycler()\n",
    "\n",
    "for cfg_name, bg_trials in bg_dict.items():\n",
    "    bg = cy.dists.TSD(values=bg_trials.ts)\n",
    "    color = next(color_cycler)\n",
    "    plot_bkg_trials(\n",
    "        bg, fig=fig, ax=ax, \n",
    "        color=color,\n",
    "        label='{} bg trials' + ' [{}]'.format(cfg_name),\n",
    "    )\n",
    "ax.set_yscale('log')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-pixel",
   "metadata": {},
   "source": [
    "#### Sensitivity and Discovery Potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-activation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sens_dict = {}\n",
    "\n",
    "for cfg_name, cfg in cfg_dict.items():\n",
    "    print('Computing sensitivity for {}'.format(cfg_name))\n",
    "    \n",
    "    bg = cy.dists.TSD(values=bg_dict[cfg_name].ts)\n",
    "    ts_median = bg.median()\n",
    "    print('  Median TS: {:3.3f}'.format(ts_median))\n",
    "    tr = TrialRunner(cfg=cfg, template=template)\n",
    "    res = tr.find_n_sig(ts=ts_median, beta=0.9, n_sig_step=5, first_batch_size=200, batch_size=2000, tol=0.03)\n",
    "    \n",
    "    sens_dict[cfg_name] = {\n",
    "        'n_sig': res['n_sig'],\n",
    "        'n_sig_error': res['n_sig_error'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_dict = {}\n",
    "\n",
    "for cfg_name, cfg in cfg_dict.items():\n",
    "    print('Computing 3-sigma discovery potential for {}'.format(cfg_name))\n",
    "    \n",
    "    bg = cy.dists.TSD(values=bg_dict[cfg_name].ts)\n",
    "    ts_3sigma = bg.isf_nsigma(3)\n",
    "    print('  3-sigma TS: {:3.3f}'.format(ts_3sigma))\n",
    "    tr = TrialRunner(cfg=cfg, template=template)\n",
    "    res = tr.find_n_sig(ts=ts_3sigma, beta=0.5, n_sig_step=10, batch_size=1000)\n",
    "    \n",
    "    disc_dict[cfg_name] = {\n",
    "        'n_sig': res['n_sig'],\n",
    "        'n_sig_error': res['n_sig_error'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-layer",
   "metadata": {},
   "source": [
    "#### Make plot for circularized comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-denver",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(ns_dict, label_suffix=''):\n",
    "    color_cycler = get_color_cycler()\n",
    "    \n",
    "    counter = 1\n",
    "    names = []\n",
    "    fig, ax = plt.subplots(figsize=(9, 6))\n",
    "    for cfg_name, cfg in ns_dict.items():\n",
    "        if 'Coverage x' in cfg_name: \n",
    "            continue\n",
    "\n",
    "        color = next(color_cycler)\n",
    "        \n",
    "        yerr = ns_dict[cfg_name]['n_sig_error'] * ns_dict[cfg_name]['n_sig']\n",
    "        ax.errorbar(\n",
    "            counter, ns_dict[cfg_name]['n_sig'], yerr=yerr, \n",
    "            marker='.', label=cfg_name + label_suffix, color=color,\n",
    "        )\n",
    "        counter += 1\n",
    "        names.append(cfg_name)\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_xlim(0.5, counter - 0.5)\n",
    "    ax.set_xlabel('Tested scenario')\n",
    "    ax.set_xticks(range(1, counter))\n",
    "    ax.set_ylabel('Signal events $n_\\mathrm{inj}$')\n",
    "    return fig, ax\n",
    "\n",
    "fig, ax = plot_performance(sens_dict, label_suffix=' [sensitivity]')\n",
    "fig.savefig('{}/sens_comparison_circularized.png'.format(plot_dir))\n",
    "fig, ax = plot_performance(disc_dict, label_suffix=r' [$3\\sigma$ disc.]')\n",
    "fig.savefig('{}/disc_comparison_circularized.png'.format(plot_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-suicide",
   "metadata": {},
   "source": [
    "#### Make plot for Coverage Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-shift",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(ns_dict, label_suffix=''):\n",
    "    color_cycler = get_color_cycler()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 6))\n",
    "    for cfg_name, cfg in ns_dict.items():\n",
    "        if 'Coverage x' not in cfg_name: \n",
    "            continue\n",
    "\n",
    "        color = next(color_cycler)\n",
    "        cov_factor = float(cfg_name.split(' ')[-1])\n",
    "        \n",
    "        yerr = ns_dict[cfg_name]['n_sig_error'] * ns_dict[cfg_name]['n_sig']\n",
    "        ax.errorbar(\n",
    "            cov_factor, ns_dict[cfg_name]['n_sig'], yerr=yerr, \n",
    "            marker='.', label=cfg_name + label_suffix, color=color,\n",
    "        )\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Coverage factor')\n",
    "    ax.set_ylabel('Signal events $n_\\mathrm{inj}$')\n",
    "    return fig, ax\n",
    "\n",
    "fig, ax = plot_performance(sens_dict, label_suffix=' [sensitivity]')\n",
    "fig.savefig('{}/sens_comparison_coverage.png'.format(plot_dir))\n",
    "fig, ax = plot_performance(disc_dict, label_suffix=r' [$3\\sigma$ disc.]')\n",
    "fig.savefig('{}/disc_comparison_coverage.png'.format(plot_dir))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-orleans",
   "metadata": {},
   "source": [
    "Plots for:\n",
    " - under- and over-coverage vs perfect coverage (on circularized) [Effect of Coverage]\n",
    " - circularized on elliptical, elliptical on elliptical [Effect of Asymmetric Contours]\n",
    " - injection smearing type: \"event\" vs \"template\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-venice",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2.3_py3-v4.1.0_csky",
   "language": "python",
   "name": "tensorflow2.3_py3-v4.1.0_csky"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

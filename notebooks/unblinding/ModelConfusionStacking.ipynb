{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: AstropyDeprecationWarning: The disable_warnings function is deprecated and may be removed in a future version. [warnings]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#PDFs in BDT and sindec?\n",
    "import os\n",
    "\n",
    "# set env flags to catch BLAS used for scipy/numpy \n",
    "# to only use 1 cpu, n_cpus will be totally controlled by csky\n",
    "if False:\n",
    "    os.environ['MKL_NUM_THREADS'] = \"1\"\n",
    "    os.environ['NUMEXPR_NUM_THREADS'] = \"1\"\n",
    "    os.environ['OMP_NUM_THREADS'] = \"1\"\n",
    "    os.environ['OPENBLAS_NUM_THREADS'] = \"1\"\n",
    "    os.environ['VECLIB_MAXIMUM_THREADS'] = \"1\"\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.facecolor'] = 'w'\n",
    "mpl.rcParams['savefig.facecolor'] = 'w'\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors, cm\n",
    "import csky as cy\n",
    "from csky import cext\n",
    "import numpy as np\n",
    "import astropy\n",
    "#from icecube import astro\n",
    "import histlite as hl\n",
    "import healpy\n",
    "import healpy as hp\n",
    "import socket\n",
    "import pickle\n",
    "import copy\n",
    "healpy.disable_warnings()\n",
    "plt.rc('figure', facecolor = 'w')\n",
    "plt.rc('figure', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Cobalts\n"
     ]
    }
   ],
   "source": [
    "selection_version = 'version-001-p00'\n",
    "\n",
    "host_name = socket.gethostname()\n",
    "\n",
    "if 'cobalt' in host_name:\n",
    "    print('Working on Cobalts')\n",
    "    data_prefix = '/data/user/ssclafani/data/cscd/final'\n",
    "    ana_dir = '/data/user/ssclafani/data/analyses/'\n",
    "    plot_dir = '/data/user/mhuennefeld/data/analyses/DNNCascadeCodeReview/unblinding_checks/plots/unblinding/model_confusion_stacking'\n",
    "    \n",
    "else:\n",
    "    raise ValueError('Unknown host:', host_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir_path in [plot_dir]:\n",
    "    if not os.path.exists(dir_path):\n",
    "        print('Creating directory:', dir_path)\n",
    "        os.makedirs(dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = cy.selections.Repository()\n",
    "specs = cy.selections.DNNCascadeDataSpecs.DNNC_10yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Analysis for:\n",
      "DNNCascade_10yr\n",
      "Setting up DNNCascade_10yr...\n",
      "Reading /data/ana/analyses/dnn_cascades/version-001-p00/MC_NuGen_bfrv1_2153x.npy ...\n",
      "Reading /data/ana/analyses/dnn_cascades/version-001-p00/IC86_2011_exp.npy ...\n",
      "Reading /data/ana/analyses/dnn_cascades/version-001-p00/IC86_2012_exp.npy ...\n",
      "Reading /data/ana/analyses/dnn_cascades/version-001-p00/IC86_2013_exp.npy ...\n",
      "Reading /data/ana/analyses/dnn_cascades/version-001-p00/IC86_2014_exp.npy ...\n",
      "Reading /data/ana/analyses/dnn_cascades/version-001-p00/IC86_2015_exp.npy ...\n",
      "Reading /data/ana/analyses/dnn_cascades/version-001-p00/IC86_2016_exp.npy ...\n",
      "Reading /data/ana/analyses/dnn_cascades/version-001-p00/IC86_2017_exp.npy ...\n",
      "Reading /data/ana/analyses/dnn_cascades/version-001-p00/IC86_2018_exp.npy ...\n",
      "Reading /data/ana/analyses/dnn_cascades/version-001-p00/IC86_2019_exp.npy ...\n",
      "Reading /data/ana/analyses/dnn_cascades/version-001-p00/IC86_2020_exp.npy ...\n",
      "Reading /data/ana/analyses/dnn_cascades/version-001-p00/GRL/IC86_2011_exp.npy ...\n",
      "Reading /data/ana/analyses/dnn_cascades/version-001-p00/GRL/IC86_2012_exp.npy ...\n",
      "Reading /data/ana/analyses/dnn_cascades/version-001-p00/GRL/IC86_2013_exp.npy ...\n",
      "Reading /data/ana/analyses/dnn_cascades/version-001-p00/GRL/IC86_2014_exp.npy ...\n",
      "Reading /data/ana/analyses/dnn_cascades/version-001-p00/GRL/IC86_2015_exp.npy ...\n",
      "Reading /data/ana/analyses/dnn_cascades/version-001-p00/GRL/IC86_2016_exp.npy ...\n",
      "Reading /data/ana/analyses/dnn_cascades/version-001-p00/GRL/IC86_2017_exp.npy ...\n",
      "Reading /data/ana/analyses/dnn_cascades/version-001-p00/GRL/IC86_2018_exp.npy ...\n",
      "Reading /data/ana/analyses/dnn_cascades/version-001-p00/GRL/IC86_2019_exp.npy ...\n",
      "Reading /data/ana/analyses/dnn_cascades/version-001-p00/GRL/IC86_2020_exp.npy ...\n",
      "Energy PDF Ratio Model...\n",
      "  * gamma = 4.0000 ...\n",
      "Signal Acceptance Model...\n",
      "  * gamma = 4.0000 ...\n",
      "Done.\n",
      "CPU times: user 7.72 s, sys: 304 ms, total: 8.02 s\n",
      "Wall time: 8.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ana = cy.get_analysis(\n",
    "    repo, selection_version, specs, \n",
    "    #gammas=np.r_[0.1:6.01:0.125],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Events(398873 items | columns: azimuth, dec, energy, event, log10energy, mjd, ra, run, sigma, sindec, subevent, xdec, xra, true_dec, true_energy, true_ra, oneweight)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ana.anas[0]\n",
    "a.sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Events(59610 items | columns: azimuth, dec, energy, event, log10energy, mjd, ra, run, sigma, sindec, subevent)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.bg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cycler import cycle\n",
    "from copy import deepcopy\n",
    "\n",
    "soft_colors = cy.plotting.soft_colors\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "\n",
    "def get_bias_allt(tr, ntrials=200, n_sigs=np.r_[:101:10], quiet=False, poisson=False):\n",
    "    trials = [\n",
    "        (None if quiet else print(f'\\r{n_sig:4d} ...', end='', flush=True))\n",
    "        or\n",
    "        tr.get_many_fits(ntrials, n_sig=n_sig, logging=False, seed=n_sig, poisson=poisson)\n",
    "        for n_sig in n_sigs]\n",
    "    if not quiet:\n",
    "        print()\n",
    "    for (n_sig, t) in zip(n_sigs, trials):\n",
    "        t['ntrue'] = np.repeat(n_sig, len(t))\n",
    "    allt = cy.utils.Arrays.concatenate(trials)\n",
    "    return allt\n",
    "\n",
    "def get_color_cycler():\n",
    "    return cycle(colors)\n",
    "\n",
    "def plot_ns_bias(ax, tr, allt, label=''):\n",
    "\n",
    "    n_sigs = np.unique(allt.ntrue)\n",
    "    dns = np.mean(np.diff(n_sigs))\n",
    "    ns_bins = np.r_[n_sigs - 0.5*dns, n_sigs[-1] + 0.5*dns]\n",
    "    expect_kw = dict(color='C0', ls='--', lw=1, zorder=-10)\n",
    "\n",
    "    h = hl.hist((allt.ntrue, allt.ns), bins=(ns_bins, 100))\n",
    "    hl.plot1d(ax, h.contain_project(1),errorbands=True, \n",
    "              drawstyle='default', label=label)\n",
    "    lim = ns_bins[[0, -1]]\n",
    "    ax.set_xlim(ax.set_ylim(lim))\n",
    "    ax.plot(lim, lim, **expect_kw)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    ax.set_xlabel(r'$n_{inj}$')\n",
    "    ax.set_ylabel(r'$n_s$')\n",
    "    ax.grid()\n",
    "\n",
    "def plot_gamma_bias(ax, tr, allt, label=''):\n",
    "\n",
    "    n_sigs = np.unique(allt.ntrue)\n",
    "    dns = np.mean(np.diff(n_sigs))\n",
    "    ns_bins = np.r_[n_sigs - 0.5*dns, n_sigs[-1] + 0.5*dns]\n",
    "    expect_kw = dict(color='C0', ls='--', lw=1, zorder=-10)\n",
    "    expect_gamma = tr.sig_injs[0].flux[0].gamma\n",
    "\n",
    "    h = hl.hist((allt.ntrue, allt.gamma), bins=(ns_bins, 100))\n",
    "    hl.plot1d(ax, h.contain_project(1),errorbands=True, \n",
    "              drawstyle='default', label=label)\n",
    "    lim = ns_bins[[0, -1]]\n",
    "    ax.set_xlim(lim)\n",
    "    ax.set_ylim(1, 4)\n",
    "    ax.axhline(expect_gamma, **expect_kw)\n",
    "\n",
    "    ax.set_xlabel(r'$n_{inj}$')\n",
    "    ax.set_ylabel(r'$\\gamma$')\n",
    "    ax.grid()\n",
    "\n",
    "def plot_bkg_trials(\n",
    "            bg, fig=None, ax=None, \n",
    "            label='{} bg trials', \n",
    "            label_fit=r'$\\chi^2[{:.2f}\\mathrm{{dof}},\\ \\eta={:.3f}]$', \n",
    "            color=colors[0],\n",
    "            density=False,\n",
    "            bins=50,\n",
    "        ):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    \n",
    "    if density:\n",
    "        h = bg.get_hist(bins=bins).normalize()\n",
    "    else:\n",
    "        h = bg.get_hist(bins=bins)\n",
    "    if label is not None:\n",
    "        label = label.format(bg.n_total)\n",
    "    hl.plot1d(ax, h, crosses=True, color=color, label=label)\n",
    "\n",
    "    # compare with the chi2 fit:\n",
    "    if hasattr(bg, 'pdf'):\n",
    "        x = h.centers[0]\n",
    "        norm = h.integrate().values\n",
    "        if label_fit is not None:\n",
    "            label_fit = label_fit.format(bg.ndof, bg.eta)\n",
    "        if density:\n",
    "            ax.semilogy(x, bg.pdf(x), lw=1, ls='--', label=label_fit, color=color)\n",
    "        else:\n",
    "            ax.semilogy(x, norm * bg.pdf(x), lw=1, ls='--', label=label_fit, color=color)\n",
    "\n",
    "    ax.set_xlabel(r'TS')\n",
    "    if density:\n",
    "        ax.set_ylabel(r'Density')\n",
    "    else:\n",
    "        ax.set_ylabel(r'number of trials')\n",
    "    ax.legend()\n",
    "        \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running as User: ssclafani on Hostname: cobalt07.icecube.wisc.edu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "import config as cg\n",
    "\n",
    "cg.base_dir = '/data/user/mhuennefeld/data/analyses/unblinding_v1.0.0/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gp_tr(template_str, cutoff=np.inf, gamma=None, cpus=20):\n",
    "    cutoff_GeV = cutoff * 1e3\n",
    "    gp_conf = cg.get_gp_conf(\n",
    "        template_str=template_str, gamma=gamma, cutoff_GeV=cutoff_GeV, base_dir=cg.base_dir)\n",
    "    tr = cy.get_trial_runner(gp_conf, ana=ana, mp_cpus=cpus)\n",
    "    return tr\n",
    "\n",
    "def get_catalog_tr(catalog, cutoff=np.inf, gamma=2.0, cpus=20):\n",
    "    catalog_file = os.path.join(\n",
    "        cg.catalog_dir, '{}_ESTES_12.pickle'.format(catalog))\n",
    "    cat = np.load(catalog_file, allow_pickle=True)\n",
    "    src = cy.utils.Sources(dec=cat['dec_deg'], ra=cat['ra_deg'], deg=True)\n",
    "    cutoff_GeV = cutoff * 1e3\n",
    "\n",
    "    conf = cg.get_ps_conf(src=src, gamma=gamma, cutoff_GeV=cutoff_GeV)\n",
    "    tr = cy.get_trial_runner(ana=ana, conf=conf, mp_cpus=cpus)\n",
    "    return tr\n",
    "\n",
    "def get_combined_catalog_tr(cutoff=np.inf, gamma=2.0, cpus=20):\n",
    "    dec_degs = []\n",
    "    ra_degs = []\n",
    "    for catalog in ['snr', 'pwn', 'unid']:\n",
    "        catalog_file = os.path.join(\n",
    "            cg.catalog_dir, '{}_ESTES_12.pickle'.format(catalog))\n",
    "        cat = np.load(catalog_file, allow_pickle=True)\n",
    "        dec_degs.append(cat['dec_deg'])\n",
    "        ra_degs.append(cat['ra_deg'])\n",
    "        \n",
    "    dec_degs = np.concatenate(dec_degs)\n",
    "    ra_degs = np.concatenate(ra_degs)\n",
    "    \n",
    "    src = cy.utils.Sources(dec=dec_degs, ra=ra_degs, deg=True)\n",
    "    cutoff_GeV = cutoff * 1e3\n",
    "\n",
    "    conf = cg.get_ps_conf(src=src, gamma=gamma, cutoff_GeV=cutoff_GeV)\n",
    "    tr = cy.get_trial_runner(ana=ana, conf=conf, mp_cpus=cpus)\n",
    "    return tr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get TrialRunners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /data/ana/analyses/NuSources/2021_DNNCascade_analyses/templates/Fermi_Bubbles_simple_map.npy ...\n",
      "<- /data/user/mhuennefeld/data/analyses/unblinding_v1.0.0//templates/fermibubbles/gamma/2.000/cutoff_GeV/50000/DNNCascade_10yr.template.npy    \n",
      "Restore successful.\n",
      "Reading /data/ana/analyses/NuSources/2021_DNNCascade_analyses/templates/Fermi-LAT_pi0_map.npy ...\n",
      "<- /data/user/mhuennefeld/data/analyses/unblinding_v1.0.0//templates/pi0/gamma/2.700/DNNCascade_10yr.template.npy    \n",
      "Restore successful.\n",
      "Reading /data/ana/analyses/NuSources/2021_DNNCascade_analyses/templates/KRA-gamma_5PeV_maps_energies.tuple.npy ...\n",
      "<- /data/user/mhuennefeld/data/analyses/unblinding_v1.0.0//templates/kra5/DNNCascade_10yr.template.npy    \n",
      "Restore successful.\n",
      "Reading /data/ana/analyses/NuSources/2021_DNNCascade_analyses/templates/KRA-gamma_maps_energies.tuple.npy ...\n",
      "<- /data/user/mhuennefeld/data/analyses/unblinding_v1.0.0//templates/kra50/DNNCascade_10yr.template.npy    \n",
      "Restore successful.\n"
     ]
    }
   ],
   "source": [
    "inj_tr_dict = {\n",
    "    'fermibubbles_50TeV': get_gp_tr('fermibubbles', cutoff=50),\n",
    "    'pi0': get_gp_tr('pi0'),\n",
    "    'kra5': get_gp_tr('kra5'),\n",
    "    'kra50': get_gp_tr('kra50'),\n",
    "    'snr': get_catalog_tr('snr', gamma=2.75126839),\n",
    "    'pwn': get_catalog_tr('pwn', gamma=2.99820651),\n",
    "    'unid': get_catalog_tr('unid', gamma=2.84580387),\n",
    "    'combined_stacking': get_combined_catalog_tr(gamma=2.86),\n",
    "}\n",
    "\n",
    "tr_dict = inj_tr_dict"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
   "id": "center-anime",
   "metadata": {},
   "source": [
    "#### Get Results for each template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = {}\n",
    "for key in tr_dict.keys():\n",
    "    if key in ['pi0', 'kra5', 'kra50']:\n",
    "        f_path = os.path.join(\n",
    "            cg.base_dir, \n",
    "            'gp/results/{}/{}_unblinded.npy'.format(key, key), \n",
    "        )\n",
    "        res_dict[key] = np.load(f_path)\n",
    "    elif key in ['fermibubbles_50TeV']:\n",
    "        f_path = os.path.join(\n",
    "            cg.base_dir, 'gp/results/fermibubbles/fermibubbles_unblinded.npy', \n",
    "        )\n",
    "        total_trials = np.load(f_path)\n",
    "        \n",
    "        cutoffs = [50, 100, 500, np.inf]\n",
    "        cutoff = float(key.replace('fermibubbles_', '').replace('TeV', ''))\n",
    "        res_dict[key] = total_trials[np.searchsorted(cutoffs, cutoff)]\n",
    "        \n",
    "    elif key in ['snr', 'pwn', 'unid']:\n",
    "        f_path = os.path.join(\n",
    "            cg.base_dir, \n",
    "            'stacking/results/{}/{}_unblinded.npy'.format(key, key), \n",
    "        )\n",
    "        res_dict[key] = np.load(f_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-nebraska",
   "metadata": {},
   "source": [
    "#### Define number of ns to inject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-assurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_dict = {\n",
    "    'pi0': 748.11,\n",
    "    'kra5': 273.24,\n",
    "    'kra50': 208.95,\n",
    "    'snr': 218.45,\n",
    "    'pwn': 279.61,\n",
    "    'unid': 237.90,\n",
    "    'combined_stacking': 735., # 735 if results were independent\n",
    "    'fermibubbles_50TeV': 95.69,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-adobe",
   "metadata": {},
   "source": [
    "#### Print Best Fit Fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, tr in tr_dict.items():\n",
    "    if key in res_dict:\n",
    "        ns = res_dict[key][1]\n",
    "    else:\n",
    "        ns = ns_dict[key]\n",
    "        print('No result found. Assuming ns of: {:3.1f}'.format(ns))\n",
    "        \n",
    "    dNdE = tr_dict[key].to_dNdE(ns=ns, E0=1e5)\n",
    "    E2dNdE = tr_dict[key].to_E2dNdE(ns=ns, E0=100, unit=1e3)\n",
    "    if not isinstance(E2dNdE, float):\n",
    "        E2dNdE = E2dNdE[0]\n",
    "    print('E2dNdE at 100 TeV in units of Tev {:3.3e} | {}'.format(E2dNdE, key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-seventh",
=======
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "#### Get bkg fits for each template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading background trials for template fermibubbles_50TeV\n",
      "fermibubbles_50TeV cutoff 50.0\n",
      "Loading background trials for template pi0\n"
     ]
    }
   ],
   "source": [
    "bkg_file_dict = {\n",
    "    'fermibubbles_50TeV': '{}/gp/trials/{}/{}/trials.dict'.format(cg.base_dir, 'DNNC', 'fermibubbles'),\n",
    "    'pi0': '{}/gp/trials/{}/{}/trials.dict'.format(cg.base_dir, 'DNNC', 'pi0'),\n",
    "    'kra5': '{}/gp/trials/{}/{}/trials.dict'.format(cg.base_dir, 'DNNC', 'kra5'),\n",
    "    'kra50': '{}/gp/trials/{}/{}/trials.dict'.format(cg.base_dir, 'DNNC', 'kra50'),\n",
    "    'snr': '{}/stacking/{}_bg.dict'.format(cg.base_dir, 'snr'),\n",
    "    'pwn': '{}/stacking/{}_bg.dict'.format(cg.base_dir, 'pwn'),\n",
    "    'unid': '{}/stacking/{}_bg.dict'.format(cg.base_dir, 'unid'),\n",
    "    'combined_stacking': os.path.join(plot_dir, 'trials_combined_stacking.pkl'),\n",
    "}\n",
    "n_bkg_trials = 20000\n",
    "seed = 1337\n",
    "\n",
    "bkg_dict = {}\n",
    "for key, tr in tr_dict.items():\n",
    "    if key in bkg_file_dict and os.path.exists(bkg_file_dict[key]):\n",
    "        print('Loading background trials for template {}'.format(key))\n",
    "        sig = np.load(bkg_file_dict[key], allow_pickle=True)\n",
    "        if key in ['pi0', 'kra5', 'kra50']:\n",
    "            bkg_dict[key] = sig['poisson']['nsig'][0.0]['ts']\n",
    "        elif key in ['fermibubbles_50TeV']:\n",
    "            cutoff = float(key.replace('fermibubbles_', '').replace('TeV', ''))\n",
    "            print(key, 'cutoff', cutoff)\n",
    "            bkg_dict[key] = sig['poisson']['cutoff'][cutoff]['nsig'][0.0]['ts']\n",
    "        else:\n",
    "            bkg_dict[key] = sig.ts\n",
    "    \n",
    "    else:\n",
    "        print('Running background trials for template {}'.format(key))\n",
    "        tirals = tr.get_many_fits(\n",
    "            n_trials=n_bkg_trials, seed=seed, mp_cpus=20)\n",
    "        \n",
    "        bkg_dict[key] = trials.ts\n",
    "        \n",
    "        out_file = os.path.join(plot_dir, 'trials_{}.pkl'.format(key))\n",
    "        with open(out_file, 'wb') as f:\n",
    "            pickle.dump(tirals, f, protocol=2)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
   "id": "short-closing",
=======
   "metadata": {},
   "source": [
    "#### Get Results for each template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = {}\n",
    "for key in tr_dict.keys():\n",
    "    if key in ['pi0', 'kra5', 'kra50']:\n",
    "        f_path = os.path.join(\n",
    "            cg.base_dir, \n",
    "            'gp/results/{}/{}_unblinded.npy'.format(key, key), \n",
    "        )\n",
    "        res_dict[key] = np.load(f_path)\n",
    "    elif key in ['fermibubbles_50TeV']:\n",
    "        f_path = os.path.join(\n",
    "            cg.base_dir, 'gp/results/fermibubbles/fermibubbles_unblinded.npy', \n",
    "        )\n",
    "        total_trials = np.load(f_path)\n",
    "        \n",
    "        cutoffs = [50, 100, 500, np.inf]\n",
    "        cutoff = float(key.replace('fermibubbles_', '').replace('TeV', ''))\n",
    "        res_dict[key] = total_trials[np.searchsorted(cutoffs, cutoff)]\n",
    "        \n",
    "    elif key in ['snr', 'pwn', 'unid']:\n",
    "        f_path = os.path.join(\n",
    "            cg.base_dir, \n",
    "            'stacking/results/{}/{}_unblinded.npy'.format(key, key), \n",
    "        )\n",
    "        res_dict[key] = np.load(f_path)"
   ]
  },
  {
   "cell_type": "markdown",
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "#### Plot ts distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key, bg in bkg_dict.items():\n",
    "    bg_tsd = cy.dists.TSD(bg)\n",
    "    fig, ax = plot_bkg_trials(bg_tsd)\n",
    "    if key in res_dict:\n",
    "        ts = res_dict[key][0]\n",
    "        ns = res_dict[key][1]\n",
    "        ax.axvline(\n",
    "            ts, color='0.8', ls='--', lw=2,\n",
    "            label='TS: {:3.3f} | ns: {:3.1f}'.format(ts, ns), \n",
    "        )\n",
    "    ts_5sig = bg_tsd.isf_nsigma(5)\n",
    "    ax.axvline(\n",
    "        ts_5sig, ls='--', lw=1,\n",
    "        label='5-sigma TS: {:3.3f}'.format(ts_5sig), \n",
    "    )\n",
    "    ax.set_title('Analysis: {}'.format(key))\n",
    "    ax.set_yscale('log')\n",
    "    ax.legend()\n",
    "    fig.savefig('{}/ts_dist_{}.png'.format(plot_dir, key))"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
   "id": "modified-pizza",
=======
   "metadata": {},
   "source": [
    "#### Define number of ns to inject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_dict = {\n",
    "    'pi0': 748.11,\n",
    "    'kra5': 273.24,\n",
    "    'kra50': 208.95,\n",
    "    'snr': 218.45,\n",
    "    'pwn': 279.61,\n",
    "    'unid': 237.90,\n",
    "    'combined_stacking': 735., # 735 if results were independent\n",
    "    'fermibubbles_50TeV': 95.69,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "#### Get trials for each template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "n_trials = 500\n",
    "seed = 42\n",
    "trials_dict = {}\n",
    "\n",
    "for key, tr in inj_tr_dict.items():\n",
    "    \n",
    "    n_sig = ns_dict[key]\n",
    "    trials = []\n",
    "    \n",
    "    print('Injecting {} signal events for template {}'.format(n_sig, key))\n",
    "    for i in tqdm(range(n_trials), total=n_trials):\n",
    "        trials.append(tr.get_one_trial(n_sig=n_sig, poisson=True, seed=seed + i))\n",
    "    \n",
    "    trials_dict[key] = trials\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get fits for each template combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "n_cpus = 25\n",
    "\n",
    "ts_dict = {}\n",
    "for key_inj, tr_inj in inj_tr_dict.items():\n",
    "    \n",
    "    for key, tr in tr_dict.items():\n",
    "        print('Computing TS values for injection {} and testing with {}'.format(key_inj, key))\n",
    "\n",
    "        ts_values = []\n",
    "        n_values = len(trials_dict[key_inj])\n",
    "        \n",
    "        if n_cpus > 1:\n",
    "            print('Running pool with {} cpus'.format(n_cpus))\n",
    "            def compute_trial(i):\n",
    "                return tr.get_one_fit_from_trial(trials_dict[key_inj][i])\n",
    "            \n",
    "            with Pool(n_cpus) as p:\n",
    "                ts_values_i = list(tqdm(p.imap(compute_trial, range(len(trials_dict[key_inj]))), total=n_values))\n",
    "            ts_values.extend(ts_values_i)\n",
    "            p.close()\n",
    "        else:\n",
    "            for trial in tqdm(trials_dict[key_inj], total=n_values):\n",
    "                ts_values.append(tr.get_one_fit_from_trial(trial)) \n",
    "        \n",
    "        ts_values = np.array(ts_values)\n",
    "        ts_dict[(key_inj, key)] = cy.utils.Arrays({\n",
    "          'ts': ts_values[:, 0],  \n",
    "          'ns': ts_values[:, 1],  \n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val_dict = {}\n",
    "sigma_dict = {}\n",
    "bkg_dist_dict = {}\n",
    "for key, ts_values in tqdm(ts_dict.items(), total=len(ts_dict)):\n",
    "    if len(bkg_dict[key[1]]) < 30000:\n",
    "        if key[1] in bkg_dist_dict:\n",
    "            bg = bkg_dist_dict[key[1]]\n",
    "        else:\n",
    "            bg = cy.dists.Chi2TSD(bkg_dict[key[1]])\n",
    "            bkg_dist_dict[key[1]] = bg\n",
    "    else:\n",
    "        bg = cy.dists.TSD(bkg_dict[key[1]])\n",
    "    max_bg_ts = np.max(bg.values)\n",
    "    mask_above = ts_values.ts > max_bg_ts\n",
    "    ts = np.array(ts_values.ts)\n",
    "    if np.sum(mask_above) > 0:\n",
    "        print('Setting {} ts values to max bkg ts value of {}.'.format(\n",
    "            np.sum(mask_above), max_bg_ts))\n",
    "        ts[mask_above] = max_bg_ts\n",
    "    p_val_dict[key] = bg.sf(ts)\n",
    "    sigma_dict[key] = bg.sf_nsigma(ts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_file = os.path.join(plot_dir, 'trials_and_fits.pkl')\n",
    "\n",
    "if False:\n",
    "    print('Writing results to file')\n",
    "    with open(res_file, 'wb') as f:\n",
    "        results = {\n",
    "            'p_val_dict': p_val_dict,\n",
    "            'sigma_dict': sigma_dict,\n",
    "            'ts_dict': ts_dict,\n",
    "            #'trials_dict': trials_dict,\n",
    "            #'tr_dict': tr_dict,\n",
    "        }\n",
    "        pickle.dump(results, f, protocol=-1)\n",
    "\n",
    "if True:\n",
    "    print('Loading results from file')\n",
    "    with open(res_file, 'rb') as handle:\n",
    "        results = pickle.load(handle)\n",
    "    p_val_dict = results['p_val_dict']\n",
    "    sigma_dict = results['sigma_dict']\n",
    "    ts_dict = results['ts_dict']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "def plot_model_confusion(inj_keys, testing_keys=None, bins=np.linspace(0, 6, 20)):\n",
    "    n_keys = len(inj_keys)\n",
    "    \n",
    "    if testing_keys is None:\n",
    "        testing_keys = inj_keys\n",
    "        \n",
    "    fig, axes = plt.subplots(n_keys, 1, figsize=(12, 4*n_keys), sharex=True)\n",
    "    \n",
    "    if n_keys <= 5:\n",
    "        color_cycle = cycle(soft_colors)\n",
    "    else:\n",
    "        color_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "\n",
    "    for i, key_inj in enumerate(inj_keys):\n",
    "\n",
    "        ax = axes[i]\n",
    "        ax.set_title('Injection: {}'.format(key_inj))\n",
    "\n",
    "        for j, key in enumerate(testing_keys):\n",
    "            sigmas = sigma_dict[(key_inj, key)]\n",
    "            if not np.isfinite(sigmas).all():\n",
    "                raise ValueError(sigmas)\n",
    "            color = next(color_cycle)\n",
    "            \n",
    "            if key in ['pi0', 'kra5', 'kra50', 'fermibubbles_50TeV']:\n",
    "                unblinded_ts = res_dict[key][3]\n",
    "            elif key in ['snr', 'pwn', 'unid']:\n",
    "                unblinded_ts = res_dict[key][4]\n",
    "            else:\n",
    "                unblinded_ts = np.nan\n",
    "            \n",
    "            ax.hist(\n",
    "                sigmas, bins=bins, \n",
    "                histtype='step',\n",
    "                color=color,\n",
    "                label=(\n",
    "                    r'Testing: {}'.format(key) + ' [$\\sigma_{50\\%}$ = ' \n",
    "                    + '{:3.2f}'.format(np.median(sigmas))\n",
    "                    + ' | $\\sigma_\\mathrm{unblinded}$ = ' \n",
    "                    + '{:3.2f}]'.format(unblinded_ts)\n",
    "                ),\n",
    "            )\n",
    "            ax.axvline(np.median(sigmas), color=color, ls='--')\n",
    "            ax.axvline(unblinded_ts, color=color, ls='-.')\n",
    "\n",
    "        ax.plot(np.inf, np.inf, color='0.7', ls='--', label='Median $\\sigma$')\n",
    "        ax.plot(np.inf, np.inf, color='0.7', ls='-.', label='Unblinded $\\sigma$')\n",
    "        ax.legend(loc='upper left')\n",
    "        ax.set_ylabel('Frequency')\n",
    "\n",
    "    axes[-1].set_xlabel('Significance in $\\sigma$')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "fig = plot_model_confusion(inj_keys=list(tr_dict.keys()), testing_keys=list(tr_dict.keys()))\n",
    "fig.savefig('{}/model_confusion_all.png'.format(plot_dir))\n",
    "\n",
    "fig = plot_model_confusion(inj_keys=['pi0', 'kra5', 'kra50'], testing_keys=['combined_stacking', 'snr', 'pwn', 'unid'])\n",
    "fig.savefig('{}/model_confusion_stacking_combined.png'.format(plot_dir))\n",
    "\n",
    "fig = plot_model_confusion(inj_keys=['combined_stacking', 'fermibubbles_50TeV'], testing_keys=['pi0', 'kra5', 'kra50', 'combined_stacking', 'fermibubbles_50TeV'])\n",
    "fig.savefig('{}/model_confusion_injected_combined_stacking_fermibubbles.png'.format(plot_dir))\n",
    "\n",
    "fig = plot_model_confusion(inj_keys=['combined_stacking', 'pi0'], testing_keys=['pi0', 'snr', 'pwn', 'unid', 'combined_stacking'])\n",
    "fig.savefig('{}/model_confusion_combined_stacking.png'.format(plot_dir))\n",
    "\n",
    "fig = plot_model_confusion(inj_keys=['fermibubbles_50TeV', 'pi0'], testing_keys=['pi0', 'kra5', 'kra50', 'snr', 'pwn', 'unid', 'fermibubbles_50TeV'])\n",
    "fig.savefig('{}/model_confusion_fermibubbles.png'.format(plot_dir))\n",
    "\n",
    "fig = plot_model_confusion(inj_keys=['pi0', 'kra5', 'kra50'], testing_keys=['pi0', 'kra5', 'kra50', 'snr', 'pwn', 'unid', 'fermibubbles_50TeV'])\n",
    "fig.savefig('{}/model_confusion_gp_inj.png'.format(plot_dir))\n",
    "\n",
    "fig = plot_model_confusion(inj_keys=['pi0', 'kra5', 'kra50'], testing_keys=['snr', 'pwn', 'unid'])\n",
    "fig.savefig('{}/model_confusion_stacking.png'.format(plot_dir))\n",
    "\n",
    "fig = plot_model_confusion(inj_keys=['pi0', 'kra5', 'kra50'], testing_keys=list(tr_dict.keys()))\n",
    "fig.savefig('{}/model_confusion_stacking_all.png'.format(plot_dir))\n",
    "\n",
    "fig = plot_model_confusion(inj_keys=['snr', 'pwn', 'unid'], testing_keys=['pi0', 'kra5', 'kra50'])\n",
    "fig.savefig('{}/model_confusion_stacking__stacking.png'.format(plot_dir))\n",
    "\n",
    "fig = plot_model_confusion(inj_keys=['snr', 'pwn', 'unid'], testing_keys=list(tr_dict.keys()))\n",
    "fig.savefig('{}/model_confusion_stacking__stacking_all.png'.format(plot_dir))\n",
    "\n",
    "fig = plot_model_confusion(inj_keys=['snr', 'pwn', 'unid'], testing_keys=['snr', 'pwn', 'unid'])\n",
    "fig.savefig('{}/model_confusion_stacking__stacking_confusion.png'.format(plot_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot matrix of median values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median_sigma_matrix(model_keys=list(tr_dict.keys())):\n",
    "    n_keys = len(model_keys)\n",
    "    matrix_diff = np.zeros((n_keys, n_keys))\n",
    "\n",
    "    for i, key_inj in enumerate(model_keys):\n",
    "        for j, key in enumerate(model_keys):\n",
    "\n",
    "            sigmas = sigma_dict[(key_inj, key)]\n",
    "            if not np.isfinite(sigmas).all():\n",
    "                raise ValueError(sigmas)\n",
    "\n",
    "            if key in ['pi0', 'kra5', 'kra50', 'fermibubbles_50TeV']:\n",
    "                unblinded_sigma = res_dict[key][3]\n",
    "            elif key in ['snr', 'pwn', 'unid']:\n",
    "                unblinded_sigma = res_dict[key][4]\n",
    "            else:\n",
    "                unblinded_sigma = np.nan\n",
    "            \n",
    "            sigma_diff = np.median(sigmas) - unblinded_sigma\n",
    "            matrix_diff[i, j] = sigma_diff\n",
    "    return matrix_diff, model_keys\n",
    "\n",
    "def plot_matrix(matrix, model_keys, bound=2):\n",
    "    fig, ax = plt.subplots(figsize=(9, 6))\n",
    "    \n",
    "    cmap = plt.cm.RdBu_r  # define the colormap\n",
    "    # extract all colors from the .jet map\n",
    "    cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "    # force the first color entry to be grey\n",
    "    #cmaplist[0] = (.5, .5, .5, 1.0)\n",
    "\n",
    "    # create the new map\n",
    "    cmap = mpl.colors.LinearSegmentedColormap.from_list(\n",
    "        'Custom cmap', cmaplist, cmap.N)\n",
    "\n",
    "    # define the bins and normalize\n",
    "    bounds = np.linspace(-bound, bound, 10)\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "    \n",
    "    image = ax.imshow(matrix, interpolation='none', norm=norm, cmap=cmap)\n",
    "    \n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(len(model_keys)):\n",
    "        for j in range(len(model_keys)):\n",
    "            color_float = np.clip(np.abs(matrix[i, j])/ (bound), 0, 1.)\n",
    "            color_float = (color_float - 0.5)**0.1 + 0.5\n",
    "            color_float =  np.clip(color_float, 0., 1.)\n",
    "            if not np.isfinite(color_float):\n",
    "                color_float = 0.\n",
    "            \n",
    "            color = '{:.2f}'.format(color_float)\n",
    "            text = ax.text(\n",
    "                j, i, '{:.1f}'.format(matrix[i, j]), \n",
    "                ha=\"center\", va=\"center\", color=color, fontsize=8,\n",
    "            )\n",
    "        \n",
    "    cbar = plt.colorbar(image, ax=ax)\n",
    "    cbar.set_label(r'$\\Delta \\sigma = \\sigma_{50\\%} - \\sigma_\\mathrm{unblinded}$')\n",
    "    plt.xticks(range(len(model_keys)), model_keys, fontsize=8, rotation=90)\n",
    "    plt.yticks(range(len(model_keys)), model_keys, fontsize=8)\n",
    "    ax.set_xlabel('Tested Model')\n",
    "    ax.set_ylabel('Injected Model')\n",
    "    return fig, ax\n",
    "\n",
    "chosen_models = ['fermibubbles_50TeV', 'pi0', 'kra5', 'kra50', 'snr', 'pwn', 'unid', 'combined_stacking']\n",
    "matrix, model_keys = get_median_sigma_matrix(model_keys=chosen_models)\n",
    "fig, ax = plot_matrix(matrix, model_keys=model_keys)\n",
    "#ax.set_title('Model Confusion Test')\n",
    "fig.tight_layout()\n",
    "fig.savefig('{}/model_confusion_matrix.png'.format(plot_dir))\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot NS Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_poisson = True\n",
    "if use_poisson:\n",
    "    allt_i_dict_file = os.path.join(plot_dir, 'allt_i_dict_poisson.pkl')\n",
    "else:\n",
    "    allt_i_dict_file = os.path.join(plot_dir, 'allt_i_dict.pkl')\n",
    "\n",
    "if os.path.exists(allt_i_dict_file):\n",
    "    print('Loading from file')\n",
    "    with open(allt_i_dict_file, 'rb') as handle:\n",
    "        allt_i_dict = pickle.load(handle)\n",
    "else:\n",
    "    print('Creating new dict')\n",
    "    allt_i_dict = {}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_bias_plot_keys = ['pi0']\n",
    "ntrials = 100\n",
    "recalculate = True\n",
    "\n",
    "for key in ns_bias_plot_keys:\n",
    "    if key not in allt_i_dict or recalculate:\n",
    "        ns = int(ns_dict[key])\n",
    "        max_diff = max(100, int(ns_dict[key] * 1.))\n",
    "        trial_runner = tr_dict[key]\n",
    "\n",
    "        n_sigs = np.sort(\n",
    "            np.r_[np.clip(ns - max_diff, 0., np.inf): ns + max_diff:10],\n",
    "        ).astype(int)\n",
    "        print('Submitting {} values for {} from {} +- {}'.format(len(n_sigs), key, ns, max_diff))\n",
    "\n",
    "        allt_i = get_bias_allt(\n",
    "            trial_runner, ntrials=ntrials, n_sigs=n_sigs, poisson=use_poisson)\n",
    "\n",
    "        allt_i_dict[key] = allt_i\n",
    "\n",
    "with open(allt_i_dict_file, 'wb') as f:\n",
    "    pickle.dump(allt_i_dict, f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, allt_i in allt_i_dict.items():\n",
    "    \n",
    "    trial_runner = tr_dict[key]\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    plot_ns_bias(ax, trial_runner, allt_i, label=None)\n",
    "    \n",
    "    ax.axhline(\n",
    "        res_dict[key][1], \n",
    "        ls='--',\n",
    "        label='Unblinded ns: {:3.3f}'.format(res_dict[key][1]),\n",
    "    )\n",
    "    ax.set(title=r'Analysis: {}'.format(key))\n",
    "    ax.legend(fontsize=8)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('{}/bias_{}.png'.format(plot_dir, key))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, allt_i in allt_i_dict.items():\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(9, 6))\n",
    "    \n",
    "    max_diff = 2\n",
    "    mask = np.abs(allt_i.ns - res_dict[key][1]) < max_diff\n",
    "    median_ntrue = np.median(allt_i.ntrue[mask])\n",
    "    mean_ntrue = np.mean(allt_i.ntrue[mask])\n",
    "    std_ntrue = np.std(allt_i.ntrue[mask])\n",
    "    ax.hist(\n",
    "        allt_i.ntrue[mask], color=soft_colors[0], \n",
    "        label=r'$P(n_\\mathrm{inj}$' + r' | ns = {:3.1f} $\\pm$ {:3.1f})'.format(\n",
    "            res_dict[key][1], max_diff),\n",
    "        density=True, bins=15,\n",
    "    )\n",
    "    \n",
    "    ax.axvline(\n",
    "        median_ntrue, color='0.7', ls='--',\n",
    "        label='Median $n_\\mathrm{inj}$' + ': {:3.1f}'.format(median_ntrue),\n",
    "    )\n",
    "    \n",
    "    ax.axvline(\n",
    "        res_dict[key][1], color=soft_colors[1], ls='--',\n",
    "        label='Unblinded ns: {:3.1f}'.format(res_dict[key][1]),\n",
    "    )\n",
    "    ax.set(title=r'Analysis: {}'.format(key) + ' | $n_\\mathrm{inj}$' + '(ns={:3.1f}) = {:3.1f} $\\pm$ {:3.1f} [$\\mu \\pm \\sigma$ ]'.format(\n",
    "        res_dict[key][1], mean_ntrue, std_ntrue))\n",
    "    ax.set_xlabel('True $n_\\mathrm{inj}$')\n",
    "    ax.set_ylabel('PDF')\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('{}/bias_at_unblinded_ns_{}.png'.format(plot_dir, key))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute bkg trial significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val_dict_bkg = {}\n",
    "sigma_dict_bkg = {}\n",
    "max_n = 10000000\n",
    "for key, bg in bkg_dict.items():\n",
    "    print('key:', key)\n",
    "    bg_tsd = cy.dists.TSD(bg[:max_n])\n",
    "    p_val_dict_bkg[key] = bg_tsd.sf(bg[:max_n])\n",
    "    sigma_dict_bkg[key] = bg_tsd.sf_nsigma(bg[:max_n])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Trial Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(bkg_dict['snr'][:max_n])\n",
    "sigma_threshold = -10.5\n",
    "\n",
    "for key, tr in sigma_dict_bkg.items():\n",
    "\n",
    "    mask = np.logical_or(mask, sigma_dict_bkg[key] > sigma_threshold)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "def plot_corr_ax(ax, key1, key2, mask=None, norm=None):\n",
    "    \n",
    "    if mask is None:\n",
    "        mask = np.ones_like(sigma_dict_bkg[key1], dtype=bool)\n",
    "        \n",
    "    ax.hist2d(\n",
    "        sigma_dict_bkg[key1][mask], sigma_dict_bkg[key2][mask],\n",
    "        bins=bins, norm=norm, cmin=1,\n",
    "    )\n",
    "    ax.plot(\n",
    "        (bins[0][0], bins[0][-1]), (bins[0][0], bins[0][-1]), \n",
    "        ls='--', color='0.7', lw=3,\n",
    "    )\n",
    "    ax.set_xlabel('$n\\cdot \\sigma$ of {}'.format(key1))\n",
    "    ax.set_ylabel('$n\\cdot \\sigma$ of {}'.format(key2))\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(9, 9))\n",
    "\n",
    "bins = (np.linspace(0, 6), np.linspace(0, 6))\n",
    "\n",
    "mask = None\n",
    "plot_corr_ax(axes[0], 'snr', 'pwn', mask=mask)\n",
    "plot_corr_ax(axes[1], 'snr', 'unid', mask=mask)\n",
    "plot_corr_ax(axes[2], 'unid', 'pwn', mask=mask)\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "corr_keys = ['snr', 'pwn', 'unid']\n",
    "corr_keys = ['pi0', 'kra5', 'kra50']\n",
    "#corr_keys = ['pi0', 'kra5', 'kra50', 'snr', 'pwn', 'unid']\n",
    "\n",
    "max_nsigma = np.max(\n",
    "    np.stack([sigma_dict_bkg[k] for k in corr_keys]),\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "bg_max = cy.dists.TSD(max_nsigma)\n",
    "bins = np.linspace(0, 6, 100)\n",
    "fig, ax = plot_bkg_trials(bg_max, bins=bins, color=soft_colors[1])\n",
    "ax.hist(max_nsigma, bins=bins)\n",
    "ax.set_xlabel('Max n-sigma')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "nsigma_chosen = 4.705\n",
    "pval_chosen = stats.norm.sf(nsigma_chosen)\n",
    "nsigma_corrected = bg_max.sf_nsigma(nsigma_chosen)\n",
    "\n",
    "pval_corrected = bg_max.sf(nsigma_chosen)\n",
    "print('Correcting for: {}'.format(corr_keys))\n",
    "print('Pre-trial N-sigma of: {}'.format(nsigma_chosen))\n",
    "print('Post-trial correlated: {} | factor: {}'.format(nsigma_corrected, pval_corrected/pval_chosen))\n",
    "print('Post-trial conservative: {} | factor: {}'.format(stats.norm.isf(pval_chosen * len(corr_keys)), len(corr_keys)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icerec3",
   "language": "python",
   "name": "icerec3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

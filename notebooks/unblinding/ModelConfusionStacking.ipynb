{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-trading",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#PDFs in BDT and sindec?\n",
    "import os\n",
    "\n",
    "# set env flags to catch BLAS used for scipy/numpy \n",
    "# to only use 1 cpu, n_cpus will be totally controlled by csky\n",
    "if False:\n",
    "    os.environ['MKL_NUM_THREADS'] = \"1\"\n",
    "    os.environ['NUMEXPR_NUM_THREADS'] = \"1\"\n",
    "    os.environ['OMP_NUM_THREADS'] = \"1\"\n",
    "    os.environ['OPENBLAS_NUM_THREADS'] = \"1\"\n",
    "    os.environ['VECLIB_MAXIMUM_THREADS'] = \"1\"\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.facecolor'] = 'w'\n",
    "mpl.rcParams['savefig.facecolor'] = 'w'\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors, cm\n",
    "import csky as cy\n",
    "from csky import cext\n",
    "import numpy as np\n",
    "import astropy\n",
    "#from icecube import astro\n",
    "import histlite as hl\n",
    "import healpy\n",
    "import healpy as hp\n",
    "import socket\n",
    "import pickle\n",
    "import copy\n",
    "healpy.disable_warnings()\n",
    "plt.rc('figure', facecolor = 'w')\n",
    "plt.rc('figure', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-narrative",
   "metadata": {},
   "source": [
    "## Define Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_version = 'version-001-p01'\n",
    "\n",
    "host_name = socket.gethostname()\n",
    "\n",
    "if 'cobalt' in host_name:\n",
    "    print('Working on Cobalts')\n",
    "    plot_dir = '/data/user/mhuennefeld/data/analyses/DNNCascadeCodeReview/unblinding_checks/plots/unblinding/model_confusion_stacking'\n",
    "    data_dir = os.path.join(plot_dir, 'data')\n",
    "    \n",
    "else:\n",
    "    raise ValueError('Unknown host:', host_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir_path in [plot_dir, data_dir]:\n",
    "    if not os.path.exists(dir_path):\n",
    "        print('Creating directory:', dir_path)\n",
    "        os.makedirs(dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-neighbor",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-hybrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = cy.selections.Repository()\n",
    "specs = cy.selections.DNNCascadeDataSpecs.DNNC_10yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ana = cy.get_analysis(\n",
    "    repo, selection_version, specs, \n",
    "    #gammas=np.r_[0.1:6.01:0.125],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ana.anas[0]\n",
    "a.sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.bg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-convention",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cycler import cycle\n",
    "from copy import deepcopy\n",
    "\n",
    "soft_colors = cy.plotting.soft_colors\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "\n",
    "def get_bias_allt(tr, ntrials=200, n_sigs=np.r_[:101:10], quiet=False, poisson=False):\n",
    "    trials = [\n",
    "        (None if quiet else print(f'\\r{n_sig:4d} ...', end='', flush=True))\n",
    "        or\n",
    "        tr.get_many_fits(ntrials, n_sig=n_sig, logging=False, seed=n_sig, poisson=poisson)\n",
    "        for n_sig in n_sigs]\n",
    "    if not quiet:\n",
    "        print()\n",
    "    for (n_sig, t) in zip(n_sigs, trials):\n",
    "        t['ntrue'] = np.repeat(n_sig, len(t))\n",
    "    allt = cy.utils.Arrays.concatenate(trials)\n",
    "    return allt\n",
    "\n",
    "def get_color_cycler():\n",
    "    return cycle(colors)\n",
    "\n",
    "def plot_ns_bias(ax, tr, allt, label=''):\n",
    "\n",
    "    n_sigs = np.unique(allt.ntrue)\n",
    "    dns = np.mean(np.diff(n_sigs))\n",
    "    ns_bins = np.r_[n_sigs - 0.5*dns, n_sigs[-1] + 0.5*dns]\n",
    "    expect_kw = dict(color='C0', ls='--', lw=1, zorder=-10)\n",
    "\n",
    "    h = hl.hist((allt.ntrue, allt.ns), bins=(ns_bins, 100))\n",
    "    hl.plot1d(ax, h.contain_project(1),errorbands=True, \n",
    "              drawstyle='default', label=label)\n",
    "    lim = ns_bins[[0, -1]]\n",
    "    ax.set_xlim(ax.set_ylim(lim))\n",
    "    ax.plot(lim, lim, **expect_kw)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    ax.set_xlabel(r'$n_{inj}$')\n",
    "    ax.set_ylabel(r'$n_s$')\n",
    "    ax.grid()\n",
    "\n",
    "def plot_gamma_bias(ax, tr, allt, label=''):\n",
    "\n",
    "    n_sigs = np.unique(allt.ntrue)\n",
    "    dns = np.mean(np.diff(n_sigs))\n",
    "    ns_bins = np.r_[n_sigs - 0.5*dns, n_sigs[-1] + 0.5*dns]\n",
    "    expect_kw = dict(color='C0', ls='--', lw=1, zorder=-10)\n",
    "    expect_gamma = tr.sig_injs[0].flux[0].gamma\n",
    "\n",
    "    h = hl.hist((allt.ntrue, allt.gamma), bins=(ns_bins, 100))\n",
    "    hl.plot1d(ax, h.contain_project(1),errorbands=True, \n",
    "              drawstyle='default', label=label)\n",
    "    lim = ns_bins[[0, -1]]\n",
    "    ax.set_xlim(lim)\n",
    "    ax.set_ylim(1, 4)\n",
    "    ax.axhline(expect_gamma, **expect_kw)\n",
    "\n",
    "    ax.set_xlabel(r'$n_{inj}$')\n",
    "    ax.set_ylabel(r'$\\gamma$')\n",
    "    ax.grid()\n",
    "\n",
    "def plot_bkg_trials(\n",
    "            bg, fig=None, ax=None, \n",
    "            label='{} bg trials', \n",
    "            label_fit=r'$\\chi^2[{:.2f}\\mathrm{{dof}},\\ \\eta={:.3f}]$', \n",
    "            color=colors[0],\n",
    "            density=False,\n",
    "            bins=50,\n",
    "        ):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    \n",
    "    if density:\n",
    "        h = bg.get_hist(bins=bins).normalize()\n",
    "    else:\n",
    "        h = bg.get_hist(bins=bins)\n",
    "    if label is not None:\n",
    "        label = label.format(bg.n_total)\n",
    "    hl.plot1d(ax, h, crosses=True, color=color, label=label)\n",
    "\n",
    "    # compare with the chi2 fit:\n",
    "    if hasattr(bg, 'pdf'):\n",
    "        x = h.centers[0]\n",
    "        norm = h.integrate().values\n",
    "        if label_fit is not None:\n",
    "            label_fit = label_fit.format(bg.ndof, bg.eta)\n",
    "        if density:\n",
    "            ax.semilogy(x, bg.pdf(x), lw=1, ls='--', label=label_fit, color=color)\n",
    "        else:\n",
    "            ax.semilogy(x, norm * bg.pdf(x), lw=1, ls='--', label=label_fit, color=color)\n",
    "\n",
    "    ax.set_xlabel(r'TS')\n",
    "    if density:\n",
    "        ax.set_ylabel(r'Density')\n",
    "    else:\n",
    "        ax.set_ylabel(r'number of trials')\n",
    "    ax.legend()\n",
    "        \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-acrobat",
   "metadata": {},
   "source": [
    "## Setup Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "import config as cg\n",
    "\n",
    "cg.base_dir = '/data/user/mhuennefeld/data/analyses/unblinding_v1.0.1_csky_bugfix_template_flux/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gp_tr(template_str, cutoff=np.inf, gamma=None, cpus=20):\n",
    "    cutoff_GeV = cutoff * 1e3\n",
    "    gp_conf = cg.get_gp_conf(\n",
    "        template_str=template_str, gamma=gamma, cutoff_GeV=cutoff_GeV, base_dir=cg.base_dir)\n",
    "    tr = cy.get_trial_runner(gp_conf, ana=ana, mp_cpus=cpus)\n",
    "    return tr\n",
    "\n",
    "def get_catalog_tr(catalog, cutoff=np.inf, gamma=2.0, cpus=20):\n",
    "    catalog_file = os.path.join(\n",
    "        cg.catalog_dir, '{}_ESTES_12.pickle'.format(catalog))\n",
    "    cat = np.load(catalog_file, allow_pickle=True)\n",
    "    src = cy.utils.Sources(dec=cat['dec_deg'], ra=cat['ra_deg'], deg=True)\n",
    "    cutoff_GeV = cutoff * 1e3\n",
    "\n",
    "    conf = cg.get_ps_conf(src=src, gamma=gamma, cutoff_GeV=cutoff_GeV)\n",
    "    tr = cy.get_trial_runner(ana=ana, conf=conf, mp_cpus=cpus)\n",
    "    return tr\n",
    "\n",
    "def get_combined_catalog_tr(cutoff=np.inf, gamma=2.0, cpus=20):\n",
    "    dec_degs = []\n",
    "    ra_degs = []\n",
    "    for catalog in ['snr', 'pwn', 'unid']:\n",
    "        catalog_file = os.path.join(\n",
    "            cg.catalog_dir, '{}_ESTES_12.pickle'.format(catalog))\n",
    "        cat = np.load(catalog_file, allow_pickle=True)\n",
    "        dec_degs.append(cat['dec_deg'])\n",
    "        ra_degs.append(cat['ra_deg'])\n",
    "        \n",
    "    dec_degs = np.concatenate(dec_degs)\n",
    "    ra_degs = np.concatenate(ra_degs)\n",
    "    \n",
    "    src = cy.utils.Sources(dec=dec_degs, ra=ra_degs, deg=True)\n",
    "    cutoff_GeV = cutoff * 1e3\n",
    "\n",
    "    conf = cg.get_ps_conf(src=src, gamma=gamma, cutoff_GeV=cutoff_GeV)\n",
    "    tr = cy.get_trial_runner(ana=ana, conf=conf, mp_cpus=cpus)\n",
    "    return tr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-framing",
   "metadata": {},
   "source": [
    "#### Choose if to use bias-corrected values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_bias_correction = True\n",
    "\n",
    "if use_bias_correction:\n",
    "    stacking_catalog_gammas = {\n",
    "        'snr': 2.735,\n",
    "        'pwn': 2.99,\n",
    "        'unid': 2.835,\n",
    "        'combined_stacking': 2.81,\n",
    "    }\n",
    "else:\n",
    "    stacking_catalog_gammas = {\n",
    "        'snr': 2.75157378532275,\n",
    "        'pwn': 2.9980144482315327,\n",
    "        'unid': 2.846381577315917,\n",
    "        'combined_stacking': 2.86,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-eligibility",
   "metadata": {},
   "source": [
    "#### Get TrialRunners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "inj_tr_dict = {\n",
    "    'fermibubbles_50TeV': get_gp_tr('fermibubbles', cutoff=50),\n",
    "    'pi0': get_gp_tr('pi0'),\n",
    "    'kra5': get_gp_tr('kra5'),\n",
    "    'kra50': get_gp_tr('kra50'),\n",
    "    'snr': get_catalog_tr('snr', gamma=stacking_catalog_gammas['snr']),\n",
    "    'pwn': get_catalog_tr('pwn', gamma=stacking_catalog_gammas['pwn']),\n",
    "    'unid': get_catalog_tr('unid', gamma=stacking_catalog_gammas['unid']),\n",
    "    'combined_stacking': get_combined_catalog_tr(gamma=stacking_catalog_gammas['combined_stacking']),\n",
    "}\n",
    "\n",
    "tr_dict = inj_tr_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-anime",
   "metadata": {},
   "source": [
    "#### Get Results for each template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = {}\n",
    "for key in tr_dict.keys():\n",
    "    if key in ['pi0', 'kra5', 'kra50']:\n",
    "        f_path = os.path.join(\n",
    "            cg.base_dir, \n",
    "            'gp/results/{}/{}_unblinded.npy'.format(key, key), \n",
    "        )\n",
    "        res_dict[key] = np.load(f_path)\n",
    "    elif key in ['fermibubbles_50TeV']:\n",
    "        f_path = os.path.join(\n",
    "            cg.base_dir, 'gp/results/fermibubbles/fermibubbles_unblinded.npy', \n",
    "        )\n",
    "        total_trials = np.load(f_path)\n",
    "        \n",
    "        cutoffs = [50, 100, 500, np.inf]\n",
    "        cutoff = float(key.replace('fermibubbles_', '').replace('TeV', ''))\n",
    "        res_dict[key] = total_trials[np.searchsorted(cutoffs, cutoff)]\n",
    "        \n",
    "    elif key in ['snr', 'pwn', 'unid']:\n",
    "        f_path = os.path.join(\n",
    "            cg.base_dir, \n",
    "            'stacking/results/{}/{}_unblinded.npy'.format(key, key), \n",
    "        )\n",
    "        res_dict[key] = np.load(f_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-nebraska",
   "metadata": {},
   "source": [
    "#### Define number of ns to inject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-projection",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "E0 = 100\n",
    "unit = 1000\n",
    "\n",
    "print('snr', tr_dict['snr'].to_ns(E2dNdE=6.2e-12, E0=E0, unit=unit))\n",
    "print('pwn', tr_dict['pwn'].to_ns(E2dNdE=3.85e-12, E0=E0, unit=unit))\n",
    "print('unid', tr_dict['unid'].to_ns(E2dNdE=4.7e-12, E0=E0, unit=unit))\n",
    "print('pi0', tr_dict['pi0'].to_ns(E2dNdE=2.18e-11, E0=E0, unit=unit))\n",
    "\n",
    "def get_ns_from_model_norm(template, model_norm, correction_factor=1.):\n",
    "    def loss(ns):\n",
    "        return (model_norm - tr_dict[template].to_model_norm(ns) * correction_factor)**2\n",
    "    \n",
    "    res = minimize(loss, x0=200)\n",
    "    print(tr_dict[template].to_model_norm(res.x[0]) * correction_factor)\n",
    "    return res.x[0]\n",
    "\n",
    "print('kra5', get_ns_from_model_norm(template='kra5', model_norm=0.55))\n",
    "print('kra50', get_ns_from_model_norm(template='kra50', model_norm=0.37))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-assurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_bias_correction:\n",
    "    ns_dict = {\n",
    "        'pi0': 669.20,\n",
    "        'kra5': 242.7,\n",
    "        'kra50': 183.6,\n",
    "        'snr': 189.5,\n",
    "        'pwn': 247.3,\n",
    "        'unid': 205.8,\n",
    "        'combined_stacking': 335.,\n",
    "        'fermibubbles_50TeV': 90., \n",
    "    }\n",
    "else:\n",
    "    ns_dict = {\n",
    "        'pi0': 748.0433961026386,\n",
    "        'kra5': 275.64561683178107,\n",
    "        'kra50': 211.13586269951296,\n",
    "        'snr': 218.59746844389832,\n",
    "        'pwn': 279.6393079525785,\n",
    "        'unid': 238.36706157922325,\n",
    "        'combined_stacking': 335,\n",
    "        'fermibubbles_50TeV': 95.94615440877195,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-adobe",
   "metadata": {},
   "source": [
    "#### Print Best Fit Fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_bias_correction:\n",
    "    print('Showing bias-corrected fluxes')\n",
    "for key, tr in tr_dict.items():\n",
    "    if key in res_dict and not use_bias_correction:\n",
    "        ns = res_dict[key][1]\n",
    "    else:\n",
    "        ns = ns_dict[key]\n",
    "        if not use_bias_correction:\n",
    "            print('No result found. Assuming ns of: {:3.1f}'.format(ns))\n",
    "        \n",
    "    dNdE = tr_dict[key].to_dNdE(ns=ns, E0=1e5)\n",
    "    E2dNdE = tr_dict[key].to_E2dNdE(ns=ns, E0=100, unit=1e3)\n",
    "    if not isinstance(E2dNdE, float):\n",
    "        E2dNdE = E2dNdE[0]\n",
    "    print('E2dNdE at 100 TeV in units of Tev {:3.3e} | {}'.format(E2dNdE, key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-seventh",
   "metadata": {},
   "source": [
    "#### Get bkg fits for each template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_file_dict = {\n",
    "    'fermibubbles_50TeV': '{}/gp/trials/{}/{}/trials.dict'.format(cg.base_dir, 'DNNC', 'fermibubbles'),\n",
    "    'pi0': '{}/gp/trials/{}/{}/trials.dict'.format(cg.base_dir, 'DNNC', 'pi0'),\n",
    "    'kra5': '{}/gp/trials/{}/{}/trials.dict'.format(cg.base_dir, 'DNNC', 'kra5'),\n",
    "    'kra50': '{}/gp/trials/{}/{}/trials.dict'.format(cg.base_dir, 'DNNC', 'kra50'),\n",
    "    'snr': '{}/stacking/{}_bg.dict'.format(cg.base_dir, 'snr'),\n",
    "    'pwn': '{}/stacking/{}_bg.dict'.format(cg.base_dir, 'pwn'),\n",
    "    'unid': '{}/stacking/{}_bg.dict'.format(cg.base_dir, 'unid'),\n",
    "    'combined_stacking': os.path.join(plot_dir, 'trials_combined_stacking.pkl'),\n",
    "}\n",
    "n_bkg_trials = 20000\n",
    "seed = 1337\n",
    "\n",
    "bkg_dict = {}\n",
    "bkg_dist_dict = {}\n",
    "\n",
    "for key, tr in tr_dict.items():\n",
    "    if key in bkg_file_dict and os.path.exists(bkg_file_dict[key]):\n",
    "        print('Loading background trials for template {}'.format(key))\n",
    "        sig = np.load(bkg_file_dict[key], allow_pickle=True)\n",
    "        if key in ['pi0', 'kra5', 'kra50']:\n",
    "            bkg_dict[key] = sig['poisson']['nsig'][0.0]['ts']\n",
    "        elif key in ['fermibubbles_50TeV']:\n",
    "            cutoff = float(key.replace('fermibubbles_', '').replace('TeV', ''))\n",
    "            print(key, 'cutoff', cutoff)\n",
    "            bkg_dict[key] = sig['poisson']['cutoff'][cutoff]['nsig'][0.0]['ts']\n",
    "        else:\n",
    "            bkg_dict[key] = sig.ts\n",
    "    \n",
    "    else:\n",
    "        print('Running background trials for template {}'.format(key))\n",
    "        trials = tr.get_many_fits(\n",
    "            n_trials=n_bkg_trials, seed=seed, mp_cpus=20)\n",
    "        \n",
    "        bkg_dict[key] = trials.ts\n",
    "        \n",
    "        out_file = os.path.join(plot_dir, 'trials_{}.pkl'.format(key))\n",
    "        with open(out_file, 'wb') as f:\n",
    "            pickle.dump(trials, f, protocol=2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sigma(key):\n",
    "    res = tr_dict[key].get_one_fit(TRUTH=True, flat=False)\n",
    "    if key in bkg_dist_dict:\n",
    "        bg = bkg_dist_dict[key]\n",
    "    else:\n",
    "        bg = cy.dists.Chi2TSD(bkg_dict[key])\n",
    "    return bg.sf_nsigma(res[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-reality",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in tr_dict.keys():\n",
    "    if k not in res_dict:\n",
    "        res_ = tr_dict[k].get_one_fit(TRUTH=True, flat=False)\n",
    "        res = {'ts': res_[0]}\n",
    "        res.update(res_[1])\n",
    "        res['sigma'] = get_sigma(k)\n",
    "        res_dict[k] = res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-closing",
   "metadata": {},
   "source": [
    "#### Plot ts distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-convenience",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key, bg in bkg_dict.items():\n",
    "    bg_tsd = cy.dists.TSD(bg)\n",
    "    fig, ax = plot_bkg_trials(bg_tsd)\n",
    "    if key in res_dict:\n",
    "        ts = res_dict[key][0]\n",
    "        ns = res_dict[key][1]\n",
    "        ax.axvline(\n",
    "            ts, color='0.8', ls='--', lw=2,\n",
    "            label='TS: {:3.3f} | ns: {:3.1f}'.format(ts, ns), \n",
    "        )\n",
    "    ts_5sig = bg_tsd.isf_nsigma(5)\n",
    "    ax.axvline(\n",
    "        ts_5sig, ls='--', lw=1,\n",
    "        label='5-sigma TS: {:3.3f}'.format(ts_5sig), \n",
    "    )\n",
    "    ax.set_title('Analysis: {}'.format(key))\n",
    "    ax.set_yscale('log')\n",
    "    ax.legend()\n",
    "    fig.savefig('{}/ts_dist_{}.png'.format(plot_dir, key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-pizza",
   "metadata": {},
   "source": [
    "#### Get trials for each template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "n_trials = 1000\n",
    "seed = 42\n",
    "trials_dict = {}\n",
    "\n",
    "for key, tr in inj_tr_dict.items():\n",
    "    \n",
    "    n_sig = ns_dict[key]\n",
    "    trials = []\n",
    "    \n",
    "    print('Injecting {} signal events for template {}'.format(n_sig, key))\n",
    "    for i in tqdm(range(n_trials), total=n_trials):\n",
    "        trials.append(tr.get_one_trial(n_sig=n_sig, poisson=True, seed=seed + i))\n",
    "    \n",
    "    trials_dict[key] = trials\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-thumbnail",
   "metadata": {},
   "source": [
    "#### Get fits for each template combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-treaty",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "n_cpus = 20\n",
    "recompute = False\n",
    "\n",
    "ts_dict = {}\n",
    "for key_inj, tr_inj in inj_tr_dict.items():\n",
    "    \n",
    "    for key, tr in tr_dict.items():\n",
    "        \n",
    "        # define output file\n",
    "        out_file = '{}/inj_{}_fit_{}.pkl'.format(data_dir, key_inj, key)\n",
    "        \n",
    "        if not os.path.exists(out_file) or recompute:\n",
    "            print('Computing TS values for injection {} and testing with {}'.format(key_inj, key))\n",
    "\n",
    "            ts_values = []\n",
    "            n_values = len(trials_dict[key_inj])\n",
    "\n",
    "            if n_cpus > 1:\n",
    "                print('Running pool with {} cpus'.format(n_cpus))\n",
    "                def compute_trial(i):\n",
    "                    return tr.get_one_fit_from_trial(trials_dict[key_inj][i])\n",
    "\n",
    "                with Pool(n_cpus) as p:\n",
    "                    ts_values_i = list(tqdm(p.imap(compute_trial, range(len(trials_dict[key_inj]))), total=n_values))\n",
    "                ts_values.extend(ts_values_i)\n",
    "                p.close()\n",
    "            else:\n",
    "                for trial in tqdm(trials_dict[key_inj], total=n_values):\n",
    "                    ts_values.append(tr.get_one_fit_from_trial(trial)) \n",
    "\n",
    "            ts_values = np.array(ts_values)\n",
    "            \n",
    "            with open(out_file, 'wb') as f:\n",
    "                pickle.dump(ts_values, f, protocol=2)\n",
    "        else:\n",
    "            print('Loading TS values for injection {} and testing with {}'.format(key_inj, key))\n",
    "            with open(out_file, 'rb') as handle:\n",
    "                ts_values = pickle.load(handle)\n",
    "        \n",
    "        ts_dict[(key_inj, key)] = cy.utils.Arrays({\n",
    "          'ts': ts_values[:, 0],  \n",
    "          'ns': ts_values[:, 1],  \n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-stanford",
   "metadata": {},
   "source": [
    "#### Compute Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-customs",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val_dict = {}\n",
    "sigma_dict = {}\n",
    "\n",
    "for key, ts_values in tqdm(ts_dict.items(), total=len(ts_dict)):\n",
    "    if len(bkg_dict[key[1]]) < 100000:\n",
    "        if key[1] in bkg_dist_dict:\n",
    "            bg = bkg_dist_dict[key[1]]\n",
    "        else:\n",
    "            bg = cy.dists.Chi2TSD(bkg_dict[key[1]])\n",
    "            bkg_dist_dict[key[1]] = bg\n",
    "    else:\n",
    "        bg = cy.dists.TSD(bkg_dict[key[1]])\n",
    "    max_bg_ts = np.max(bg.values)\n",
    "    mask_above = ts_values.ts > max_bg_ts\n",
    "    ts = np.array(ts_values.ts)\n",
    "    if np.sum(mask_above) > 0:\n",
    "        print('Setting {} ts values to max bkg ts value of {}.'.format(\n",
    "            np.sum(mask_above), max_bg_ts))\n",
    "        ts[mask_above] = max_bg_ts\n",
    "    p_val_dict[key] = bg.sf(ts)\n",
    "    sigma_dict[key] = bg.sf_nsigma(ts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-boost",
   "metadata": {},
   "source": [
    "#### Save/Load Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-journey",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_bias_correction:\n",
    "    res_file = os.path.join(plot_dir, 'trials_and_fits_bias_corrected.pkl')\n",
    "else:\n",
    "    res_file = os.path.join(plot_dir, 'trials_and_fits.pkl')\n",
    "\n",
    "\n",
    "if not os.path.exists(res_file):\n",
    "    print('Writing results to file')\n",
    "    with open(res_file, 'wb') as f:\n",
    "        results = {\n",
    "            'p_val_dict': p_val_dict,\n",
    "            'sigma_dict': sigma_dict,\n",
    "            'ts_dict': ts_dict,\n",
    "            'res_dict': res_dict,\n",
    "            #'trials_dict': trials_dict,\n",
    "            #'tr_dict': tr_dict,\n",
    "        }\n",
    "        pickle.dump(results, f, protocol=-1)\n",
    "\n",
    "if True:\n",
    "    print('Loading results from file')\n",
    "    with open(res_file, 'rb') as handle:\n",
    "        results = pickle.load(handle)\n",
    "    p_val_dict = results['p_val_dict']\n",
    "    sigma_dict = results['sigma_dict']\n",
    "    ts_dict = results['ts_dict']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-landscape",
   "metadata": {},
   "source": [
    "#### Plot Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "def plot_model_confusion(inj_keys, testing_keys=None, bins=np.linspace(0, 6, 20)):\n",
    "    n_keys = len(inj_keys)\n",
    "    \n",
    "    if testing_keys is None:\n",
    "        testing_keys = inj_keys\n",
    "        \n",
    "    fig, axes = plt.subplots(n_keys, 1, figsize=(12, 4*n_keys), sharex=True)\n",
    "    \n",
    "    if n_keys <= 5:\n",
    "        color_cycle = cycle(soft_colors)\n",
    "    else:\n",
    "        color_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "\n",
    "    for i, key_inj in enumerate(inj_keys):\n",
    "\n",
    "        ax = axes[i]\n",
    "        ax.set_title('Injection: {}'.format(key_inj))\n",
    "\n",
    "        for j, key in enumerate(testing_keys):\n",
    "            sigmas = sigma_dict[(key_inj, key)]\n",
    "            if not np.isfinite(sigmas).all():\n",
    "                raise ValueError(sigmas)\n",
    "            color = next(color_cycle)\n",
    "            \n",
    "            if key in ['pi0', 'kra5', 'kra50', 'fermibubbles_50TeV']:\n",
    "                unblinded_ts = res_dict[key][3]\n",
    "            elif key in ['snr', 'pwn', 'unid']:\n",
    "                unblinded_ts = res_dict[key][5]\n",
    "            else:\n",
    "                unblinded_ts = np.nan\n",
    "            \n",
    "            ax.hist(\n",
    "                sigmas, bins=bins, \n",
    "                histtype='step',\n",
    "                color=color,\n",
    "                label=(\n",
    "                    r'Testing: {}'.format(key) + ' [$\\sigma_{50\\%}$ = ' \n",
    "                    + '{:3.2f}'.format(np.median(sigmas))\n",
    "                    + ' | $\\sigma_\\mathrm{unblinded}$ = ' \n",
    "                    + '{:3.2f}]'.format(unblinded_ts)\n",
    "                ),\n",
    "            )\n",
    "            ax.axvline(np.median(sigmas), color=color, ls='--')\n",
    "            ax.axvline(unblinded_ts, color=color, ls='-.')\n",
    "\n",
    "        ax.plot(np.inf, np.inf, color='0.7', ls='--', label='Median $\\sigma$')\n",
    "        ax.plot(np.inf, np.inf, color='0.7', ls='-.', label='Unblinded $\\sigma$')\n",
    "        ax.legend(loc='upper left')\n",
    "        ax.set_ylabel('Frequency')\n",
    "\n",
    "    axes[-1].set_xlabel('Significance in $\\sigma$')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "fig = plot_model_confusion(inj_keys=list(tr_dict.keys()), testing_keys=list(tr_dict.keys()))\n",
    "fig.savefig('{}/model_confusion_all.png'.format(plot_dir))\n",
    "\n",
    "fig = plot_model_confusion(inj_keys=['pi0', 'kra5', 'kra50'], testing_keys=['combined_stacking', 'snr', 'pwn', 'unid'])\n",
    "fig.savefig('{}/model_confusion_stacking_combined.png'.format(plot_dir))\n",
    "\n",
    "fig = plot_model_confusion(inj_keys=['combined_stacking', 'fermibubbles_50TeV'], testing_keys=['pi0', 'kra5', 'kra50', 'combined_stacking', 'fermibubbles_50TeV'])\n",
    "fig.savefig('{}/model_confusion_injected_combined_stacking_fermibubbles.png'.format(plot_dir))\n",
    "\n",
    "fig = plot_model_confusion(inj_keys=['combined_stacking', 'pi0'], testing_keys=['pi0', 'snr', 'pwn', 'unid', 'combined_stacking'])\n",
    "fig.savefig('{}/model_confusion_combined_stacking.png'.format(plot_dir))\n",
    "\n",
    "fig = plot_model_confusion(inj_keys=['fermibubbles_50TeV', 'pi0'], testing_keys=['pi0', 'kra5', 'kra50', 'snr', 'pwn', 'unid', 'fermibubbles_50TeV'])\n",
    "fig.savefig('{}/model_confusion_fermibubbles.png'.format(plot_dir))\n",
    "\n",
    "fig = plot_model_confusion(inj_keys=['pi0', 'kra5', 'kra50'], testing_keys=['pi0', 'kra5', 'kra50', 'snr', 'pwn', 'unid', 'fermibubbles_50TeV'])\n",
    "fig.savefig('{}/model_confusion_gp_inj.png'.format(plot_dir))\n",
    "\n",
    "fig = plot_model_confusion(inj_keys=['pi0', 'kra5', 'kra50'], testing_keys=['snr', 'pwn', 'unid'])\n",
    "fig.savefig('{}/model_confusion_stacking.png'.format(plot_dir))\n",
    "\n",
    "fig = plot_model_confusion(inj_keys=['pi0', 'kra5', 'kra50'], testing_keys=list(tr_dict.keys()))\n",
    "fig.savefig('{}/model_confusion_stacking_all.png'.format(plot_dir))\n",
    "\n",
    "fig = plot_model_confusion(inj_keys=['snr', 'pwn', 'unid'], testing_keys=['pi0', 'kra5', 'kra50'])\n",
    "fig.savefig('{}/model_confusion_stacking__stacking.png'.format(plot_dir))\n",
    "\n",
    "fig = plot_model_confusion(inj_keys=['snr', 'pwn', 'unid'], testing_keys=list(tr_dict.keys()))\n",
    "fig.savefig('{}/model_confusion_stacking__stacking_all.png'.format(plot_dir))\n",
    "\n",
    "fig = plot_model_confusion(inj_keys=['snr', 'pwn', 'unid'], testing_keys=['snr', 'pwn', 'unid'])\n",
    "fig.savefig('{}/model_confusion_stacking__stacking_confusion.png'.format(plot_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-money",
   "metadata": {},
   "source": [
    "#### Plot matrix of median values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patheffects as pe\n",
    "\n",
    "def get_median_sigma_matrix(model_keys=list(tr_dict.keys())):\n",
    "    n_keys = len(model_keys)\n",
    "    matrix_diff = np.zeros((n_keys, n_keys))\n",
    "\n",
    "    for i, key_inj in enumerate(model_keys):\n",
    "        for j, key in enumerate(model_keys):\n",
    "\n",
    "            sigmas = sigma_dict[(key_inj, key)]\n",
    "            if not np.isfinite(sigmas).all():\n",
    "                raise ValueError(sigmas)\n",
    "\n",
    "            if key in ['pi0', 'kra5', 'kra50', 'fermibubbles_50TeV']:\n",
    "                unblinded_sigma = res_dict[key][3]\n",
    "            elif key in ['snr', 'pwn', 'unid']:\n",
    "                unblinded_sigma = res_dict[key][5]\n",
    "            elif 'sigma' in res_dict[key]:\n",
    "                unblinded_sigma = res_dict[key]['sigma']\n",
    "            else:\n",
    "                unblinded_sigma = np.nan\n",
    "            \n",
    "            sigma_diff = unblinded_sigma - np.median(sigmas)\n",
    "            matrix_diff[i, j] = sigma_diff\n",
    "    return matrix_diff, model_keys\n",
    "\n",
    "def plot_sigma_matrix(\n",
    "            matrix, model_keys,\n",
    "            bound=2,\n",
    "            name_converter={}, value_str=r'{:+.1f}$\\sigma$',\n",
    "            cmap=plt.cm.RdBu,\n",
    "        ):\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "    model_names = [name_converter.get(m, m) for m in model_keys]\n",
    "\n",
    "    # extract all colors from the .jet map\n",
    "    cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "    # force the first color entry to be grey\n",
    "    # cmaplist[0] = (.5, .5, .5, 1.0)\n",
    "\n",
    "    # create the new map\n",
    "    cmap = mpl.colors.LinearSegmentedColormap.from_list(\n",
    "        'Custom cmap', cmaplist, cmap.N)\n",
    "\n",
    "    # define the bins and normalize\n",
    "    bounds = np.linspace(-bound, bound, 50)\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "    image = ax.imshow(matrix, interpolation='none', norm=norm, cmap=cmap)\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(len(model_keys)):\n",
    "        for j in range(len(model_keys)):\n",
    "            color_float = np.clip(np.abs(matrix[i, j])/ (bound), 0, 1.)\n",
    "            color_float = (color_float - 0.5)**0.1 + 0.5\n",
    "            color_float =  np.clip(color_float, 0., 1.)\n",
    "            if not np.isfinite(color_float):\n",
    "                color_float = 0.\n",
    "\n",
    "            color = '{:.2f}'.format(color_float)\n",
    "            text = ax.text(\n",
    "                j, i, value_str.format(matrix[i, j]),\n",
    "                ha=\"center\", va=\"center\", color=color, fontsize=7,\n",
    "            )\n",
    "\n",
    "    cbar = plt.colorbar(image, ax=ax)\n",
    "    cbar.set_label(\n",
    "        r'$\\Delta \\sigma = \\sigma_\\mathrm{unblinded} - \\sigma_{50\\%}$')\n",
    "    plt.xticks(range(len(model_keys)), model_names, fontsize=8, rotation=90)\n",
    "    plt.yticks(range(len(model_keys)), model_names, fontsize=8)\n",
    "    ax.set_xlabel('Tested Model')\n",
    "    ax.set_ylabel('Injected Model')\n",
    "    return fig, ax, cbar\n",
    "\n",
    "name_converter = {\n",
    "    'fermibubbles_50TeV': r'FB$_{50}$',\n",
    "    'pi0': r'$\\pi^0$',\n",
    "    'kra5': r'KRA$_\\gamma^{5}$',\n",
    "    'kra50': r'KRA$_\\gamma^{50}$',\n",
    "    'snr': r'SNR',\n",
    "    'pwn': r'PWN',\n",
    "    'unid': r'UNID',\n",
    "    'combined_stacking': r'All S.',\n",
    "}\n",
    "\n",
    "chosen_models = ['fermibubbles_50TeV', 'pi0', 'kra5', 'kra50', 'snr', 'pwn', 'unid', 'combined_stacking']\n",
    "chosen_models = ['fermibubbles_50TeV', 'pi0', 'kra5', 'kra50', 'snr', 'pwn', 'unid']\n",
    "matrix, model_keys = get_median_sigma_matrix(model_keys=chosen_models)\n",
    "fig, ax, cbar = plot_sigma_matrix(matrix, model_keys=model_keys, name_converter=name_converter)\n",
    "#ax.set_title('Model Confusion Test')\n",
    "fig.tight_layout()\n",
    "fig.savefig('{}/model_confusion_matrix.png'.format(plot_dir))\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-conspiracy",
   "metadata": {},
   "source": [
    "#### Plot P-value Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pval_matrix(model_keys=list(tr_dict.keys())):\n",
    "    n_keys = len(model_keys)\n",
    "    matrix_diff = np.zeros((n_keys, n_keys))\n",
    "\n",
    "    for i, key_inj in enumerate(model_keys):\n",
    "        for j, key in enumerate(model_keys):\n",
    "\n",
    "            sigmas = sigma_dict[(key_inj, key)]\n",
    "            if not np.isfinite(sigmas).all():\n",
    "                raise ValueError(sigmas)\n",
    "\n",
    "            if key in ['pi0', 'kra5', 'kra50', 'fermibubbles_50TeV']:\n",
    "                unblinded_sigma = res_dict[key][3]\n",
    "            elif key in ['snr', 'pwn', 'unid']:\n",
    "                unblinded_sigma = res_dict[key][5]\n",
    "            elif 'sigma' in res_dict[key]:\n",
    "                unblinded_sigma = res_dict[key]['sigma']\n",
    "            else:\n",
    "                unblinded_sigma = np.nan\n",
    "            \n",
    "            # do 2-sided test here:\n",
    "            sorted_sigmas = np.sort(sigmas)\n",
    "            idx = np.searchsorted(np.sort(sigmas), unblinded_sigma)\n",
    "            fraction = float(idx)/len(sigmas)\n",
    "            if fraction < 0.5:\n",
    "                pval = 2 * fraction\n",
    "            else:\n",
    "                pval = 2 * (1 - fraction)\n",
    "            matrix_diff[i, j] = pval\n",
    "    return matrix_diff, model_keys\n",
    "\n",
    "def plot_matrix_pval(\n",
    "            matrix, model_keys,\n",
    "            bound=-1.0,\n",
    "            name_converter={},\n",
    "            value_str=r'{:.3f}',\n",
    "            lower_bound=0.001,\n",
    "            cmap=plt.cm.cividis_r,\n",
    "        ):\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "    model_names = [name_converter.get(m, m) for m in model_keys]\n",
    "\n",
    "    # extract all colors from the .jet map\n",
    "    cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "    # force the first color entry to be grey\n",
    "    # cmaplist[0] = (.5, .5, .5, 1.0)\n",
    "\n",
    "    # create the new map\n",
    "    cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\n",
    "        'Custom cmap', cmaplist, cmap.N)\n",
    "\n",
    "    # define the bins and normalize\n",
    "    bounds = np.logspace(bound, 0., 11)\n",
    "    norm = matplotlib.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "    image = ax.imshow(matrix, interpolation='none', norm=norm, cmap=cmap)\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(len(model_keys)):\n",
    "        for j in range(len(model_keys)):\n",
    "            color_float = np.clip(np.abs(matrix[i, j])/ (bound), 0, 1.)\n",
    "            color_float = (color_float - 0.5)**0.1 + 0.5\n",
    "            color_float = np.clip(color_float, 0., 1.)\n",
    "            if not np.isfinite(color_float):\n",
    "                color_float = 1.\n",
    "\n",
    "            if matrix[i, j] < lower_bound*150:\n",
    "                color_float = 0.\n",
    "\n",
    "            if matrix[i, j] < lower_bound:\n",
    "                text = '<' + value_str.format(lower_bound)\n",
    "            else:\n",
    "                text = value_str.format(matrix[i, j])\n",
    "\n",
    "            color = '{:.2f}'.format(color_float)\n",
    "            text = ax.text(\n",
    "                j, i, text,\n",
    "                ha=\"center\", va=\"center\", color=color, fontsize=7,\n",
    "                #path_effects=[pe.Stroke(linewidth=2, foreground='0.'), pe.Normal()],\n",
    "            )\n",
    "\n",
    "    cbar = plt.colorbar(image, ax=ax)\n",
    "    cbar.set_label(r'P-value')\n",
    "    plt.xticks(range(len(model_keys)), model_names, fontsize=8, rotation=90)\n",
    "    plt.yticks(range(len(model_keys)), model_names, fontsize=8)\n",
    "    ax.set_xlabel('Tested Model')\n",
    "    ax.set_ylabel('Injected Model')\n",
    "    return fig, ax, cbar\n",
    "\n",
    "chosen_models = ['fermibubbles_50TeV', 'pi0', 'kra5', 'kra50', 'snr', 'pwn', 'unid', 'combined_stacking']\n",
    "chosen_models = ['fermibubbles_50TeV', 'pi0', 'kra5', 'kra50', 'snr', 'pwn', 'unid']\n",
    "matrix_pval, model_keys_pval = get_pval_matrix(model_keys=chosen_models)\n",
    "fig, ax, cbar = plot_matrix_pval(\n",
    "    matrix_pval, \n",
    "    model_keys=model_keys_pval, \n",
    "    name_converter=name_converter,\n",
    ")\n",
    "\n",
    "#ax.set_title('Model Confusion Test')\n",
    "fig.tight_layout()\n",
    "fig.savefig('{}/model_confusion_matrix_pval.png'.format(plot_dir))\n",
    "matrix_pval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-trust",
   "metadata": {},
   "source": [
    "## Plot NS Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-symposium",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_poisson = True\n",
    "if use_poisson:\n",
    "    allt_i_dict_file = os.path.join(plot_dir, 'allt_i_dict_poisson.pkl')\n",
    "else:\n",
    "    allt_i_dict_file = os.path.join(plot_dir, 'allt_i_dict.pkl')\n",
    "\n",
    "if os.path.exists(allt_i_dict_file):\n",
    "    print('Loading from file')\n",
    "    with open(allt_i_dict_file, 'rb') as handle:\n",
    "        allt_i_dict = pickle.load(handle)\n",
    "else:\n",
    "    print('Creating new dict')\n",
    "    allt_i_dict = {}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-swing",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_bias_plot_keys = ['fermibubbles_50TeV']\n",
    "ntrials = 200\n",
    "recalculate = True\n",
    "\n",
    "for key in ns_bias_plot_keys:\n",
    "    if key not in allt_i_dict or recalculate:\n",
    "        ns = int(ns_dict[key])\n",
    "        max_diff = max(100, int(ns_dict[key] * 1.))\n",
    "        trial_runner = tr_dict[key]\n",
    "\n",
    "        n_sigs = np.sort(\n",
    "            np.r_[np.clip(ns - max_diff, 0., np.inf): ns + max_diff:5],\n",
    "        ).astype(int)\n",
    "        print('Submitting {} values for {} from {} +- {}'.format(len(n_sigs), key, ns, max_diff))\n",
    "\n",
    "        allt_i = get_bias_allt(\n",
    "            trial_runner, ntrials=ntrials, n_sigs=n_sigs, poisson=use_poisson)\n",
    "\n",
    "        allt_i_dict[key] = allt_i\n",
    "\n",
    "with open(allt_i_dict_file, 'wb') as f:\n",
    "    pickle.dump(allt_i_dict, f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-frame",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, allt_i in allt_i_dict.items():\n",
    "    \n",
    "    trial_runner = tr_dict[key]\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    plot_ns_bias(ax, trial_runner, allt_i, label=None)\n",
    "    \n",
    "    ax.axhline(\n",
    "        res_dict[key][1], \n",
    "        ls='--',\n",
    "        label='Unblinded ns: {:3.3f}'.format(res_dict[key][1]),\n",
    "    )\n",
    "    ax.set(title=r'Analysis: {}'.format(key))\n",
    "    ax.legend(fontsize=8)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('{}/bias_{}.png'.format(plot_dir, key))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, allt_i in allt_i_dict.items():\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(9, 6))\n",
    "    \n",
    "    max_diff = 2\n",
    "    mask = np.abs(allt_i.ns - res_dict[key][1]) < max_diff\n",
    "    median_ntrue = np.median(allt_i.ntrue[mask])\n",
    "    mean_ntrue = np.mean(allt_i.ntrue[mask])\n",
    "    std_ntrue = np.std(allt_i.ntrue[mask])\n",
    "    ax.hist(\n",
    "        allt_i.ntrue[mask], color=soft_colors[0], \n",
    "        label=r'$P(n_\\mathrm{inj}$' + r' | ns = {:3.1f} $\\pm$ {:3.1f})'.format(\n",
    "            res_dict[key][1], max_diff),\n",
    "        density=True, bins=15,\n",
    "    )\n",
    "    \n",
    "    ax.axvline(\n",
    "        median_ntrue, color='0.7', ls='--',\n",
    "        label='Median $n_\\mathrm{inj}$' + ': {:3.1f}'.format(median_ntrue),\n",
    "    )\n",
    "    \n",
    "    ax.axvline(\n",
    "        res_dict[key][1], color=soft_colors[1], ls='--',\n",
    "        label='Unblinded ns: {:3.1f}'.format(res_dict[key][1]),\n",
    "    )\n",
    "    ax.set(title=r'Analysis: {}'.format(key) + ' | $n_\\mathrm{inj}$' + '(ns={:3.1f}) = {:3.1f} $\\pm$ {:3.1f} [$\\mu \\pm \\sigma$ ]'.format(\n",
    "        res_dict[key][1], mean_ntrue, std_ntrue))\n",
    "    ax.set_xlabel('True $n_\\mathrm{inj}$')\n",
    "    ax.set_ylabel('PDF')\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('{}/bias_at_unblinded_ns_{}.png'.format(plot_dir, key))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-quarter",
   "metadata": {},
   "source": [
    "# Scratch Area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-decline",
   "metadata": {},
   "source": [
    "#### Compute bkg trial significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-smell",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val_dict_bkg = {}\n",
    "sigma_dict_bkg = {}\n",
    "max_n = 10000000\n",
    "for key, bg in bkg_dict.items():\n",
    "    print('key:', key)\n",
    "    bg_tsd = cy.dists.TSD(bg[:max_n])\n",
    "    p_val_dict_bkg[key] = bg_tsd.sf(bg[:max_n])\n",
    "    sigma_dict_bkg[key] = bg_tsd.sf_nsigma(bg[:max_n])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-gallery",
   "metadata": {},
   "source": [
    "#### Plot Trial Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(bkg_dict['snr'][:max_n])\n",
    "sigma_threshold = -10.5\n",
    "\n",
    "for key, tr in sigma_dict_bkg.items():\n",
    "\n",
    "    mask = np.logical_or(mask, sigma_dict_bkg[key] > sigma_threshold)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-darwin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "def plot_corr_ax(ax, key1, key2, mask=None, norm=None):\n",
    "    \n",
    "    if mask is None:\n",
    "        mask = np.ones_like(sigma_dict_bkg[key1], dtype=bool)\n",
    "        \n",
    "    ax.hist2d(\n",
    "        sigma_dict_bkg[key1][mask], sigma_dict_bkg[key2][mask],\n",
    "        bins=bins, norm=norm, cmin=1,\n",
    "    )\n",
    "    ax.plot(\n",
    "        (bins[0][0], bins[0][-1]), (bins[0][0], bins[0][-1]), \n",
    "        ls='--', color='0.7', lw=3,\n",
    "    )\n",
    "    ax.set_xlabel('$n\\cdot \\sigma$ of {}'.format(key1))\n",
    "    ax.set_ylabel('$n\\cdot \\sigma$ of {}'.format(key2))\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(9, 9))\n",
    "\n",
    "bins = (np.linspace(0, 6), np.linspace(0, 6))\n",
    "\n",
    "mask = None\n",
    "plot_corr_ax(axes[0], 'snr', 'pwn', mask=mask)\n",
    "plot_corr_ax(axes[1], 'snr', 'unid', mask=mask)\n",
    "plot_corr_ax(axes[2], 'unid', 'pwn', mask=mask)\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-swimming",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "corr_keys = ['snr', 'pwn', 'unid']\n",
    "corr_keys = ['pi0', 'kra5', 'kra50']\n",
    "#corr_keys = ['pi0', 'kra5', 'kra50', 'snr', 'pwn', 'unid']\n",
    "\n",
    "max_nsigma = np.max(\n",
    "    np.stack([sigma_dict_bkg[k] for k in corr_keys]),\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "bg_max = cy.dists.TSD(max_nsigma)\n",
    "bins = np.linspace(0, 6, 100)\n",
    "fig, ax = plot_bkg_trials(bg_max, bins=bins, color=soft_colors[1])\n",
    "ax.hist(max_nsigma, bins=bins)\n",
    "ax.set_xlabel('Max n-sigma')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "nsigma_chosen = 4.705\n",
    "pval_chosen = stats.norm.sf(nsigma_chosen)\n",
    "nsigma_corrected = bg_max.sf_nsigma(nsigma_chosen)\n",
    "\n",
    "pval_corrected = bg_max.sf(nsigma_chosen)\n",
    "print('Correcting for: {}'.format(corr_keys))\n",
    "print('Pre-trial N-sigma of: {}'.format(nsigma_chosen))\n",
    "print('Post-trial correlated: {} | factor: {}'.format(nsigma_corrected, pval_corrected/pval_chosen))\n",
    "print('Post-trial conservative: {} | factor: {}'.format(stats.norm.isf(pval_chosen * len(corr_keys)), len(corr_keys)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-sympathy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2.3_py3-v4.1.0_csky",
   "language": "python",
   "name": "tensorflow2.3_py3-v4.1.0_csky"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

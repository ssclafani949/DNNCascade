{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "# set env flags to catch BLAS used for scipy/numpy \n",
    "# to only use 1 cpu, n_cpus will be totally controlled by csky\n",
    "if False:\n",
    "    os.environ['MKL_NUM_THREADS'] = \"1\"\n",
    "    os.environ['NUMEXPR_NUM_THREADS'] = \"1\"\n",
    "    os.environ['OMP_NUM_THREADS'] = \"1\"\n",
    "    os.environ['OPENBLAS_NUM_THREADS'] = \"1\"\n",
    "    os.environ['VECLIB_MAXIMUM_THREADS'] = \"1\"\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.facecolor'] = 'w'\n",
    "mpl.rcParams['savefig.facecolor'] = 'w'\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors, cm\n",
    "import csky as cy\n",
    "from csky import cext\n",
    "import numpy as np\n",
    "import astropy\n",
    "#from icecube import astro\n",
    "import histlite as hl\n",
    "import healpy\n",
    "import healpy as hp\n",
    "import socket\n",
    "import pickle\n",
    "from scipy import stats\n",
    "import copy\n",
    "healpy.disable_warnings()\n",
    "plt.rc('figure', facecolor = 'w')\n",
    "plt.rc('figure', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-nevada",
   "metadata": {},
   "source": [
    "## Define Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-replica",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_version = 'version-001-p00'\n",
    "\n",
    "host_name = socket.gethostname()\n",
    "\n",
    "if 'cobalt' in host_name:\n",
    "    print('Working on Cobalts')\n",
    "    #data_prefix = '/data/user/ssclafani/data/cscd/final'\n",
    "    #ana_dir = '/data/user/ssclafani/data/analyses/'\n",
    "    plot_dir = cy.utils.ensure_dir('/data/user/mhuennefeld/data/analyses/DNNCascadeCodeReview/unblinding_checks/plots/unblinding/galactic_latitude_hist')\n",
    "    \n",
    "else:\n",
    "    raise ValueError('Unknown host:', host_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir_path in [plot_dir]:\n",
    "    if not os.path.exists(dir_path):\n",
    "        print('Creating directory:', dir_path)\n",
    "        os.makedirs(dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-mystery",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-plate",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = cy.selections.Repository()\n",
    "specs = cy.selections.DNNCascadeDataSpecs.DNNC_10yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-retail",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ana = cy.get_analysis(\n",
    "    repo, selection_version, specs, \n",
    "    #gammas=np.r_[0.1:6.01:0.125],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ana.anas[0]\n",
    "a.sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.bg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-decade",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-closing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cycler import cycle\n",
    "from copy import deepcopy\n",
    "\n",
    "soft_colors = cy.plotting.soft_colors\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "\n",
    "def get_bias_allt(tr, ntrials=200, n_sigs=np.r_[:101:10], quiet=False):\n",
    "    trials = [\n",
    "        (None if quiet else print(f'\\r{n_sig:4d} ...', end='', flush=True))\n",
    "        or\n",
    "        tr.get_many_fits(ntrials, n_sig=n_sig, logging=False, seed=n_sig)\n",
    "        for n_sig in n_sigs]\n",
    "    if not quiet:\n",
    "        print()\n",
    "    for (n_sig, t) in zip(n_sigs, trials):\n",
    "        t['ntrue'] = np.repeat(n_sig, len(t))\n",
    "    allt = cy.utils.Arrays.concatenate(trials)\n",
    "    return allt\n",
    "\n",
    "def get_color_cycler():\n",
    "    return cycle(colors)\n",
    "\n",
    "def plot_ns_bias(ax, tr, allt, label=''):\n",
    "\n",
    "    n_sigs = np.unique(allt.ntrue)\n",
    "    dns = np.mean(np.diff(n_sigs))\n",
    "    ns_bins = np.r_[n_sigs - 0.5*dns, n_sigs[-1] + 0.5*dns]\n",
    "    expect_kw = dict(color='C0', ls='--', lw=1, zorder=-10)\n",
    "\n",
    "    h = hl.hist((allt.ntrue, allt.ns), bins=(ns_bins, 100))\n",
    "    hl.plot1d(ax, h.contain_project(1),errorbands=True, \n",
    "              drawstyle='default', label=label)\n",
    "    lim = ns_bins[[0, -1]]\n",
    "    ax.set_xlim(ax.set_ylim(lim))\n",
    "    ax.plot(lim, lim, **expect_kw)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    ax.set_xlabel(r'$n_{inj}$')\n",
    "    ax.set_ylabel(r'$n_s$')\n",
    "    ax.grid()\n",
    "\n",
    "def plot_gamma_bias(ax, tr, allt, label=''):\n",
    "\n",
    "    n_sigs = np.unique(allt.ntrue)\n",
    "    dns = np.mean(np.diff(n_sigs))\n",
    "    ns_bins = np.r_[n_sigs - 0.5*dns, n_sigs[-1] + 0.5*dns]\n",
    "    expect_kw = dict(color='C0', ls='--', lw=1, zorder=-10)\n",
    "    expect_gamma = tr.sig_injs[0].flux[0].gamma\n",
    "\n",
    "    h = hl.hist((allt.ntrue, allt.gamma), bins=(ns_bins, 100))\n",
    "    hl.plot1d(ax, h.contain_project(1),errorbands=True, \n",
    "              drawstyle='default', label=label)\n",
    "    lim = ns_bins[[0, -1]]\n",
    "    ax.set_xlim(lim)\n",
    "    ax.set_ylim(1, 4)\n",
    "    ax.axhline(expect_gamma, **expect_kw)\n",
    "\n",
    "    ax.set_xlabel(r'$n_{inj}$')\n",
    "    ax.set_ylabel(r'$\\gamma$')\n",
    "    ax.grid()\n",
    "\n",
    "def plot_bkg_trials(\n",
    "            bg, fig=None, ax=None, \n",
    "            label='{} bg trials', \n",
    "            label_fit=r'$\\chi^2[{:.2f}\\mathrm{{dof}},\\ \\eta={:.3f}]$', \n",
    "            color=colors[0],\n",
    "            density=False,\n",
    "            bins=50,\n",
    "        ):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    \n",
    "    if density:\n",
    "        h = bg.get_hist(bins=bins).normalize(density=True)\n",
    "    else:\n",
    "        h = bg.get_hist(bins=bins)\n",
    "    if label is not None:\n",
    "        label = label.format(bg.n_total)\n",
    "    hl.plot1d(ax, h, crosses=True, color=color, label=label)\n",
    "\n",
    "    # compare with the chi2 fit:\n",
    "    if hasattr(bg, 'pdf'):\n",
    "        x = h.centers[0]\n",
    "        norm = h.integrate().values\n",
    "        if label_fit is not None:\n",
    "            label_fit = label_fit.format(bg.ndof, bg.eta)\n",
    "        if density:\n",
    "            ax.semilogy(x, bg.pdf(x), lw=1, ls='--', label=label_fit, color=color)\n",
    "        else:\n",
    "            ax.semilogy(x, norm * bg.pdf(x), lw=1, ls='--', label=label_fit, color=color)\n",
    "\n",
    "    ax.set_xlabel(r'TS')\n",
    "    if density:\n",
    "        ax.set_ylabel(r'Density')\n",
    "    else:\n",
    "        ax.set_ylabel(r'number of trials')\n",
    "    ax.legend()\n",
    "        \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-criterion",
   "metadata": {},
   "source": [
    "##### Helpers for event injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flux(tr):\n",
    "    for key, item in tr.llh_kw['conf'].items():\n",
    "        if 'flux' == key:\n",
    "            return item\n",
    "        if isinstance(item, dict):\n",
    "            for key_sub, item_sub in item.items():\n",
    "                if key_sub == 'flux':\n",
    "                    return item_sub\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_injected_events(tr, n_sig, seed=None):\n",
    "    injector = tr.sig_injs[0]\n",
    "    original_keep = [k for k in injector.keep]\n",
    "    if 'energy' not in injector.keep:\n",
    "        injector.keep += ['energy']\n",
    "    if 'true_energy' not in injector.keep:\n",
    "        injector.keep += ['true_energy']\n",
    "    injected_events = injector.inject(n_sig, seed=seed)[0][0]\n",
    "    injector.keep = original_keep\n",
    "    return injected_events\n",
    "    \n",
    "def get_bkg_events(tr, seed=None):\n",
    "    randomizer = tr.bg_injs[0].randomizers[0]\n",
    "    bg_data_cpy = cy.utils.Events(a.bg_data)\n",
    "    randomizer(bg_data_cpy, seed=seed)\n",
    "    return bg_data_cpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-bridges",
   "metadata": {},
   "source": [
    "## Setup Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-notebook",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "import config as cg\n",
    "\n",
    "cg.base_dir = '/data/user/mhuennefeld/data/analyses/unblinding_v1.0.0/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gp_tr(template_str, cutoff=np.inf, gamma=None, ana=ana, cpus=20):\n",
    "    cutoff_GeV = cutoff * 1e3\n",
    "    gp_conf = cg.get_gp_conf(\n",
    "        template_str=template_str, gamma=gamma, \n",
    "        cutoff_GeV=cutoff_GeV, base_dir=cg.base_dir)\n",
    "    \n",
    "    if template_str == 'pi0' and cutoff != np.inf or ana.keys != ['DNNCascade_10yr']:\n",
    "        print('Removing dir!', cutoff)\n",
    "        gp_conf.pop('dir')\n",
    "\n",
    "    tr = cy.get_trial_runner(gp_conf, ana=ana, mp_cpus=cpus)\n",
    "    return tr\n",
    "\n",
    "def get_template_tr(template, gamma=2.7, cutoff_tev=np.inf, cpus=20):\n",
    "    cutoff_gev = cutoff_tev * 1000.\n",
    "    gp_conf = {\n",
    "        'template': template,\n",
    "        'flux': cy.hyp.PowerLawFlux(gamma, energy_cutoff=cutoff_gev),\n",
    "        'randomize': ['ra'],\n",
    "        'fitter_args': dict(gamma=gamma),\n",
    "        'sigsub': True,\n",
    "        'update_bg': True,\n",
    "        'fast_weight': False,\n",
    "    }\n",
    "    tr = cy.get_trial_runner(gp_conf, ana=ana, mp_cpus=cpus)\n",
    "    return tr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-tutorial",
   "metadata": {},
   "source": [
    "#### Get TrialRunners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dict = {\n",
    "    'pi0': get_gp_tr('pi0'),\n",
    "    'kra5': get_gp_tr('kra5'),\n",
    "    'kra50': get_gp_tr('kra50'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-matter",
   "metadata": {},
   "source": [
    "#### Get Results for each template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-creator",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = {}\n",
    "for key in tr_dict.keys():\n",
    "    f_path = os.path.join(\n",
    "        cg.base_dir, \n",
    "        'gp/results/{}/{}_unblinded.npy'.format(key, key), \n",
    "    )\n",
    "    if os.path.exists(f_path):\n",
    "        res_dict[key] = np.load(f_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_dict = {\n",
    "    'pi0': 748.11,\n",
    "    'pi0_lowE': 623.67,\n",
    "    'kra5': 273.24,\n",
    "    'kra50': 208.95,\n",
    "    'snr': 218.45,\n",
    "    'pwn': 279.61,\n",
    "    'unid': 237.90,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-cleveland",
   "metadata": {},
   "source": [
    "#### Helper functions for projection on Galactic Latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "\n",
    "def ra_dec_to_lon_lat(ra, dec, unit='rad'):\n",
    "    c_icrs = SkyCoord(ra=ra, dec=dec, unit=unit, frame='icrs')\n",
    "    c_gal = c_icrs.galactic\n",
    "    return c_gal.data.lon.rad, c_gal.data.lat.rad\n",
    "\n",
    " \n",
    "#np.rad2deg(ra_dec_to_lon_lat(np.deg2rad([083.63308, 266.41500889]), np.deg2rad([22.01450, -29.00611111])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csky import cext\n",
    "from scipy.integrate import quad\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "def compute_dec_pdf(src_decs, ev_decs, ev_sigmas):\n",
    "    \n",
    "    src_decs = np.atleast_1d(src_decs)\n",
    "    \n",
    "    sigsub = True\n",
    "    kent_min = 0.\n",
    "    cut_pdf_threshold = -1\n",
    "    cut_n_sigma = float('inf')\n",
    "    ev_ras = np.zeros_like(ev_decs)\n",
    "    src_ras = np.zeros_like(src_decs)\n",
    "    src_exts = np.zeros_like(src_decs)\n",
    "    \n",
    "    sig_data, sigsub_data, row, column = cext.kent_1D_space_pdf(\n",
    "        ev_decs, ev_ras, ev_sigmas, src_decs, src_ras, src_exts, \n",
    "        sigsub, cut_n_sigma, cut_pdf_threshold, kent_min,\n",
    "    )\n",
    "    return sigsub_data.reshape([-1, len(src_decs)]) * 2*np.pi * np.cos(src_decs)\n",
    "\n",
    "def compute_dec_cdf(src_dec_min, src_dec_max, ev_decs, ev_sigmas, n_points=100):\n",
    "    \n",
    "    bins_src_decs = np.linspace(src_dec_min, src_dec_max, 100)\n",
    "    src_dec_width = np.diff(bins_src_decs)[0]\n",
    "    assert np.allclose(np.diff(bins_src_decs), src_dec_width)\n",
    "\n",
    "    src_decs = bins_src_decs[:-1] + 0.5 * src_dec_width\n",
    "\n",
    "    res = compute_dec_pdf(src_decs, ev_decs=ev_decs, ev_sigmas=ev_sigmas)\n",
    "    return np.sum(res, axis=1) * src_dec_width\n",
    "\n",
    "def compute_abs_dec_bin_contribution(ev_decs, ev_sigmas, abs_dec_bins):\n",
    "    n_bins = len(abs_dec_bins) - 1\n",
    "    bin_contribution = np.empty((len(ev_decs), n_bins))\n",
    "    \n",
    "    for i in tqdm(range(n_bins), total=n_bins):\n",
    "        \n",
    "        # positive dec range\n",
    "        bin_contribution[:, i] = compute_dec_cdf(\n",
    "            src_dec_min=abs_dec_bins[i], \n",
    "            src_dec_max=abs_dec_bins[i+1], \n",
    "            ev_decs=ev_decs, \n",
    "            ev_sigmas=ev_sigmas,\n",
    "        )\n",
    "        \n",
    "        # negative dec range\n",
    "        bin_contribution[:, i] += compute_dec_cdf(\n",
    "            src_dec_min=-abs_dec_bins[i+1], \n",
    "            src_dec_max=-abs_dec_bins[i], \n",
    "            ev_decs=ev_decs, \n",
    "            ev_sigmas=ev_sigmas,\n",
    "        )\n",
    "    \n",
    "    return bin_contribution\n",
    "\n",
    "dec_min = -np.pi/2.\n",
    "dec_max = np.pi/2.\n",
    "ev_decs = [-0.1]\n",
    "ev_sigmas = [0.1]\n",
    "print('Discrete', compute_dec_cdf(dec_min, dec_max, ev_decs=ev_decs, ev_sigmas=ev_sigmas))\n",
    "print('Quad', quad(compute_dec_pdf, dec_min, dec_max, args=(ev_decs, ev_sigmas)))\n",
    "bin_contribution = compute_abs_dec_bin_contribution(ev_decs=ev_decs, ev_sigmas=ev_sigmas, abs_dec_bins=np.linspace(0, np.pi/2, 10))\n",
    "print(bin_contribution, np.sum(bin_contribution))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-census",
   "metadata": {},
   "source": [
    "#### Compute Bin contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bin_contributions(mask_func=None, n_reps=10, template_string='pi0', bins=np.linspace(0, 90, 15)):\n",
    "    bkg_events = cy.utils.Arrays.concatenate([get_bkg_events(tr=tr_dict[template_string]) for i in range(n_reps)])\n",
    "    bkg_lon, bkg_lat = ra_dec_to_lon_lat(ra=bkg_events.ra, dec=bkg_events.dec)\n",
    "\n",
    "    inj_events = get_injected_events(tr_dict[template_string], n_sig=int(ns_dict[template_string]))\n",
    "    inj_lon, inj_lat = ra_dec_to_lon_lat(ra=inj_events.ra, dec=inj_events.dec)\n",
    "\n",
    "    exp_lon, exp_lat = ra_dec_to_lon_lat(ra=a.bg_data.ra, dec=a.bg_data.dec)\n",
    "    \n",
    "    if mask_func is None:\n",
    "        mask_bkg = np.ones_like(bkg_lat, dtype=bool)\n",
    "        mask_inj = np.ones_like(inj_lat, dtype=bool)\n",
    "        mask_exp = np.ones_like(exp_lat, dtype=bool)\n",
    "    else:\n",
    "        mask_bkg = mask_func(bkg_events)\n",
    "        mask_inj = mask_func(inj_events)\n",
    "        mask_exp = mask_func(a.bg_data)\n",
    "        \n",
    "    bkg_events_m = bkg_events[mask_bkg]\n",
    "    inj_events_m = inj_events[mask_inj]\n",
    "    exp_events_m = a.bg_data[mask_exp]\n",
    "        \n",
    "    bkg_weights = np.ones_like(bkg_lat[mask_bkg]) / n_reps\n",
    "    \n",
    "    plot_bkg = np.rad2deg(np.abs(bkg_lat[mask_bkg]))\n",
    "    plot_inj = np.rad2deg(np.abs(inj_lat[mask_inj]))\n",
    "    plot_exp = np.rad2deg(np.abs(exp_lat[mask_exp]))\n",
    "    \n",
    "    bin_mids = bins[:-1] + 0.5 * np.diff(bins)\n",
    "    bin_width = np.diff(bins)[0]\n",
    "    assert np.allclose(np.diff(bins), bin_width)\n",
    "        \n",
    "    hist_bkg, _ = np.histogram(plot_bkg, bins=bins, weights=bkg_weights)\n",
    "    hist_inj, _ = np.histogram(plot_inj, bins=bins)\n",
    "    hist_exp, _ = np.histogram(plot_exp, bins=bins)\n",
    "    \n",
    "    # compute contribution to bins\n",
    "    bin_prob_bkg = compute_abs_dec_bin_contribution(\n",
    "        ev_decs=bkg_lat[mask_bkg], ev_sigmas=bkg_events_m.sigma, abs_dec_bins=np.deg2rad(bins))\n",
    "    bin_prob_inj = compute_abs_dec_bin_contribution(\n",
    "        ev_decs=inj_lat[mask_inj], ev_sigmas=inj_events_m.sigma, abs_dec_bins=np.deg2rad(bins))\n",
    "    bin_prob_exp = compute_abs_dec_bin_contribution(\n",
    "        ev_decs=exp_lat[mask_exp], ev_sigmas=exp_events_m.sigma, abs_dec_bins=np.deg2rad(bins))\n",
    "    \n",
    "    hist_prob_bkg = np.sum(bin_prob_bkg, axis=0) / float(n_reps)\n",
    "    hist_prob_inj = np.sum(bin_prob_inj, axis=0)\n",
    "    hist_prob_exp = np.sum(bin_prob_exp, axis=0)\n",
    "    print('bin_prob_inj', bin_prob_inj.shape)\n",
    "    print('bin_prob_exp', bin_prob_exp.shape)\n",
    "    \n",
    "    sig_fraction = np.sum(hist_inj) / np.sum(hist_bkg)\n",
    "    print('sig_fraction', sig_fraction, np.sum(hist_prob_inj) / np.sum(hist_prob_bkg))\n",
    "    hist_combined = hist_bkg * (1. - sig_fraction) + hist_inj\n",
    "    hist_prob_combined = hist_prob_bkg * (1. - sig_fraction) + hist_prob_inj\n",
    "    \n",
    "    bin_contributions = {\n",
    "        'bins': bins,\n",
    "        'n_reps': n_reps,\n",
    "        \n",
    "        'bkg_events_m': bkg_events_m,\n",
    "        'inj_events_m': inj_events_m,\n",
    "        \n",
    "        'plot_bkg': plot_bkg,\n",
    "        'plot_inj': plot_inj,\n",
    "        'plot_exp': plot_exp,\n",
    "        'bin_prob_bkg': bin_prob_bkg,\n",
    "        'bin_prob_inj': bin_prob_inj,\n",
    "        'bin_prob_exp': bin_prob_exp,\n",
    "        \n",
    "        'hist_bkg': hist_bkg,\n",
    "        'hist_inj': hist_inj,\n",
    "        'hist_exp': hist_exp,\n",
    "        'hist_combined': hist_combined,\n",
    "        'hist_prob_bkg': hist_prob_bkg,\n",
    "        'hist_prob_inj': hist_prob_inj,\n",
    "        'hist_prob_exp': hist_prob_exp,\n",
    "        'hist_prob_combined': hist_prob_combined,\n",
    "    }\n",
    "    return bin_contributions\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload = True\n",
    "\n",
    "bin_args = (0, 90, 30) # 15\n",
    "bins = np.linspace(*bin_args)\n",
    "\n",
    "bin_contributions_file = os.path.join(plot_dir, 'bin_contributions_{}_{}_{}.pkl'.format(*bin_args))\n",
    "if os.path.exists(bin_contributions_file) and reload:\n",
    "    print('Reloading data from file')\n",
    "    with open(bin_contributions_file, 'rb') as handle:\n",
    "        bin_contributions = pickle.load(handle)\n",
    "else:\n",
    "    print('Computing data')\n",
    "    bin_contributions = get_bin_contributions(n_reps=10, bins=bins)    \n",
    "    with open(bin_contributions_file, 'wb') as handle:\n",
    "        pickle.dump(bin_contributions, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-truth",
   "metadata": {},
   "source": [
    "#### Make Projection Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_projection_hist(bin_contributions, mask_func=None):\n",
    "\n",
    "    inj_events = bin_contributions['inj_events_m']\n",
    "    inj_lon, inj_lat = ra_dec_to_lon_lat(ra=inj_events.ra, dec=inj_events.dec)\n",
    "\n",
    "    bkg_events = bin_contributions['bkg_events_m']\n",
    "    bkg_lon, bkg_lat = ra_dec_to_lon_lat(ra=bkg_events.ra, dec=bkg_events.dec)\n",
    "    \n",
    "    exp_lon, exp_lat = ra_dec_to_lon_lat(ra=a.bg_data.ra, dec=a.bg_data.dec)\n",
    "    \n",
    "    if mask_func is None:\n",
    "        mask_bkg = np.ones_like(bkg_lat, dtype=bool)\n",
    "        mask_inj = np.ones_like(inj_lat, dtype=bool)\n",
    "        mask_exp = np.ones_like(exp_lat, dtype=bool)\n",
    "    else:\n",
    "        mask_bkg = mask_func(bkg_events)\n",
    "        mask_inj = mask_func(inj_events)\n",
    "        mask_exp = mask_func(a.bg_data)\n",
    "        \n",
    "    bkg_events_m = bkg_events[mask_bkg]\n",
    "    inj_events_m = inj_events[mask_inj]\n",
    "    exp_events_m = a.bg_data[mask_exp]\n",
    "        \n",
    "    n_reps = bin_contributions['n_reps']\n",
    "    bkg_weights = np.ones_like(bkg_lat[mask_bkg]) / n_reps\n",
    "    \n",
    "    plot_bkg = bin_contributions['plot_bkg'][mask_bkg]\n",
    "    plot_inj = bin_contributions['plot_inj'][mask_inj]\n",
    "    plot_exp = bin_contributions['plot_exp'][mask_exp]\n",
    "    bins = bin_contributions['bins']\n",
    "    xlabel = 'Galactic Latitude $|b|$ / Â°'\n",
    "    \n",
    "    bin_mids = bins[:-1] + 0.5 * np.diff(bins)\n",
    "    bin_width = np.diff(bins)[0]\n",
    "    assert np.allclose(np.diff(bins), bin_width)\n",
    "        \n",
    "    hist_bkg, _ = np.histogram(plot_bkg, bins=bins, weights=bkg_weights)\n",
    "    hist_inj, _ = np.histogram(plot_inj, bins=bins)\n",
    "    hist_exp, _ = np.histogram(plot_exp, bins=bins)\n",
    "    \n",
    "    # get contribution to bins\n",
    "    bin_prob_bkg = bin_contributions['bin_prob_bkg'][mask_bkg]\n",
    "    bin_prob_inj = bin_contributions['bin_prob_inj'][mask_inj]\n",
    "    bin_prob_exp = bin_contributions['bin_prob_exp'][mask_exp]\n",
    "    \n",
    "    hist_prob_bkg = np.sum(bin_prob_bkg, axis=0) / float(n_reps)\n",
    "    hist_prob_inj = np.sum(bin_prob_inj, axis=0)\n",
    "    hist_prob_exp = np.sum(bin_prob_exp, axis=0)\n",
    "    print('bin_prob_inj', bin_prob_inj.shape)\n",
    "    print('bin_prob_exp', bin_prob_exp.shape)\n",
    "    \n",
    "    \n",
    "    sig_fraction = np.sum(hist_inj) / np.sum(hist_bkg)\n",
    "    hist_combined = hist_bkg * (1. - sig_fraction) + hist_inj\n",
    "    hist_prob_combined = hist_prob_bkg * (1. - sig_fraction) + hist_prob_inj\n",
    "    \n",
    "    print('Prob-Hist normalization:', np.sum(hist_prob_exp), np.sum(hist_prob_bkg), np.sum(hist_prob_combined))\n",
    "    color_cycler = get_color_cycler()\n",
    "    color_exp = next(color_cycler)\n",
    "    color_sig = next(color_cycler)\n",
    "    color_bkg = '0.7'\n",
    "        \n",
    "    fig, axes = plt.subplots(3, 1, gridspec_kw={'height_ratios': [2, 1, 1]}, sharex=True, figsize=(9, 6))\n",
    "    ax = axes[0]\n",
    "    #ax.hist(plot_bkg, bins=bins, weights=bkg_weights, histtype='step', label='Scrambled background')\n",
    "    #ax.hist(plot_inj, bins=bins, histtype='step', label='Signal')\n",
    "    #ax.hist([plot_bkg, plot_inj], weights=[bkg_weights, np.ones_like(plot_inj)], \n",
    "    #        bins=bins, histtype='step', label=['Background', 'Signal'], stacked=True)\n",
    "    #ax.hist(plot_exp, bins=bins, histtype='step', label='Exp')\n",
    "    #ax.errorbar(bin_mids, hist_exp, yerr=np.sqrt(hist_exp), xerr=bin_width/2., label='Exp Data', fmt='.')\n",
    "    #ax.errorbar(bin_mids, hist_combined, yerr=np.sqrt(hist_combined), xerr=bin_width/2., label='MC Exp', fmt='.')\n",
    "    ax.errorbar(bin_mids, hist_prob_combined, yerr=np.sqrt(hist_prob_combined), xerr=bin_width/2., label='MC signal expectation', fmt='.', color=color_sig)\n",
    "    ax.errorbar(bin_mids, hist_prob_bkg, yerr=np.sqrt(hist_prob_bkg), xerr=bin_width/2., label='Background Scrambles', fmt='.', color=color_bkg)\n",
    "    ax.errorbar(bin_mids, hist_prob_exp, yerr=np.sqrt(hist_prob_exp), xerr=bin_width/2., label='Exp Data', fmt='.', color=color_exp)\n",
    "    ax.legend(loc='lower center')\n",
    "    \n",
    "    # ----------\n",
    "    # plot ratio\n",
    "    # ----------\n",
    "    axes[1].plot(bins, np.ones_like(bins), color=color_bkg, ls='--')\n",
    "    axes[1].plot(bin_mids, hist_prob_exp / hist_prob_bkg, color=color_exp, marker='.')\n",
    "    axes[1].plot(bin_mids, hist_prob_combined / hist_prob_bkg, color=color_sig, marker='.', ls='--')\n",
    "    \n",
    "    # ----------\n",
    "    # plot diff\n",
    "    # ----------\n",
    "    axes[2].plot(bins, np.zeros_like(bins), color=color_bkg, ls='--')\n",
    "    axes[2].plot(bin_mids, hist_prob_exp - hist_prob_bkg, color=color_exp, marker='.')\n",
    "    axes[2].plot(bin_mids, hist_prob_combined - hist_prob_bkg, color=color_sig, marker='.', ls='--')\n",
    "\n",
    "    axes[0].set_ylabel('Number of Events')\n",
    "    axes[1].set_ylabel('Ratio to Bkg')\n",
    "    axes[2].set_ylabel('Diff to Bkg')\n",
    "    \n",
    "    axes[-1].set_xlabel(xlabel)\n",
    "    axes[-1].set_xlim(bins[0], bins[-1])\n",
    "    #axes[-1].set_xlim(bins[0], 25)\n",
    "    #axes[0].set_ylim(5900, 6500)\n",
    "    return fig, axes\n",
    "\n",
    "    \n",
    "def mask_func(df):\n",
    "    lon, lat = np.rad2deg(ra_dec_to_lon_lat(ra=df.ra, dec=df.dec))\n",
    "    mask_lon = np.logical_or(\n",
    "        lon > 300,\n",
    "        lon < 210,\n",
    "    )\n",
    "    mask = np.logical_and(mask_lon, df.energy > 2000)\n",
    "    #mask = np.logical_and(mask_lon, df.energy < 20000)\n",
    "    mask = df.energy > -1000\n",
    "    mask = np.logical_and(mask, df.energy < 50000000)\n",
    "    mask = np.logical_and(mask, df.sigma < np.deg2rad(150))\n",
    "    return mask\n",
    "\n",
    "fig, axes = make_projection_hist(bin_contributions=bin_contributions, mask_func=mask_func)\n",
    "fig.savefig('{}/latitude_excess.png'.format(plot_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-beatles",
   "metadata": {},
   "source": [
    "##### Make plots for different energy ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_ranges = [[0, 1000], [1000, 20000], [20000, float('inf')]]\n",
    "\n",
    "for e_min, e_max in e_ranges:\n",
    "    def mask_func(df):\n",
    "        mask = np.logical_and(df.energy >= e_min, df.energy < e_max)\n",
    "        return mask\n",
    "\n",
    "    fig, axes = make_projection_hist(bin_contributions=bin_contributions, mask_func=mask_func)\n",
    "    axes[0].set_title(r'$E_{\\mathrm{reco}} \\in $' + '[{:.0f} TeV, {:.0f} TeV]'.format(e_min/1000., e_max/1000.))\n",
    "    fig.savefig('{}/latitude_excess_E{:.0f}_{:.0f}.png'.format(plot_dir, e_min, e_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-anniversary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-gates",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = np.linspace(0., 2*np.pi, 180)\n",
    "dec = np.zeros_like(ra)\n",
    "lon, lat = np.rad2deg(ra_dec_to_lon_lat(ra=ra, dec=dec))\n",
    "\n",
    "plt.plot(np.rad2deg(ra), lon)\n",
    "plt.plot(np.rad2deg(ra), lat)\n",
    "plt.plot(np.rad2deg(ra), np.zeros_like(ra), ls='--', color='0.6')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-adventure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-graphic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-combat",
   "metadata": {},
   "source": [
    "#### Scratch Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_hdf('/data/ana/PointSource/DNNCascade/analysis/version-001-p00/MC_NuGen_bfrv1_2153x.hdf', key='df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-scratch",
   "metadata": {},
   "outputs": [],
   "source": [
    "[k for k in df.keys() if 'azi' in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-slope",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 2*np.pi, 30)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "ax.hist(df.MCPrimary_azimuth, weights=df.weights, bins=bins, histtype='step', label='MC')\n",
    "ax.hist(df.azi, weights=df.weights, bins=bins, histtype='step', label='Reco')\n",
    "ax.hist(a.bg_data.azimuth, bins=bins, histtype='step', label='Exp')\n",
    "\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2.3_py3-v4.1.0_csky",
   "language": "python",
   "name": "tensorflow2.3_py3-v4.1.0_csky"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# set env flags to catch BLAS used for scipy/numpy \n",
    "# to only use 1 cpu, n_cpus will be totally controlled by csky\n",
    "os.environ['MKL_NUM_THREADS'] = \"1\"\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = \"1\"\n",
    "os.environ['OMP_NUM_THREADS'] = \"1\"\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = \"1\"\n",
    "os.environ['VECLIB_MAXIMUM_THREADS'] = \"1\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.facecolor'] = 'w'\n",
    "mpl.rcParams['savefig.facecolor'] = 'w'\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "\n",
    "# suppress natural naming warnings\n",
    "import warnings\n",
    "from tables import NaturalNameWarning\n",
    "warnings.filterwarnings('ignore', category=NaturalNameWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-antarctica",
   "metadata": {},
   "source": [
    "## Defines Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-marks",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_version = 'version-001-p01'\n",
    "\n",
    "plot_dir = '/home/mhuennefeld/public_html/analyses/DNNCascade/plots/reconstruction_resolution/selection_{}'.format(selection_version)\n",
    "df_dir = '/data/ana/PointSource/DNNCascade/analysis/{}/'.format(selection_version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir_path in [plot_dir]:\n",
    "    if not os.path.exists(dir_path):\n",
    "        print('Creating directory:', dir_path)\n",
    "        os.makedirs(dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-sunglasses",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "\n",
    "print('Loading BFRv1 ...')\n",
    "dfs['BFRv1'] = pd.read_hdf(\n",
    "    df_dir + '/MC_NuGen_bfrv1_2153x.hdf', key='df',\n",
    ")\n",
    "\n",
    "print('Loading SnowStorm ...')\n",
    "dfs['SnowStorm']  = pd.read_hdf(\n",
    "    df_dir + '/systematics/SnowStorm_Spice321/MC_NuGen_snowstorm_214xx.hdf', key='df',\n",
    ")\n",
    "\n",
    "print('Loading exp ...')\n",
    "df_exp_list = []\n",
    "for y in range(2011, 2021):\n",
    "     df_exp_list.append(pd.read_hdf(\n",
    "        '{}/IC86_{}_exp.hdf'.format(df_dir, y), key='df',\n",
    "    ))\n",
    "dfs['_exp']  = pd.concat(df_exp_list, ignore_index=True)\n",
    "\n",
    "print('Loading MuonGun ...')\n",
    "dfs['MuonGun']  = pd.read_hdf(\n",
    "    df_dir + '/MC_MuonGun_2131x.hdf', key='df',\n",
    ")\n",
    "\n",
    "print('Loading CORSIKA ...')\n",
    "dfs['CORSIKA']  = pd.read_hdf(\n",
    "    df_dir + '/MC_CORSIKA_20904.hdf', key='df',\n",
    ") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-marketing",
   "metadata": {},
   "source": [
    "## Livetime and Burnsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_burn = dfs['_exp']['I3EventHeader_Run'] % 10 == 0\n",
    "dfs['exp'] = dfs['_exp'][mask_burn]\n",
    "\n",
    "burnsample_fraction = np.sum(mask_burn) / len(dfs['_exp'])\n",
    "print('Burn sample fraction: {:3.3f}%'.format(burnsample_fraction * 100))\n",
    "\n",
    "for name, df in dfs.items():\n",
    "    if 'exp' not in name:\n",
    "        print('Adjusting weights for: {}'.format(name))\n",
    "        df['weights_new'] = df['weights'] * burnsample_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "_livetime = dfs['BFRv1']['weights_livetime'].iloc[0]\n",
    "livetime = _livetime * burnsample_fraction\n",
    "print('Livetime: {} days'.format(_livetime / 60 / 60 / 24))\n",
    "print('Livetime [Burnsample]: {} days'.format(livetime / 60 / 60 / 24))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-strength",
   "metadata": {},
   "source": [
    "## Snowstorm Systematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "priors_dict = {\n",
    "    #'Absorption': [0.930, 1.070], #[0.9, 1.0],\n",
    "    #'Scattering': [0.953, 1.012], #[0.9, 1.1],\n",
    "    #'AnisotropyScale': [0, 2], #[0., 2.],\n",
    "    #'DOMEfficiency': [0.9, 1.1],\n",
    "    #'HoleIceForward_Unified_00': [-0.800, 0.800], #[-0.65, 0.65],\n",
    "    #'HoleIceForward_Unified_01': [-0.120, -0.040], #[-0.2, 0.2],\n",
    "}\n",
    "snowstorm_simulation_range = {\n",
    "    'Scattering': [0.9, 1.1],\n",
    "    'Absorption': [0.9, 1.1],\n",
    "    'AnisotropyScale': [0., 2.],\n",
    "    'DOMEfficiency': [0.9, 1.1],\n",
    "    'HoleIceForward_Unified_00': [-1.0, 1.0],\n",
    "    'HoleIceForward_Unified_01': [-0.2, 0.2],\n",
    "}\n",
    "\n",
    "def rename_snowstorm_params(df):\n",
    "    parameter_names=[\n",
    "        'Scattering', 'Absorption', 'AnisotropyScale', \n",
    "        'DOMEfficiency', 'HoleIceForward_Unified_00', \n",
    "        'HoleIceForward_Unified_01',\n",
    "    ]\n",
    "    for i, param in enumerate(parameter_names):\n",
    "        df[param] = df['SnowstormParameters_{:05d}'.format(i)]\n",
    "\n",
    "def get_snowstorm_multiplier(\n",
    "        df,\n",
    "        priors_dict,\n",
    "        simulation_range=snowstorm_simulation_range,\n",
    "        verbose=False,\n",
    "    ):\n",
    "    \"\"\"Reweight snowstorm\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: DataFrame or dict\n",
    "        The dataframe or dictionary containing the SnowStorm\n",
    "        parameters. \n",
    "    priors_dict : dict\n",
    "        A dictionary with uniform Snowstorm priors defined\n",
    "        as a tuple of (min, max).\n",
    "    \"\"\"\n",
    "    w_multiplier = 1.0\n",
    "    mask = np.ones_like(df[list(simulation_range.keys())[0]], dtype=bool)\n",
    "    for name, prior in priors_dict.items():\n",
    "        \n",
    "        prior_orig = simulation_range[name]\n",
    "        assert prior[1] >= prior[0] and prior_orig[1] >= prior_orig[0]\n",
    "        assert prior[0] >= prior_orig[0] and prior[0] <= prior_orig[1]\n",
    "        assert prior[1] >= prior_orig[0] and prior[1] <= prior_orig[1]\n",
    "        \n",
    "        range_sim = prior_orig[1] - prior_orig[0]\n",
    "        range_new = prior[1] - prior[0]\n",
    "        w_multiplier *= range_sim / range_new\n",
    "        mask = np.logical_and(mask, df[name] >= prior[0])\n",
    "        mask = np.logical_and(mask, df[name] <= prior[1])\n",
    "    \n",
    "    \n",
    "    snowstorm_multiplier = np.ones_like(mask) * mask.astype(float) * w_multiplier\n",
    "    if verbose:\n",
    "        print(np.sum(mask) / float(len(mask)), 1./w_multiplier, w_multiplier)\n",
    "        print(np.sum(mask), len(mask), np.sum(snowstorm_multiplier))\n",
    "    return snowstorm_multiplier\n",
    "        \n",
    "if 'SnowStorm' in dfs:\n",
    "    print('Reweighting Snowstorm set')\n",
    "    rename_snowstorm_params(dfs['SnowStorm'])\n",
    "    dfs['SnowStorm']['snowstorm_multiplier'] = get_snowstorm_multiplier(\n",
    "        df=dfs['SnowStorm'],\n",
    "        priors_dict=priors_dict,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-freedom",
   "metadata": {},
   "source": [
    "## Compute Containment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnn_cascade_selection.utils.notebook import coordinates\n",
    "from ic3_labels.labels.utils import geometry\n",
    "\n",
    "def add_distance_to_hull(df, reco_key='EventGeneratorSelectedRecoNN_I3Particle_'):\n",
    "    pos = np.array([\n",
    "        df[reco_key + 'x'],\n",
    "        df[reco_key + 'y'],\n",
    "        df[reco_key + 'z'],\n",
    "    ]).T\n",
    "    distances = np.empty_like(df[reco_key + 'x'])\n",
    "    for i, pos_i in tqdm(enumerate(pos), total=len(pos)):\n",
    "        distances[i] = geometry.distance_to_icecube_hull(pos_i)\n",
    "    df['distance_hull'] = distances\n",
    "        \n",
    "add_distance_to_hull(dfs['MuonGun'])\n",
    "add_distance_to_hull(dfs['CORSIKA'])\n",
    "add_distance_to_hull(dfs['exp'])\n",
    "add_distance_to_hull(dfs['_exp'])\n",
    "add_distance_to_hull(dfs['BFRv1'])\n",
    "#add_distance_to_hull(dfs['SnowStorm'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-easter",
   "metadata": {},
   "source": [
    "## Compute Opening Angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_opening_angle(df, reco_key='EventGeneratorSelectedRecoNN_I3Particle'):\n",
    "    dpsi = coordinates.get_angle_deviation(\n",
    "        azimuth1=df[reco_key + '_azimuth'], \n",
    "        zenith1=df[reco_key + '_zenith'], \n",
    "        azimuth2=df['LabelsDeepLearning_PrimaryAzimuth'], \n",
    "        zenith2=df['LabelsDeepLearning_PrimaryZenith'], \n",
    "    )\n",
    "    df['dpsi'] = dpsi\n",
    "    df['dpsi_deg'] = np.rad2deg(dpsi)\n",
    "\n",
    "compute_opening_angle(dfs['MuonGun'])\n",
    "compute_opening_angle(dfs['CORSIKA'])\n",
    "compute_opening_angle(dfs['BFRv1'])\n",
    "compute_opening_angle(dfs['SnowStorm'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-bunny",
   "metadata": {},
   "source": [
    "## Create Combined MC DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "nugen_keys = ['BFRv1']\n",
    "muon_keys = ['MuonGun', 'CORSIKA']\n",
    "\n",
    "shared_keys = None\n",
    "for name, df in dfs.items():\n",
    "    if 'exp' not in name:\n",
    "        if shared_keys is None:\n",
    "            shared_keys = set(df.columns.values)\n",
    "        else:\n",
    "            shared_keys = shared_keys.intersection(\n",
    "                set(df.columns.values))\n",
    "\n",
    "df_list = []\n",
    "for name in nugen_keys:\n",
    "    print('NuGen:', name)\n",
    "    df_red = dfs[name][list(shared_keys)]\n",
    "    df_red['mc_origin'] = 'NuGen_' + name\n",
    "    df_list.append(df_red)\n",
    "for name in muon_keys:\n",
    "    print('Muon:', name)\n",
    "    df_red = dfs[name][list(shared_keys)]\n",
    "    df_red['mc_origin'] = 'Muon_' + name\n",
    "    df_list.append(df_red)\n",
    "    \n",
    "df_mc = pd.concat(df_list, ignore_index=True)\n",
    "del df_list\n",
    "print(len(df_mc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-wright",
   "metadata": {},
   "source": [
    "## Plot Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert = {\n",
    "    'distance_hull': 'Distance to convex hull /m ',\n",
    "    'LabelsDeepLearning_TotalDepositedEnergy': 'In detector deposited EM energy / GeV',\n",
    "    'LabelsDeepLearning_EnergyVisible': 'Visible energy / GeV',\n",
    "    'LabelsDeepLearning_PrimaryEnergy': 'Neutrino energy / GeV',\n",
    "    'EventGeneratorSelectedRecoNN_I3Particle_z': 'Reconstructed vertex-$z$ / m',\n",
    "    'EventGeneratorSelectedRecoNN_I3Particle_energy': r'Reconstructed energy $E_\\mathrm{reco}$ / GeV',\n",
    "    'EventGeneratorSelectedRecoNNCircularUncertainty': r'Angular uncertainty $\\sigma_\\mathrm{reco}$ [uncorrected]',\n",
    "    'angErr': r'Angular uncertainty $\\sigma_\\mathrm{reco}$',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from cycler import cycle\n",
    "from copy import deepcopy\n",
    "import csky as cy\n",
    "import histlite as hl\n",
    "\n",
    "soft_colors = cy.plotting.soft_colors\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "def get_color_cycler(colors=colors):\n",
    "    return cycle(colors)\n",
    "\n",
    "def plot_1d_quantity(\n",
    "            df, x_key, quantity_func, \n",
    "            x_edges, x_width,\n",
    "            x_width_in_log=False,\n",
    "            label_quantity=None,\n",
    "            label=None,\n",
    "            color=None, ls='-',\n",
    "            fig=None, ax=None, figsize=(6, 4),\n",
    "            mask_func=None,\n",
    "        ):\n",
    "    if fig is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    if mask_func is None:\n",
    "        mask = np.ones_like(df[x_key], dtype=bool)\n",
    "    else:\n",
    "        mask = mask_func(df)\n",
    "    \n",
    "    x_mids = x_edges[:-1] + 0.5 * np.diff(x_edges)\n",
    "    \n",
    "    values = np.empty(len(x_mids))\n",
    "    errors = np.empty(len(x_mids)) * np.nan\n",
    "    errors_exist = False\n",
    "    \n",
    "    # walk through each bin and compute quantity\n",
    "    for i, x_mid in tqdm(enumerate(x_mids), total=len(x_mids)):\n",
    "        if x_width_in_log:\n",
    "            mask_x = np.logical_and(\n",
    "                np.log10(df[x_key]) >= np.log10(x_mid) - x_width, \n",
    "                np.log10(df[x_key]) < np.log10(x_mid) + x_width, \n",
    "            )\n",
    "        else:\n",
    "            mask_x = np.logical_and(\n",
    "                df[x_key] >= x_mid - x_width, \n",
    "                df[x_key] < x_mid + x_width, \n",
    "            )\n",
    "            \n",
    "        mask_i = mask & mask_x\n",
    "        res = quantity_func(df=df, mask=mask_i)\n",
    "        if isinstance(res, (float, int)):\n",
    "            values[i] = res\n",
    "        else:\n",
    "            values[i] = res[0]\n",
    "            errors[i] = res[1]\n",
    "            errors_exist = True\n",
    "    \n",
    "    if errors_exist:\n",
    "        if x_width_in_log:\n",
    "            xerr = (10**(np.log10(x_mids) - x_width) - x_mids, 10**(np.log10(x_mids) + x_width) - x_mids)\n",
    "        else:\n",
    "            xerr = x_width\n",
    "        ax.errorbar(x_mids, values, xerr=xerr, yerr=errors, ls=ls, label=label, color=color, fmt='o')\n",
    "    else:\n",
    "        ax.plot(x_mids, values, ls=ls, label=label, color=color)\n",
    "    ax.set_xlabel(convert.get(x_key, x_key))\n",
    "    ax.set_ylabel(label_quantity)\n",
    "    return fig, ax\n",
    "\n",
    "def plot_2d_quantity(\n",
    "            df, x_key, y_key, quantity_func, \n",
    "            x_edges, y_edges, x_width, y_width,\n",
    "            x_width_in_log=False,\n",
    "            y_width_in_log=False,\n",
    "            label_quantity=None,\n",
    "            fig=None, ax=None, figsize=(9, 6),\n",
    "            mask_func=None,\n",
    "            vmin=None, vmax=None, norm='log',\n",
    "            cmap=plt.cm.get_cmap('viridis', 15),\n",
    "            plot_colorbar=True,\n",
    "            cb_axis=None,\n",
    "            cb_kwargs={},\n",
    "            convert=convert,\n",
    "            do_not_show_zeros=False,\n",
    "        ):\n",
    "    if fig is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    if mask_func is None:\n",
    "        mask = np.ones_like(df[x_key], dtype=bool)\n",
    "    else:\n",
    "        mask = mask_func(df)\n",
    "    \n",
    "    x_mids = x_edges[:-1] + 0.5 * np.diff(x_edges)\n",
    "    y_mids = y_edges[:-1] + 0.5 * np.diff(y_edges)\n",
    "    \n",
    "    if isinstance(norm, str):\n",
    "        if norm == 'log':\n",
    "            norm = mpl.colors.LogNorm(vmin=vmin, vmax=vmax)\n",
    "        elif norm == 'linear':\n",
    "            norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "        else:\n",
    "            raise ValueError('Unkown normalization:', norm)\n",
    "    \n",
    "    shape = (len(x_mids), len(y_mids))\n",
    "    values = np.empty(shape)\n",
    "    \n",
    "    # walk through each bin and compute quantity\n",
    "    for i, x_mid in tqdm(enumerate(x_mids), total=len(x_mids)):\n",
    "        for j, y_mid in enumerate(y_mids):\n",
    "            \n",
    "            if x_width_in_log:\n",
    "                mask_x = np.logical_and(\n",
    "                    np.log10(df[x_key]) >= np.log10(x_mid) - x_width, \n",
    "                    np.log10(df[x_key]) < np.log10(x_mid) + x_width, \n",
    "                )\n",
    "            else:\n",
    "                mask_x = np.logical_and(\n",
    "                    df[x_key] >= x_mid - x_width, \n",
    "                    df[x_key] < x_mid + x_width, \n",
    "                )\n",
    "            \n",
    "            if y_width_in_log:\n",
    "                mask_y = np.logical_and(\n",
    "                    np.log10(df[y_key]) >= np.log10(y_mid) - y_width, \n",
    "                    np.log10(df[y_key]) < np.log10(y_mid) + y_width, \n",
    "                )\n",
    "            else:\n",
    "                mask_y = np.logical_and(\n",
    "                    df[y_key] >= y_mid - y_width, \n",
    "                    df[y_key] < y_mid + y_width, \n",
    "                )\n",
    "            mask_i = mask & mask_x & mask_y\n",
    "            \n",
    "            quantity = quantity_func(df=df, mask=mask_i)\n",
    "            values[i, j] = quantity\n",
    "    \n",
    "    if do_not_show_zeros:\n",
    "        values[values == 0] = np.inf\n",
    "        \n",
    "    im = ax.pcolormesh(x_edges, y_edges, values.T, norm=norm, cmap=cmap)\n",
    "    if plot_colorbar:\n",
    "        if cb_axis is None:\n",
    "            cb_axis = ax\n",
    "        cb = plt.colorbar(im, ax=cb_axis, **cb_kwargs)\n",
    "        cb.set_label(label_quantity)\n",
    "    if convert is not None:\n",
    "        ax.set_xlabel(convert.get(x_key, x_key))\n",
    "        ax.set_ylabel(convert.get(y_key, y_key))\n",
    "    return fig, ax, values\n",
    "\n",
    "\n",
    "def plot_resolution(\n",
    "            df, x_key, y_key, \n",
    "            bins=np.logspace(np.log10(500), 7, 30), \n",
    "            fig=None, ax=None, figsize=(9, 6),\n",
    "            normalize_column=True,\n",
    "            density=True,\n",
    "            mask_func=None,\n",
    "            vmin=None, vmax=None,\n",
    "            convert=convert,\n",
    "            plot_colorbar=True,\n",
    "            cb_axis='ax',\n",
    "            cb_kwargs={},\n",
    "        ):\n",
    "    if fig is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    if mask_func is None:\n",
    "        mask = np.ones_like(df[x_key], dtype=bool)\n",
    "    else:\n",
    "        mask = mask_func(df)\n",
    "    \n",
    "    norm = mpl.colors.LogNorm(vmin=vmin, vmax=vmax)\n",
    "    if normalize_column:\n",
    "        H, xedges, yedges = np.histogram2d(\n",
    "            df[x_key][mask], df[y_key][mask], bins=bins, weights=df['weights'][mask],\n",
    "        )\n",
    "        H /= np.sum(H, axis=1, keepdims=True)\n",
    "        im = ax.pcolormesh(xedges, yedges, H.T, norm=norm)\n",
    "\n",
    "    else:\n",
    "        h, _, _, im = ax.hist2d(\n",
    "            df[x_key][mask], df[y_key][mask], bins=bins, weights=df['weights'][mask], \n",
    "            density=True, norm=norm,\n",
    "        )\n",
    "    \n",
    "    if plot_colorbar:\n",
    "        if cb_axis is 'ax':\n",
    "            cb_axis = ax\n",
    "        cb = plt.colorbar(im, ax=cb_axis, **cb_kwargs)\n",
    "        if normalize_column:\n",
    "            cb.set_label('Density (column-normalized)')\n",
    "        else:\n",
    "            cb.set_label('Density')\n",
    "    ax.set_xlabel(convert.get(x_key, x_key))\n",
    "    ax.set_ylabel(convert.get(y_key, y_key))\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    return fig, ax\n",
    "\n",
    "def plot_angular_resolution(\n",
    "            df, \n",
    "            key_x='LabelsDeepLearning_PrimaryEnergy', \n",
    "            xlabel=r'$E_\\mathrm{true}$ / GeV',\n",
    "            label=r'${:.0f}\\%$',\n",
    "            bins=(10**np.r_[2.25:8.26:.45], np.r_[0:180.01:.01]),\n",
    "            fig=None, ax=None, figsize=(9, 6),\n",
    "            xscale='log',\n",
    "            color=soft_colors[0],\n",
    "            mask_func=None,\n",
    "            draw_only_median=False,\n",
    "            median_kwargs=dict(lw=2),\n",
    "            dpsi_deg=None,\n",
    "            weights=None,\n",
    "            plot_lim=None,\n",
    "            set_xlim=True,\n",
    "            **kwargs\n",
    "        ):\n",
    "    \n",
    "    if mask_func is None:\n",
    "        mask = np.ones_like(df[key_x], dtype=bool)\n",
    "    else:\n",
    "        mask = mask_func(df)\n",
    "    \n",
    "    if dpsi_deg is None:\n",
    "        dpsi_deg = df['dpsi_deg']\n",
    "    if weights is None:\n",
    "        weights = df['weights']\n",
    "    \n",
    "    # create a histogram:\n",
    "    h = hl.hist_slide(\n",
    "        # slide the bins 5 times along energy, hold them still along angular error\n",
    "        (5,1),\n",
    "        # 2D histogram of true energy and angular error in degrees\n",
    "        (df[key_x][mask], dpsi_deg[mask]),\n",
    "        # weighting\n",
    "        weights[mask],\n",
    "        bins=bins,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    # normalize along the angular error axis\n",
    "    h = h.normalize(1)\n",
    "    \n",
    "    if plot_lim is not None:\n",
    "        \n",
    "        bin_idx_lower = np.searchsorted(h.bins[0], plot_lim[0])\n",
    "        bin_idx_upper = np.searchsorted(h.bins[0], plot_lim[1])\n",
    "        bins_red = (h.bins[0][bin_idx_lower:bin_idx_upper+1], h.bins[1])\n",
    "        h = hl.Hist(bins=bins_red, values=h.values[bin_idx_lower:bin_idx_upper+1])\n",
    "\n",
    "    # get 20%, 50%, and 80% quantiles\n",
    "    h2 = h.contain(1, .2)\n",
    "    h5 = h.contain(1, .5)\n",
    "    h8 = h.contain(1, .8)\n",
    "    \n",
    "    if fig is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # plot quantiles, emphasize median\n",
    "    if draw_only_median:\n",
    "        hl.plot1d (ax, h5, color=color, drawstyle='default', **median_kwargs)\n",
    "    else:\n",
    "        hl.fill_between(ax, 0, h2, color=color, alpha=.3, drawstyle='line')\n",
    "        hl.fill_between(ax, 0, h5, color=color, alpha=.3, drawstyle='line')\n",
    "        hl.fill_between(ax, 0, h8, color=color, alpha=.3, drawstyle='line')\n",
    "        hl.plot1d (ax, h5, color=color, drawstyle='default', **median_kwargs)\n",
    "\n",
    "        # trick to get the legend handles colored right\n",
    "        # try testing what happens if you just do hl.fill_between(..., label='...')\n",
    "        nans = [np.nan, np.nan]\n",
    "        ax.plot (nans, nans, color=color, lw=5, alpha=1 - (1-0.3)**1, label=label.format(80))\n",
    "        ax.plot (nans, nans, color=color, lw=5, alpha=1 - (1-0.3)**2, label=label.format(50))\n",
    "        ax.plot (nans, nans, color=color, lw=5, alpha=1 - (1-0.3)**3, label=label.format(20))\n",
    "\n",
    "    # labels etc\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(r'$\\Delta\\Psi[\\mathrm{true,reco}]~/^\\circ$')\n",
    "    if set_xlim:\n",
    "        ax.set_xlim(h.bins[0][1], h.bins[0][-2])\n",
    "    ax.set_ylim(0)\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig, ax, (h, h2, h5, h8)\n",
    "\n",
    "\n",
    "def plot_hist(\n",
    "            key, bins,\n",
    "            fig=None, ax=None, figsize=(9, 6),\n",
    "            density=False,\n",
    "            mask_func=None,\n",
    "            ls=None,\n",
    "            colors=colors,\n",
    "            add_labels=True,\n",
    "            dfs_to_plot=['exp', 'BFRv1', 'MuonGun', 'CORSIKA'],\n",
    "        ):\n",
    "    \n",
    "    color_cycle = cycle(colors)\n",
    "    \n",
    "    if fig is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    if 'exp' in dfs_to_plot:\n",
    "        if mask_func is None:\n",
    "            values = dfs['exp'][key]\n",
    "        else:\n",
    "            values = dfs['exp'][key][mask_func(dfs['exp'])]\n",
    "        if add_labels:\n",
    "            label = 'exp'\n",
    "        else:\n",
    "            label = None\n",
    "        ax.hist(values, bins=bins, histtype='step', density=density, ls=ls, label=label, color=next(color_cycle))\n",
    "    \n",
    "    for k in ['BFRv1', 'MuonGun', 'CORSIKA']:\n",
    "        if k in dfs_to_plot:\n",
    "            if mask_func is None:\n",
    "                mask = np.ones_like(dfs[k][key], dtype=bool)\n",
    "            else:\n",
    "                mask = mask_func(dfs[k])\n",
    "            if add_labels:\n",
    "                label = k\n",
    "            else:\n",
    "                label = None\n",
    "            ax.hist(\n",
    "                dfs[k][key][mask], bins=bins, weights=dfs[k]['weights_new'][mask], \n",
    "                histtype='step', density=density, label=label, ls=ls, color=next(color_cycle),\n",
    "            )\n",
    "    ax.legend()  \n",
    "    ax.set_xlabel(key)\n",
    "    if density:\n",
    "        ax.set_ylabel('Density')\n",
    "    else:\n",
    "        ax.set_ylabel('Number of Events')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(1e-1)\n",
    "    return fig, ax\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-decrease",
   "metadata": {},
   "source": [
    "### Masked Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contained_mask(df):\n",
    "    return df['distance_hull'] < 0\n",
    "\n",
    "def get_non_contained_mask(df):\n",
    "    return ~get_contained_mask(df)\n",
    "\n",
    "dust_lower = -150\n",
    "dust_upper = 0\n",
    "\n",
    "def get_dust_layer_mask(df):\n",
    "    reco_key='EventGeneratorSelectedRecoNN_I3Particle'\n",
    "    mask = np.logical_and(\n",
    "        df[reco_key + '_z'] >= dust_lower,\n",
    "        df[reco_key + '_z'] <= dust_upper,\n",
    "    )\n",
    "    return mask\n",
    "\n",
    "def get_non_dust_layer_mask(df):\n",
    "    return ~get_dust_layer_mask(df)\n",
    "\n",
    "def get_mesc_equivalent(df):\n",
    "    mask = np.logical_and(\n",
    "        get_non_dust_layer_mask(df),\n",
    "        df['distance_hull'] < 0,\n",
    "    )\n",
    "    return mask\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-carolina",
   "metadata": {},
   "source": [
    "#### Fraction outside as function of energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-conversion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantity_func(df, mask, with_err=False):\n",
    "    if np.sum(mask) <= 1:\n",
    "        return np.nan\n",
    "    if 'weights' in df:\n",
    "        n_out = np.sum(df['weights'][mask & get_non_contained_mask(df)])\n",
    "        n_total = np.sum(df['weights'][mask])\n",
    "        fr = np.sum(df['weights'][mask & get_non_contained_mask(df)]) / np.sum(df['weights'][mask])\n",
    "    else:\n",
    "        n_out = np.sum(mask & get_non_contained_mask(df))\n",
    "        n_total = np.sum(mask)\n",
    "        fr = np.sum(mask & get_non_contained_mask(df)) * 1. / np.sum(mask)\n",
    "                          \n",
    "    h_out = hl.Hist(bins=(0, 1), values=[n_out], errors=[np.sqrt(n_out)])\n",
    "    h_total = hl.Hist(bins=(0, 1), values=[n_total], errors=[np.sqrt(n_total)])\n",
    "    \n",
    "    h_res = h_out.efficiency(h_total)\n",
    "    if with_err:\n",
    "        return h_res.values[0], h_res.errors[0]\n",
    "    else:\n",
    "        return h_res.values[0]\n",
    "\n",
    "def quantity_func_err(df, mask, with_err=False):\n",
    "    return quantity_func(df=df, mask=mask, with_err=True)\n",
    "\n",
    "x_key = 'EventGeneratorSelectedRecoNN_I3Particle_energy'\n",
    "x_edges_exp = np.linspace(np.log10(500), 8, 31)\n",
    "x_edges = 10**x_edges_exp\n",
    "x_width = 0.5*np.diff(x_edges_exp)[0]\n",
    "print('x_width:', x_width)\n",
    "\n",
    "fig, ax = plot_1d_quantity(\n",
    "    df=dfs['BFRv1'], \n",
    "    x_key=x_key, \n",
    "    quantity_func=quantity_func, \n",
    "    x_edges=x_edges, \n",
    "    x_width=x_width, \n",
    "    x_width_in_log=True,\n",
    "    color=soft_colors[0],\n",
    "    label='MC',\n",
    "    label_quantity='Fraction of events outside',\n",
    ")\n",
    "plot_1d_quantity(\n",
    "    df=dfs['exp'], \n",
    "    x_key=x_key, \n",
    "    quantity_func=quantity_func_err, \n",
    "    x_edges=x_edges, \n",
    "    x_width=x_width, \n",
    "    x_width_in_log=True,\n",
    "    fig=fig, ax=ax,\n",
    "    color='0.7', ls=None,\n",
    "    label='Exp data',\n",
    "    label_quantity='Fraction of events outside',\n",
    ")\n",
    "fig.tight_layout()\n",
    "ax.set_xscale('log')\n",
    "ax.legend()\n",
    "ax.set_ylim(0., 0.7)\n",
    "fig.savefig(os.path.join(\n",
    "    plot_dir, 'fraction_outside_1d_{}.png'.format(x_key)))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-landscape",
   "metadata": {},
   "source": [
    "##### Distance Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-construction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plot_hist('distance_hull', bins=np.linspace(-500, 200, 40))\n",
    "ax.set_xlabel('Distance to convex hull')\n",
    "\n",
    "fr_outside_exp = np.sum(dfs['exp']['distance_hull'] > 0) / len(dfs['exp'])\n",
    "fr_outside_mc = np.sum(dfs['BFRv1']['weights_new'][dfs['BFRv1']['distance_hull'] > 0]) / np.sum(dfs['BFRv1']['weights_new'])\n",
    "\n",
    "ax.set_title('Fraction of events outside: {:3.3f} [MC: {:3.3f}]'.format(fr_outside_exp, fr_outside_mc))\n",
    "ax.axvline(0., color='0.6', ls='--', label='Detector Boundary')\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(plot_dir, 'hist_distance_hull.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-current",
   "metadata": {},
   "source": [
    "##### Vertex-Z Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-testament",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_hist('EventGeneratorSelectedRecoNN_I3Particle_z', bins=np.linspace(-500, 500, 80))\n",
    "ax.set_xlabel('Vertex-$z$ / m')\n",
    "\n",
    "fr_outside_exp = np.sum(get_dust_layer_mask(dfs['exp'])) / len(dfs['exp'])\n",
    "fr_outside_mc = np.sum(dfs['BFRv1']['weights_new'][get_dust_layer_mask(dfs['BFRv1'])]) / np.sum(dfs['BFRv1']['weights_new'])\n",
    "\n",
    "ax.set_title('Fraction of events in dust layer: {:3.3f} [MC: {:3.3f}]'.format(fr_outside_exp, fr_outside_mc))\n",
    "ax.axvline(dust_lower, color='0.6', ls='--', label='Dust Layer')\n",
    "ax.axvline(dust_upper, color='0.6', ls='--')\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(plot_dir, 'hist_vertex_z.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-musical",
   "metadata": {},
   "source": [
    "##### Energy Hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-property",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.logspace(2, 8, 15)\n",
    "dfs_to_plot = ['exp', 'BFRv1']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "plot_hist(\n",
    "    'EventGeneratorSelectedRecoNN_I3Particle_energy', \n",
    "    bins=bins, fig=fig, ax=ax, ls='-', add_labels=True,\n",
    "    mask_func=get_contained_mask,\n",
    "    dfs_to_plot=dfs_to_plot,\n",
    ")\n",
    "plot_hist(\n",
    "    'EventGeneratorSelectedRecoNN_I3Particle_energy', \n",
    "    bins=bins, fig=fig, ax=ax, ls='--', add_labels=False,\n",
    "    mask_func=get_non_contained_mask,\n",
    "    dfs_to_plot=dfs_to_plot,\n",
    ")\n",
    "plot_hist(\n",
    "    'EventGeneratorSelectedRecoNN_I3Particle_energy', \n",
    "    bins=bins, fig=fig, ax=ax, ls='-.', add_labels=False,\n",
    "    mask_func=get_dust_layer_mask,\n",
    "    dfs_to_plot=dfs_to_plot,\n",
    ")\n",
    "ax.set_xlabel(r'$E_\\mathrm{reco}$')\n",
    "\n",
    "ax.plot(np.inf, np.inf, color='0.7', ls='-', label='Contained')\n",
    "ax.plot(np.inf, np.inf, color='0.7', ls='--', label='Outside')\n",
    "ax.plot(np.inf, np.inf, color='0.7', ls='-.', label='Dust Layer')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xscale('log')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(plot_dir, 'containment_hist_energy.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-inspection",
   "metadata": {},
   "source": [
    "#### Declination Hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, np.pi, 15)\n",
    "dfs_to_plot = ['exp', 'BFRv1']\n",
    "density = False\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "plot_hist(\n",
    "    'EventGeneratorSelectedRecoNN_I3Particle_zenith', \n",
    "    bins=bins, fig=fig, ax=ax, ls='-', add_labels=True, density=density,\n",
    "    mask_func=get_contained_mask,\n",
    "    dfs_to_plot=dfs_to_plot,\n",
    ")\n",
    "plot_hist(\n",
    "    'EventGeneratorSelectedRecoNN_I3Particle_zenith', \n",
    "    bins=bins, fig=fig, ax=ax, ls='--', add_labels=False, density=density,\n",
    "    mask_func=get_non_contained_mask,\n",
    "    dfs_to_plot=dfs_to_plot,\n",
    ")\n",
    "plot_hist(\n",
    "    'EventGeneratorSelectedRecoNN_I3Particle_zenith', \n",
    "    bins=bins, fig=fig, ax=ax, ls='-.', add_labels=False, density=density,\n",
    "    mask_func=get_dust_layer_mask,\n",
    "    dfs_to_plot=dfs_to_plot,\n",
    ")\n",
    "ax.set_xlabel(r'Zenith $\\theta_\\mathrm{reco}$')\n",
    "\n",
    "ax.plot(np.inf, np.inf, color='0.7', ls='-', label='Contained')\n",
    "ax.plot(np.inf, np.inf, color='0.7', ls='--', label='Outside')\n",
    "ax.plot(np.inf, np.inf, color='0.7', ls='-.', label='Dust Layer')\n",
    "\n",
    "ax.legend(loc='lower center')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(plot_dir, 'containment_hist_declination.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-adjustment",
   "metadata": {},
   "source": [
    "#### Azimuth Hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 2*np.pi, 15)\n",
    "dfs_to_plot = ['exp', 'BFRv1']\n",
    "density = False\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "plot_hist(\n",
    "    'EventGeneratorSelectedRecoNN_I3Particle_azimuth', \n",
    "    bins=bins, fig=fig, ax=ax, ls='-', add_labels=True, density=density,\n",
    "    mask_func=get_contained_mask,\n",
    "    dfs_to_plot=dfs_to_plot,\n",
    ")\n",
    "plot_hist(\n",
    "    'EventGeneratorSelectedRecoNN_I3Particle_azimuth', \n",
    "    bins=bins, fig=fig, ax=ax, ls='--', add_labels=False, density=density,\n",
    "    mask_func=get_non_contained_mask,\n",
    "    dfs_to_plot=dfs_to_plot,\n",
    ")\n",
    "plot_hist(\n",
    "    'EventGeneratorSelectedRecoNN_I3Particle_azimuth', \n",
    "    bins=bins, fig=fig, ax=ax, ls='-.', add_labels=False, density=density,\n",
    "    mask_func=get_dust_layer_mask,\n",
    "    dfs_to_plot=dfs_to_plot,\n",
    ")\n",
    "ax.set_xlabel(r'Azimuth $\\Phi\\mathrm{reco}$')\n",
    "\n",
    "ax.plot(np.inf, np.inf, color='0.7', ls='-', label='Contained')\n",
    "ax.plot(np.inf, np.inf, color='0.7', ls='--', label='Outside')\n",
    "ax.plot(np.inf, np.inf, color='0.7', ls='-.', label='Dust Layer')\n",
    "\n",
    "ax.legend(loc='lower center')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(plot_dir, 'containment_hist_azimuth.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-glucose",
   "metadata": {},
   "source": [
    "## Event Number Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantity_func(df, mask):\n",
    "    return np.sum(df['weights'][mask])\n",
    "\n",
    "x_key = 'distance_hull'\n",
    "y_key = 'EventGeneratorSelectedRecoNN_I3Particle_energy'\n",
    "x_edges = np.linspace(-500, 200, 16)\n",
    "y_edges_exp = np.linspace(np.log10(500), 8, 16)\n",
    "y_edges = 10**y_edges_exp\n",
    "x_width = 0.5*np.diff(x_edges)[0]\n",
    "y_width = 0.5*np.diff(y_edges_exp)[0]\n",
    "print('x_width:', x_width)\n",
    "print('y_width:', y_width)\n",
    "\n",
    "fig, ax, values = plot_2d_quantity(\n",
    "    df=dfs['BFRv1'], \n",
    "    x_key=x_key, \n",
    "    y_key=y_key, \n",
    "    quantity_func=quantity_func, \n",
    "    x_edges=x_edges, \n",
    "    y_edges=y_edges, \n",
    "    x_width=x_width, \n",
    "    y_width=y_width,\n",
    "    y_width_in_log=True,\n",
    "    vmin=1e-4, vmax=1e3,\n",
    "    #norm='linear',\n",
    "    label_quantity='Number of Events',\n",
    ")\n",
    "ax.set_yscale('log')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(\n",
    "    plot_dir, 'num_events2d_{}_{}.png'.format(x_key, y_key)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-coach",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantity_func(df, mask):\n",
    "    return np.sum(df['weights'][mask])\n",
    "\n",
    "x_key = 'distance_hull'\n",
    "y_key = 'EventGeneratorSelectedRecoNN_I3Particle_z'\n",
    "\n",
    "x_edges = np.linspace(-500, 200, 31)\n",
    "y_edges = np.linspace(-500, 500, 31)\n",
    "x_width = 0.5*np.diff(x_edges)[0]\n",
    "y_width = 0.5*np.diff(y_edges)[0]\n",
    "print('x_width:', x_width)\n",
    "print('y_width:', y_width)\n",
    "\n",
    "fig, ax, values = plot_2d_quantity(\n",
    "    df=dfs['BFRv1'], \n",
    "    x_key=x_key, \n",
    "    y_key=y_key, \n",
    "    quantity_func=quantity_func, \n",
    "    x_edges=x_edges, \n",
    "    y_edges=y_edges, \n",
    "    x_width=x_width, \n",
    "    y_width=y_width,\n",
    "    y_width_in_log=False,\n",
    "    vmin=1e-4, vmax=1e3,\n",
    "    #norm='linear',\n",
    "    label_quantity='Number of Events',\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(\n",
    "    plot_dir, 'num_events2d_{}_{}.png'.format(x_key, y_key)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantity_func(df, mask):\n",
    "    return np.sum(df['weights'][mask])\n",
    "\n",
    "y_key = 'EventGeneratorSelectedRecoNN_I3Particle_energy'\n",
    "x_key = 'EventGeneratorSelectedRecoNN_I3Particle_z'\n",
    "\n",
    "\n",
    "x_edges = np.linspace(-500, 500, 31)\n",
    "y_edges_exp = np.linspace(np.log10(500), 8, 31)\n",
    "y_edges = 10**y_edges_exp\n",
    "x_width = 0.5*np.diff(x_edges)[0]\n",
    "y_width = 0.5*np.diff(y_edges_exp)[0]\n",
    "print('x_width:', x_width)\n",
    "print('y_width:', y_width)\n",
    "\n",
    "fig, ax, values = plot_2d_quantity(\n",
    "    df=dfs['BFRv1'], \n",
    "    x_key=x_key, \n",
    "    y_key=y_key, \n",
    "    quantity_func=quantity_func, \n",
    "    x_edges=x_edges, \n",
    "    y_edges=y_edges, \n",
    "    x_width=x_width, \n",
    "    y_width=y_width,\n",
    "    y_width_in_log=True,\n",
    "    vmin=1e-4, vmax=1e3,\n",
    "    #norm='linear',\n",
    "    label_quantity='Number of Events',\n",
    ")\n",
    "ax.set_yscale('log')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(\n",
    "    plot_dir, 'num_events2d_{}_{}.png'.format(x_key, y_key)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-husband",
   "metadata": {},
   "source": [
    "## Median Opening Angle Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantity_func(df, mask):\n",
    "    return np.median(df['dpsi_deg'][mask])\n",
    "\n",
    "x_key = 'distance_hull'\n",
    "y_key = 'EventGeneratorSelectedRecoNN_I3Particle_energy'\n",
    "\n",
    "fig, ax, values = plot_2d_quantity(\n",
    "    df=dfs['BFRv1'], \n",
    "    x_key=x_key, \n",
    "    y_key=y_key, \n",
    "    quantity_func=quantity_func, \n",
    "    x_edges=np.linspace(-500, 200, 16), \n",
    "    y_edges=np.logspace(np.log10(500), 8, 16), \n",
    "    x_width=50, \n",
    "    y_width=0.5,\n",
    "    y_width_in_log=True,\n",
    "    #vmin=1, vmax=1e2,\n",
    "    #norm='linear',\n",
    "    label_quantity='Median opening angle $\\Delta\\Psi_{50\\%}[\\mathrm{true,reco}]~/^\\circ$'\n",
    ")\n",
    "ax.set_yscale('log')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(\n",
    "    plot_dir, 'opening_angle2d_{}_{}.png'.format(x_key, y_key)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-college",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantity_func(df, mask):\n",
    "    if np.sum(mask) == 0: return np.nan\n",
    "    return np.median(df['dpsi_deg'][mask])\n",
    "\n",
    "x_key = 'distance_hull'\n",
    "y_key = 'EventGeneratorSelectedRecoNN_I3Particle_z'\n",
    "\n",
    "fig, ax, values = plot_2d_quantity(\n",
    "    df=dfs['BFRv1'], \n",
    "    x_key=x_key, \n",
    "    y_key=y_key, \n",
    "    quantity_func=quantity_func, \n",
    "    x_edges=np.linspace(-500, 200, 51), \n",
    "    y_edges=np.linspace(-500, 500, 51), \n",
    "    x_width=70, \n",
    "    y_width=50,\n",
    "    y_width_in_log=False,\n",
    "    vmin=None, vmax=None,\n",
    "    #norm='linear',\n",
    "    label_quantity='Median opening angle $\\Delta\\Psi_{50\\%}[\\mathrm{true,reco}]~/^\\circ$'\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(\n",
    "    plot_dir, 'opening_angle2d_{}_{}.png'.format(x_key, y_key)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-receptor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantity_func(df, mask):\n",
    "    if np.sum(mask) == 0: return np.nan\n",
    "    return np.median(df['dpsi_deg'][mask])\n",
    "\n",
    "y_key = 'EventGeneratorSelectedRecoNN_I3Particle_energy'\n",
    "\n",
    "x_key = 'EventGeneratorSelectedRecoNN_I3Particle_z'\n",
    "\n",
    "fig, ax, values = plot_2d_quantity(\n",
    "    df=dfs['BFRv1'], \n",
    "    x_key=x_key, \n",
    "    y_key=y_key, \n",
    "    quantity_func=quantity_func, \n",
    "    x_edges=np.linspace(-500, 500, 51), \n",
    "    y_edges=np.logspace(np.log10(500), 8, 16), \n",
    "    x_width=50, \n",
    "    y_width=0.5,\n",
    "    y_width_in_log=True,\n",
    "    vmin=None, vmax=None,\n",
    "    #norm='linear',\n",
    "    label_quantity='Median opening angle $\\Delta\\Psi_{50\\%}[\\mathrm{true,reco}]~/^\\circ$'\n",
    ")\n",
    "ax.set_yscale('log')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(\n",
    "    plot_dir, 'opening_angle2d_{}_{}.png'.format(x_key, y_key)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-equation",
   "metadata": {},
   "source": [
    "## Sigma vs Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_key = 'EventGeneratorSelectedRecoNN_I3Particle_energy'\n",
    "y_key = 'angErr'\n",
    "bins = (np.logspace(np.log10(500), 7, 30), np.linspace(0, np.deg2rad(40), 30))\n",
    "\n",
    "fig, ax = plot_resolution(\n",
    "    dfs['BFRv1'], \n",
    "    x_key=x_key,\n",
    "    y_key=y_key,\n",
    "    vmin=5e-4, vmax=3e-1,\n",
    "    bins=bins,\n",
    ")\n",
    "ax.set_yscale('linear')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(\n",
    "    plot_dir, 'correlation_{}_{}.png'.format(x_key, y_key)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = 5e-4\n",
    "vmax = 3e-1\n",
    "\n",
    "x_key = 'EventGeneratorSelectedRecoNN_I3Particle_energy'\n",
    "y_key = 'angErr'\n",
    "bins = (np.logspace(np.log10(500), 7, 20), np.linspace(0, np.deg2rad(40), 20))\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "axes[0].set_title('All Events')\n",
    "plot_resolution(\n",
    "    dfs['BFRv1'], \n",
    "    x_key=x_key,\n",
    "    y_key=y_key,\n",
    "    fig=fig, ax=axes[0],\n",
    "    vmin=vmin, vmax=vmax,\n",
    "    bins=bins,\n",
    ")\n",
    "\n",
    "axes[1].set_title('Uncontained Events')\n",
    "plot_resolution(\n",
    "    dfs['BFRv1'], \n",
    "    x_key=x_key,\n",
    "    y_key=y_key,\n",
    "    fig=fig, ax=axes[1],\n",
    "    mask_func=get_non_contained_mask,\n",
    "    vmin=vmin, vmax=vmax,\n",
    "    bins=bins,\n",
    ")\n",
    "\n",
    "axes[2].set_title('Dust Layer Events')\n",
    "plot_resolution(\n",
    "    dfs['BFRv1'], \n",
    "    x_key=x_key,\n",
    "    y_key=y_key,\n",
    "    fig=fig, ax=axes[2],\n",
    "    mask_func=get_dust_layer_mask,\n",
    "    vmin=vmin, vmax=vmax,\n",
    "    bins=bins,\n",
    ")\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_yscale('linear')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(\n",
    "    plot_dir, 'correlation_masked_{}_{}.png'.format(x_key, y_key)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-transportation",
   "metadata": {},
   "source": [
    "## Angular Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-adult",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "from dnn_cascade_selection.utils.notebook import coordinates\n",
    "from dnn_cascade_selection.utils.notebook import ps_pdf\n",
    "\n",
    "\n",
    "def get_ls_cycler():\n",
    "    return cycle(['-', '--', ':', '-.'])\n",
    "\n",
    "def get_color_cycler(colors=colors):\n",
    "    return cycle(colors)\n",
    "\n",
    "def reweight(ow, energy, gamma, norm=1.0e-18, \n",
    "             e_pivot=1e5, energy_cutoff=None):\n",
    "    \"\"\"Reweight events according to power_law\n",
    "    \"\"\"\n",
    "    n_types = 2.  # Dividing by n_types gives flux per flavor and per type\n",
    "    weight = ow * norm * np.power(energy/e_pivot, -gamma) / n_types\n",
    "    \n",
    "    if energy_cutoff is not None:\n",
    "        weight *= np.exp(-energy / energy_cutoff)\n",
    "    return weight\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "every_nth = 110\n",
    "gamma = 2.5\n",
    "quantiles = np.linspace(0.01, 1, 20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.plot((0., 1.), (0., 1.), ls='--', lw=2., color='0.7')\n",
    "color_cycler = get_color_cycler()\n",
    "\n",
    "# -------\n",
    "# Current\n",
    "# -------\n",
    "for gamma in [2., 2.5, 3.]:\n",
    "    color = next(color_cycler)\n",
    "    weights = reweight(\n",
    "        ow=dfs['BFRv1']['I3MCWeightDict_OneWeight'][::every_nth],\n",
    "        energy=dfs['BFRv1']['I3MCWeightDict_PrimaryNeutrinoEnergy'][::every_nth],\n",
    "        gamma=gamma,\n",
    "    )\n",
    "    _, cov_values = ps_pdf.compute_von_mises_coverage(\n",
    "        dPsi=dfs['BFRv1']['dpsi'].values[::every_nth],\n",
    "        sigma=dfs['BFRv1']['angErr'].values[::every_nth],\n",
    "        weights=weights.values,\n",
    "        quantiles=quantiles,\n",
    "    )\n",
    "    ax.plot(\n",
    "        quantiles, cov_values, \n",
    "        ls='-', color=color,\n",
    "        label='$\\gamma={:.1f}$'.format(gamma)\n",
    "    )\n",
    "    \n",
    "    # uncorrected\n",
    "    if True:\n",
    "        _, cov_values = ps_pdf.compute_von_mises_coverage(\n",
    "            dPsi=dfs['BFRv1']['dpsi'].values[::every_nth],\n",
    "            sigma=dfs['BFRv1']['EventGeneratorSelectedRecoNNCircularUncertainty'].values[::every_nth],\n",
    "            weights=weights.values,\n",
    "            quantiles=quantiles,\n",
    "        )\n",
    "        ax.plot(\n",
    "            quantiles, cov_values, \n",
    "            ls='--', color=color,\n",
    "            label='$\\gamma={:.1f}$ [Uncorrected Sigma]'.format(gamma)\n",
    "        )\n",
    "    \n",
    "\n",
    "ax.set_title('Gamma-Dependent Coverage')\n",
    "ax.set_xlabel('Estimated Quantile')\n",
    "ax.set_ylabel('Actual Quantile')\n",
    "ax.legend()\n",
    "fig.savefig('{}/coverage_gamma.png'.format(plot_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "every_nth = 110\n",
    "gamma = 2.5\n",
    "quantiles = np.linspace(0.01, 1, 20)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.plot((0., 1.), (0., 1.), ls='--', lw=2., color='0.7')\n",
    "\n",
    "names = ['All Events', 'Uncontained Events', 'Dust Layer Events']\n",
    "mask_funcs = [None, get_non_contained_mask, get_dust_layer_mask]\n",
    "\n",
    "color_cycler = get_color_cycler()\n",
    "\n",
    "for name, mask_func in zip(names, mask_funcs):\n",
    "    \n",
    "    color = next(color_cycler)\n",
    "    \n",
    "    if mask_func is None:\n",
    "        mask = np.ones_like(dfs['BFRv1']['dpsi'].values, dtype=bool)\n",
    "    else:\n",
    "        mask = mask_func(dfs['BFRv1'])\n",
    "    \n",
    "    weights = reweight(\n",
    "        ow=dfs['BFRv1']['I3MCWeightDict_OneWeight'][mask][::every_nth],\n",
    "        energy=dfs['BFRv1']['I3MCWeightDict_PrimaryNeutrinoEnergy'][mask][::every_nth],\n",
    "        gamma=gamma,\n",
    "    )\n",
    "        \n",
    "    _, cov_values = ps_pdf.compute_von_mises_coverage(\n",
    "        dPsi=dfs['BFRv1']['dpsi'].values[mask][::every_nth],\n",
    "        sigma=dfs['BFRv1']['angErr'].values[mask][::every_nth],\n",
    "        weights=weights.values,\n",
    "        quantiles=quantiles,\n",
    "    )\n",
    "    ax.plot(\n",
    "        quantiles, cov_values, \n",
    "        ls='-', color=color,\n",
    "        label=name,\n",
    "    )\n",
    "    \n",
    "    # uncorrected\n",
    "    if True:\n",
    "        _, cov_values = ps_pdf.compute_von_mises_coverage(\n",
    "            dPsi=dfs['BFRv1']['dpsi'].values[mask][::every_nth],\n",
    "            sigma=dfs['BFRv1']['EventGeneratorSelectedRecoNNCircularUncertainty'].values[mask][::every_nth],\n",
    "            weights=weights.values,\n",
    "            quantiles=quantiles,\n",
    "        )\n",
    "        ax.plot(\n",
    "            quantiles, cov_values, \n",
    "            ls='--', color=color,\n",
    "            label='{} [Uncorrected Sigma]'.format(name),\n",
    "        )\n",
    "\n",
    "ax.set_title('$\\gamma={:.1f}$'.format(gamma))\n",
    "ax.set_xlabel('Estimated Quantile')\n",
    "ax.set_ylabel('Actual Quantile')\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "fig.savefig('{}/coverage_masked.png'.format(plot_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-navigation",
   "metadata": {},
   "source": [
    "#### Energy-dependent coverage (Paper Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-picnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "embargo_str = 'Under Embargo,\\nNot For Proceedings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-frequency",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "in_percent = True\n",
    "every_nth = 11\n",
    "gamma = 2.5\n",
    "quantiles = np.linspace(0.01, 1, 30)\n",
    "\n",
    "for df_key in ['BFRv1', 'SnowStorm']:\n",
    "    \n",
    "    weights = reweight(\n",
    "        ow=dfs[df_key]['I3MCWeightDict_OneWeight'],\n",
    "        energy=dfs[df_key]['I3MCWeightDict_PrimaryNeutrinoEnergy'],\n",
    "        gamma=gamma,\n",
    "    )\n",
    "    fig, ax = plt.subplots(figsize=(4.5, 2.8))\n",
    "    if in_percent:\n",
    "        ax.plot((0., 100.), (0., 100.), ls='--', lw=2., color='0.8', label='Perfect Coverage')\n",
    "    else:\n",
    "        ax.plot((0., 1.), (0., 1.), ls='--', lw=2., color='0.8', label='Perfect Coverage')\n",
    "    color_cycler = get_color_cycler(colors=['#0B3D53', '#FF7F0E',  '#5C9FC9', '0.7'])\n",
    "    ls_cycler = get_color_cycler(colors=['-', '--',  '-.', ':'])\n",
    "\n",
    "    # -------\n",
    "    # Current\n",
    "    # -------\n",
    "    log10_width = 0.5\n",
    "    for energy in [1000, 10000, 500000]:\n",
    "        e_log10 = np.log10(energy)\n",
    "        color = next(color_cycler)\n",
    "        ls = next(ls_cycler)\n",
    "\n",
    "        if e_log10 < 3:\n",
    "            e_str = '{:.0f} GeV'.format(energy)\n",
    "        elif e_log10 < 6:\n",
    "            e_str = '{:.0f} TeV'.format(energy / 1000.)\n",
    "        else:\n",
    "            e_str = '{:.0f} PeV'.format(energy / 1000000.)\n",
    "\n",
    "        mask = np.logical_and(\n",
    "            dfs[df_key]['I3MCWeightDict_PrimaryNeutrinoEnergy'] >= 10**(e_log10 - log10_width),\n",
    "            dfs[df_key]['I3MCWeightDict_PrimaryNeutrinoEnergy'] < 10**(e_log10 + log10_width),\n",
    "        )\n",
    "\n",
    "        _, cov_values = ps_pdf.compute_von_mises_coverage(\n",
    "            dPsi=dfs[df_key]['dpsi'].values[mask][::every_nth],\n",
    "            sigma=dfs[df_key]['angErr'].values[mask][::every_nth],\n",
    "            weights=weights.values[mask][::every_nth],\n",
    "            quantiles=quantiles,\n",
    "        )\n",
    "        if in_percent:\n",
    "            ax.plot(\n",
    "                quantiles * 100., cov_values * 100., \n",
    "                ls=ls, color=color,\n",
    "                label=r'$E_\\nu$ = {}'.format(e_str),\n",
    "            )\n",
    "        else:\n",
    "            ax.plot(\n",
    "                quantiles, cov_values, \n",
    "                ls=ls, color=color,\n",
    "                label=r'$E_\\nu$ = {}'.format(e_str),\n",
    "            )\n",
    "    \n",
    "    if df_key == 'BFRv1':\n",
    "        panel_str = 'A'\n",
    "        df_str = 'Baseline MC'\n",
    "    elif df_key == 'SnowStorm':\n",
    "        panel_str = 'B'\n",
    "        df_str = 'Systematic MC'\n",
    "    \n",
    "    # add panel labels\n",
    "    ax.text(\n",
    "        0.01, 0.98, panel_str, color='0.', fontsize=18,\n",
    "        va='top', ha='left', transform=ax.transAxes,\n",
    "    )\n",
    "    ax.text(\n",
    "        0.10, 0.95, df_str, color='0.6', fontsize=12,\n",
    "        va='top', ha='left', transform=ax.transAxes,\n",
    "    )\n",
    "    \n",
    "    #ax.set_title('Energy-Dependent Coverage')\n",
    "    if in_percent:\n",
    "        ax.set_xlim(0, 100)\n",
    "        ax.set_ylim(0, 100)\n",
    "        ax.set_xlabel(r'Estimated quantile', fontsize=12)\n",
    "        ax.set_ylabel(r'True quantile', fontsize=12)\n",
    "        \n",
    "        ticks = np.r_[:101:20]\n",
    "        ax.set_xticks(ticks)\n",
    "        ax.set_yticks(ticks)\n",
    "        ax.set_xticklabels([r'${:3.0f}\\,$%'.format(t) for t in ticks])\n",
    "        ax.set_yticklabels([r'${:3.0f}\\,$%'.format(t) for t in ticks])\n",
    "    \n",
    "    else:\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_xlabel('Estimated fraction', fontsize=12)\n",
    "        ax.set_ylabel('True fraction', fontsize=12)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('{}/coverage_energy_{}.png'.format(plot_dir, df_key), dpi=300)\n",
    "    fig.savefig('{}/coverage_energy_{}.pdf'.format(plot_dir, df_key), dpi=300)\n",
    "    \n",
    "    ax.text(\n",
    "        .03, 0.85, embargo_str, \n",
    "        ha='left', va='top', color='red', fontsize=13,\n",
    "        transform=ax.transAxes,\n",
    "    )\n",
    "    fig.savefig('{}/coverage_energy_{}__embargo.png'.format(plot_dir, df_key), dpi=300)\n",
    "    fig.savefig('{}/coverage_energy_{}__embargo.pdf'.format(plot_dir, df_key), dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-syracuse",
   "metadata": {},
   "source": [
    "#### Sigma-dependent coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-bumper",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "every_nth = 110\n",
    "gamma = 2.5\n",
    "quantiles = np.linspace(0.01, 1, 20)\n",
    "\n",
    "weights = reweight(\n",
    "    ow=dfs['BFRv1']['I3MCWeightDict_OneWeight'],\n",
    "    energy=dfs['BFRv1']['I3MCWeightDict_PrimaryNeutrinoEnergy'],\n",
    "    gamma=gamma,\n",
    ")\n",
    "\n",
    "weights_sys = reweight(\n",
    "    ow=dfs['SnowStorm']['I3MCWeightDict_OneWeight'],\n",
    "    energy=dfs['SnowStorm']['I3MCWeightDict_PrimaryNeutrinoEnergy'],\n",
    "    gamma=gamma,\n",
    ")\n",
    "\n",
    "dfs['BFRv1']['angErr_deg'] = np.rad2deg(dfs['BFRv1']['angErr'])\n",
    "dfs['SnowStorm']['angErr_deg'] = np.rad2deg(dfs['SnowStorm']['angErr'])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.plot((0., 1.), (0., 1.), ls='--', lw=2., color='0.7')\n",
    "color_cycler = get_color_cycler()\n",
    "\n",
    "sigma_ranges = [[1, 5], [5, 10], [10, 20], [20, 40]]\n",
    "\n",
    "# -------\n",
    "# Current\n",
    "# -------\n",
    "for sigma_range in sigma_ranges:\n",
    "    color = next(color_cycler)\n",
    "    \n",
    "    # baseline\n",
    "    if False:\n",
    "        mask = np.logical_and(\n",
    "            dfs['BFRv1']['angErr_deg'] >= sigma_range[0],\n",
    "            dfs['BFRv1']['angErr_deg'] < sigma_range[1],\n",
    "        )\n",
    "\n",
    "        _, cov_values = ps_pdf.compute_von_mises_coverage(\n",
    "            dPsi=dfs['BFRv1']['dpsi'].values[mask][::every_nth],\n",
    "            sigma=dfs['BFRv1']['angErr'].values[mask][::every_nth],\n",
    "            weights=weights.values[mask][::every_nth],\n",
    "            quantiles=quantiles,\n",
    "        )\n",
    "        ax.plot(\n",
    "            quantiles, cov_values, \n",
    "            ls='-', color=color,\n",
    "            label='$\\sigma \\in [{:.1e}°, {:.1e}°]$ (sys)'.format(*sigma_range),\n",
    "        )\n",
    "    \n",
    "    # SnowStorm\n",
    "    if True:\n",
    "        mask = np.logical_and(\n",
    "            dfs['SnowStorm']['angErr_deg'] >= sigma_range[0],\n",
    "            dfs['SnowStorm']['angErr_deg'] < sigma_range[1],\n",
    "        )\n",
    "\n",
    "        _, cov_values = ps_pdf.compute_von_mises_coverage(\n",
    "            dPsi=dfs['SnowStorm']['dpsi'].values[mask][::every_nth],\n",
    "            sigma=dfs['SnowStorm']['angErr'].values[mask][::every_nth],\n",
    "            weights=weights_sys.values[mask][::every_nth],\n",
    "            quantiles=quantiles,\n",
    "        )\n",
    "        ax.plot(\n",
    "            quantiles, cov_values, \n",
    "            ls='--', color=color,\n",
    "            label='$\\sigma \\in [{:.1e}°, {:.1e}°]$ (sys)'.format(*sigma_range),\n",
    "        )\n",
    "    \n",
    "\n",
    "ax.set_title('Sigma-Dependent Coverage')\n",
    "ax.set_xlabel('Estimated Quantile')\n",
    "ax.set_ylabel('Actual Quantile')\n",
    "ax.legend()\n",
    "#fig.savefig('{}/coverage_energy.png'.format(plot_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-issue",
   "metadata": {},
   "source": [
    "#### Plot for reviewer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-cooking",
   "metadata": {},
   "source": [
    "Also, I understand from the same Supplement C that the energy dependency of this angular smearing is accounted for by considering the estimated angular uncertainty coming from the direction reconstruction on an event-by-event basis (namely sigma_i). Is this quantity linearly dependent on the angular error with respect to the true neutrino direction? I.e. if the authors were to produce a 2D plot of the angular resolution as a function of sigma_i, would they find a straight line with a constant dispersion around the \"diagonal\" or would this dispersion be dependent on sigma_i (and maybe also on the event energy). Usually, these correction tend to decrease sensitivities/significance. I would like to see a statement on how this is actually treated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import scipy.stats\n",
    "\n",
    "def rW(n, kappa, m):\n",
    "    dim = m-1\n",
    "    b = dim / (np.sqrt(4*kappa*kappa + dim*dim) + 2*kappa)\n",
    "    x = (1-b) / (1+b)\n",
    "    c = kappa*x + dim*np.log(1-x*x)\n",
    "\n",
    "    y = []\n",
    "    for i in range(0,n):\n",
    "        done = False\n",
    "        while not done:\n",
    "            z = sc.stats.beta.rvs(dim/2,dim/2)\n",
    "            w = (1 - (1+b)*z) / (1 - (1-b)*z)\n",
    "            u = sc.stats.uniform.rvs()\n",
    "            if kappa*w + dim*np.log(1-x*w) - c >= np.log(u):\n",
    "                done = True\n",
    "        y.append(w)\n",
    "    return np.array(y)\n",
    "\n",
    "def rvMF(n,theta):\n",
    "    dim = len(theta)\n",
    "    kappa = np.linalg.norm(theta)\n",
    "    mu = theta / kappa\n",
    "\n",
    "    result = []\n",
    "    for sample in range(0,n):\n",
    "        w = rW(1, kappa,dim)\n",
    "        v = np.random.randn(dim)\n",
    "        v = v / np.linalg.norm(v)\n",
    "\n",
    "        result.append(np.sqrt(1-w**2)*v + w*mu)\n",
    "\n",
    "    return np.array(result)\n",
    "\n",
    "n = 10\n",
    "kappa = 100000\n",
    "direction = np.array([1, 0, 0])\n",
    "direction = direction / np.linalg.norm(direction)\n",
    "\n",
    "res_sampling = rvMF(n, kappa * direction)\n",
    "res_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-colleague",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs['BFRv1']\n",
    "df = dfs['SnowStorm']\n",
    "gamma = 2.5\n",
    "\n",
    "df['angErr_deg'] = np.rad2deg(df['angErr'])\n",
    "\n",
    "if False:\n",
    "    weights = reweight(\n",
    "        ow=df['I3MCWeightDict_OneWeight'],\n",
    "        energy=df['I3MCWeightDict_PrimaryNeutrinoEnergy'],\n",
    "        gamma=gamma,\n",
    "    )\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 6))\n",
    "    ax.hist2d(np.rad2deg(df['angErr']), df['dpsi_deg'], bins=100, weights=weights)\n",
    "    ax.set_xlim(0, 40)\n",
    "    ax.set_ylim(0, 40)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "ax.plot(np.inf, np.inf, color=soft_colors[0], ls='-', label='All events')\n",
    "plot_angular_resolution(\n",
    "    df,\n",
    "    key_x='angErr_deg',\n",
    "    bins=(np.r_[2:20:0.3], np.r_[0:180.01:.01]),\n",
    "    color=soft_colors[0],\n",
    "    fig=fig, ax=ax,\n",
    "    xscale='linear',\n",
    ")\n",
    "ax.set_xlabel('Estimated angular uncertainty $\\sigma$ / °')\n",
    "\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "#fig.savefig(os.path.join(plot_dir, 'angular_res_sigma.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-palestinian",
   "metadata": {},
   "source": [
    "## Angular Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "plot_angular_resolution(\n",
    "    dfs['BFRv1'],\n",
    "    color=soft_colors[0],\n",
    "    fig=fig, ax=ax,\n",
    ")\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-postcard",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "ax.plot(np.inf, np.inf, color=soft_colors[0], ls='-', label='All events')\n",
    "plot_angular_resolution(\n",
    "    dfs['BFRv1'],\n",
    "    key_x='distance_hull',\n",
    "    bins=(np.r_[-450:241:35.], np.r_[0:180.01:.01]),\n",
    "    color=soft_colors[0],\n",
    "    fig=fig, ax=ax,\n",
    "    xscale='linear',\n",
    ")\n",
    "\n",
    "ax.plot(np.inf, np.inf, color=soft_colors[1], ls='-', label='Events > 100 TeV')\n",
    "def get_above_100TeV_mask(df):\n",
    "    return df['LabelsDeepLearning_PrimaryEnergy'] > 1e5\n",
    "\n",
    "plot_angular_resolution(\n",
    "    dfs['BFRv1'],\n",
    "    key_x='distance_hull',\n",
    "    bins=(np.r_[-450:241:35.], np.r_[0:180.01:.01]),\n",
    "    color=soft_colors[1],\n",
    "    fig=fig, ax=ax,\n",
    "    xscale='linear',\n",
    "    mask_func=get_above_100TeV_mask,\n",
    ")\n",
    "ax.set_xlabel('Distance to convex hull / m')\n",
    "\n",
    "ax.legend(ncol=2)\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(plot_dir, 'angular_res_distance_hull.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-waste",
   "metadata": {},
   "source": [
    "##### Contained/Outside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-passenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "ax.plot(np.inf, np.inf, color=soft_colors[0], ls='-', label='Contained')\n",
    "plot_angular_resolution(\n",
    "    dfs['BFRv1'],\n",
    "    mask_func=get_contained_mask,\n",
    "    color=soft_colors[0],\n",
    "    fig=fig, ax=ax,\n",
    ")\n",
    "\n",
    "ax.plot(np.inf, np.inf, color=soft_colors[1], ls='-', label='Outside')\n",
    "plot_angular_resolution(\n",
    "    dfs['BFRv1'],\n",
    "    mask_func=get_non_contained_mask,\n",
    "    color=soft_colors[1],\n",
    "    fig=fig, ax=ax,\n",
    ")\n",
    "\n",
    "if False:\n",
    "    ax.plot(np.inf, np.inf, color=soft_colors[2], ls='-', label='Dust Layer')\n",
    "    plot_angular_resolution(\n",
    "        dfs['BFRv1'],\n",
    "        mask_func=get_dust_layer_mask,\n",
    "        color=soft_colors[2],\n",
    "        fig=fig, ax=ax,\n",
    "    )\n",
    "\n",
    "if False:\n",
    "    ax.plot(np.inf, np.inf, color=soft_colors[3], ls='-', label='MESC Equivalent')\n",
    "    plot_angular_resolution(\n",
    "        dfs['BFRv1'],\n",
    "        mask_func=get_mesc_equivalent,\n",
    "        color=soft_colors[3],\n",
    "        fig=fig, ax=ax,\n",
    "    )\n",
    "\n",
    "\n",
    "ax.legend(ncol=2)\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(plot_dir, 'angular_res_containment.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-minister",
   "metadata": {},
   "source": [
    "##### Dust Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "ax.plot(np.inf, np.inf, color=soft_colors[0], ls='-', label='Dust Layer')\n",
    "plot_angular_resolution(\n",
    "    dfs['BFRv1'],\n",
    "    mask_func=get_dust_layer_mask,\n",
    "    color=soft_colors[0],\n",
    "    fig=fig, ax=ax,\n",
    ")\n",
    "\n",
    "ax.plot(np.inf, np.inf, color=soft_colors[1], ls='-', label='No-Dust Layer')\n",
    "plot_angular_resolution(\n",
    "    dfs['BFRv1'],\n",
    "    mask_func=get_non_dust_layer_mask,\n",
    "    color=soft_colors[1],\n",
    "    fig=fig, ax=ax,\n",
    ")\n",
    "\n",
    "ax.set_title('Dust Layer Comparison ($z \\in [-150~\\mathrm{m}, 0~\\mathrm{m}]$)')\n",
    "ax.legend(ncol=2)\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(plot_dir, 'angular_res_dust_layer.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-thesis",
   "metadata": {},
   "source": [
    "#### MESC 7yr Comparison plots (Paper Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "repo = cy.selections.Repository()\n",
    "specs = cy.selections.MESEDataSpecs.mesc_7yr\n",
    "selection_version = 'version-001-p02'\n",
    "\n",
    "ana = cy.get_analysis(repo, selection_version, specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ana.anas[0]\n",
    "a.sig, a.bg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sig['dpsi'] = cy.utils.coord.delta_angle(\n",
    "    azimuth1=a.sig.ra, \n",
    "    zenith1=a.sig.dec, \n",
    "    azimuth2=a.sig.true_ra, \n",
    "    zenith2=a.sig.true_dec, \n",
    "    latlon=True,\n",
    ")\n",
    "a.sig.dpsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesc_cascade_label = 'Previous Cascade Analysis (14)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-profit",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_systematic_curve = False\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 3.5))\n",
    "\n",
    "colors = ['#0B3D53', '#FF7F0E',  '#5C9FC9']\n",
    "\n",
    "ang_res_kwargs = dict(\n",
    "    range=((5e2, 1e7), (0, 180)), \n",
    "    log=(True, False),\n",
    "    bins=(15, 10**4),\n",
    "    #bins=(np.logspace(2.25, 7.56, 15),10**4),\n",
    "    #bins=(10**np.r_[2.25:7.56:.45], np.r_[0:40.01:.01]),\n",
    "    #bins=(10**np.r_[2.6:7.2:.15], np.r_[0:40.01:.01]),\n",
    ")\n",
    "\n",
    "astro_weights = reweight(\n",
    "    ow=dfs['BFRv1']['I3MCWeightDict_OneWeight'],\n",
    "    energy=dfs['BFRv1']['I3MCWeightDict_PrimaryNeutrinoEnergy'],\n",
    "    gamma=2.5,\n",
    ")\n",
    "astro_weights_sys = reweight(\n",
    "    ow=dfs['SnowStorm']['I3MCWeightDict_OneWeight'],\n",
    "    energy=dfs['SnowStorm']['I3MCWeightDict_PrimaryNeutrinoEnergy'],\n",
    "    gamma=2.5,\n",
    ")\n",
    "astro_weights_mesc = reweight(\n",
    "    ow=a.sig.oneweight,\n",
    "    energy=a.sig.true_energy,\n",
    "    gamma=2.5,\n",
    ")\n",
    "\n",
    "_, _, hists = plot_angular_resolution(\n",
    "    dfs['BFRv1'],\n",
    "    key_x='LabelsDeepLearning_PrimaryEnergy', \n",
    "    label=r'$\\leq {:.0f}\\%$ This work',\n",
    "    #bins=(10**np.r_[2.25:8.26:.45], np.r_[0:180.01:.01]),\n",
    "    median_kwargs=dict(label=r'$50\\%$ This work (all events)', lw=2, ls='-'),\n",
    "    color=colors[0],\n",
    "    fig=fig, ax=ax,\n",
    "    weights=astro_weights,\n",
    "    **ang_res_kwargs\n",
    ")\n",
    "\n",
    "if add_systematic_curve:\n",
    "    _, _, hists_sys = plot_angular_resolution(\n",
    "        dfs['SnowStorm'],\n",
    "        key_x='LabelsDeepLearning_PrimaryEnergy', \n",
    "        #bins=(10**np.r_[2.25:8.26:.45], np.r_[0:180.01:.01]),\n",
    "        color='0.8',\n",
    "        fig=fig, ax=ax,\n",
    "        draw_only_median=True,\n",
    "        median_kwargs=dict(label=r'$50\\%$ This work (with systematics)', lw=2, ls='-'),\n",
    "        weights=astro_weights_sys,\n",
    "        set_xlim=False,\n",
    "        **ang_res_kwargs\n",
    "    )\n",
    "\n",
    "_, _, hists2 = plot_angular_resolution(\n",
    "    dfs['BFRv1'],\n",
    "    key_x='LabelsDeepLearning_PrimaryEnergy', \n",
    "    #bins=(10**np.r_[2.25:8.26:.45], np.r_[0:180.01:.01]),\n",
    "    color=colors[1],\n",
    "    fig=fig, ax=ax,\n",
    "    mask_func=get_mesc_equivalent,\n",
    "    draw_only_median=True,\n",
    "    median_kwargs=dict(label=r'$50\\%$ This work (contained events)', lw=2, ls='--'),\n",
    "    weights=astro_weights,\n",
    "    set_xlim=False,\n",
    "    **ang_res_kwargs\n",
    ")\n",
    "\n",
    "_, _, hists3 = plot_angular_resolution(\n",
    "    a.sig,\n",
    "    key_x='true_energy', \n",
    "    #bins=(10**np.r_[2.25:7.5:.45], np.r_[0:180.01:.01]),\n",
    "    color=colors[2],\n",
    "    fig=fig, ax=ax,\n",
    "    draw_only_median=True,\n",
    "    #median_kwargs=dict(label=r'$50\\%$ Cascades [Aartsen et al(2019)]', lw=2, ls='-.'),\n",
    "    #median_kwargs=dict(label=r'$50\\%$ Cascades [IceCube(2019)]', lw=2, ls='-.'),\n",
    "    median_kwargs=dict(label=r'$50\\%$ ' + mesc_cascade_label, lw=2, ls='-.'),\n",
    "    weights=astro_weights_mesc,\n",
    "    dpsi_deg=np.rad2deg(a.sig.dpsi),\n",
    "    range=((5e2, 1e7), (0, 180)), \n",
    "    log=(True, False),\n",
    "    bins=(15, 1000),\n",
    "    #bins=(10**np.r_[2.25:7.2:.15], np.r_[0:180.01:.01]),\n",
    "    plot_lim=(800, np.inf),\n",
    "    set_xlim=False,\n",
    ")\n",
    "\n",
    "\n",
    "#ax.set_xlim(1e3, 1e7)\n",
    "ticks = np.r_[0:41:5]\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_yticklabels([r'{:2.0f}°'.format(t) for t in ticks])\n",
    "ax.set_ylim(0, max(ticks))\n",
    "ax.legend(ncol=2)\n",
    "ax.set_ylabel(r'Opening Angle $\\Delta \\Psi$')\n",
    "ax.set_xlabel(r'Neutrino Energy $E_\\nu$ / GeV')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(plot_dir, 'angular_res_mesc_comparison.png'), dpi=300)\n",
    "fig.savefig(os.path.join(plot_dir, 'angular_res_mesc_comparison.pdf'), dpi=300)\n",
    "\n",
    "ax.text(\n",
    "    .5, 0.69, embargo_str, \n",
    "    ha='left', va='top', color='red', fontsize=18,\n",
    "    transform=ax.transAxes,\n",
    ")\n",
    "fig.savefig(os.path.join(plot_dir, 'angular_res_mesc_comparison__embargo.png'), dpi=300)\n",
    "fig.savefig(os.path.join(plot_dir, 'angular_res_mesc_comparison__embargo.pdf'), dpi=300)\n",
    "\n",
    "# systematic impact:\n",
    "# 1 TeV: ~5%\n",
    "# 10 TeV: ~15%\n",
    "# 100 TeV: ~25%\n",
    "# 1 PeV: ~28.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-arkansas",
   "metadata": {},
   "source": [
    "###### Event vertex distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "mesc_hdf_dir = '/data/user/mrichman/mesc7_pub/data/data/Fullsample'\n",
    "\n",
    "def get_mesc7yr_data(hdf5_file, key='L5MonopodFit4'):\n",
    "    df_mesc7yr_i = pd.read_hdf(hdf5_file, key='L5MonopodFit4')\n",
    "    \n",
    "    # get is_cascade_reco\n",
    "    is_cascade_reco = pd.read_hdf(\n",
    "        hdf5_file, key='IsCascade_reco', columns=['value'])['value'].values > 0\n",
    "    \n",
    "    return df_mesc7yr_i.iloc[is_cascade_reco]\n",
    "\n",
    "df_mesc7yr_list = []\n",
    "for hdf5_file in sorted(glob.glob(os.path.join(mesc_hdf_dir, '*/*.hdf5'))):\n",
    "    df_mesc7yr_list.append(get_mesc7yr_data(hdf5_file=hdf5_file))\n",
    "\n",
    "df_mesc7yr = pd.concat(df_mesc7yr_list)\n",
    "\n",
    "assert np.allclose(df_mesc7yr.Run, a.bg_data.run)\n",
    "assert np.allclose(df_mesc7yr.Event, a.bg_data.event)\n",
    "\n",
    "for key in a.bg_data.keys():\n",
    "    print('Addding key:', key)\n",
    "    df_mesc7yr['ana_'+key] = np.array(a.bg_data[key])\n",
    "\n",
    "# Add distance to convex hull\n",
    "add_distance_to_hull(df_mesc7yr, reco_key='')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-guatemala",
   "metadata": {},
   "source": [
    "#### MESC/DNNCascade Comparison 2D Nevents (Paper Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantity_func(df, mask):\n",
    "    return len(df[mask])\n",
    "\n",
    "add_ratio = False\n",
    "\n",
    "# define binning\n",
    "x_edges = np.linspace(-500, 210, 31)\n",
    "y_edges_exp = np.linspace(np.log10(500), 7, 31)\n",
    "y_edges = 10**y_edges_exp\n",
    "x_width = 0.5*np.diff(x_edges)[0]\n",
    "y_width = 0.5*np.diff(y_edges_exp)[0]\n",
    "\n",
    "norm = mpl.colors.LogNorm(vmin=1, vmax=1e3)\n",
    "#norm = mpl.colors.Normalize(vmin=1, vmax=1e3)\n",
    "norm_ratio = mpl.colors.LogNorm(vmin=1e-2, vmax=1e2)\n",
    "\n",
    "if add_ratio:\n",
    "    fig, axes = plt.subplots(\n",
    "        1, 3, sharey=True, figsize=(12, 6), constrained_layout=True, \n",
    "        gridspec_kw=dict(width_ratios=[4, 4, 3]))\n",
    "else:\n",
    "    fig, axes = plt.subplots(\n",
    "        1, 2, sharey=True, figsize=(8.0, 3.4), constrained_layout=True)\n",
    "    \n",
    "_, _, values_dnnc = plot_2d_quantity(\n",
    "    df=dfs['_exp'], \n",
    "    x_key='distance_hull', \n",
    "    y_key='energy', \n",
    "    quantity_func=quantity_func, \n",
    "    x_edges=x_edges, \n",
    "    y_edges=y_edges, \n",
    "    x_width=x_width, \n",
    "    y_width=y_width,\n",
    "    y_width_in_log=True,\n",
    "    norm=norm,\n",
    "    label_quantity='Number of Events',\n",
    "    fig=fig, ax=axes[0],\n",
    "    plot_colorbar=False,\n",
    "    convert=None,\n",
    "    do_not_show_zeros=True,\n",
    ")\n",
    "axes[0].set_yscale('log')\n",
    "#axes[0].set_title('This Work')\n",
    "axes[0].text(\n",
    "    0.10, 0.97, 'This Work', color='0.6', fontsize=12,\n",
    "    va='top', ha='left', transform=axes[0].transAxes,\n",
    ")\n",
    "\n",
    "_, _, values_mesc7yr = plot_2d_quantity(\n",
    "    df=df_mesc7yr, \n",
    "    x_key='distance_hull', \n",
    "    y_key='energy', \n",
    "    quantity_func=quantity_func, \n",
    "    x_edges=x_edges, \n",
    "    y_edges=y_edges, \n",
    "    x_width=x_width, \n",
    "    y_width=y_width,\n",
    "    y_width_in_log=True,\n",
    "    norm=norm,\n",
    "    label_quantity='Number of Events',\n",
    "    fig=fig, ax=axes[1],\n",
    "    cb_axis=axes[:2],\n",
    "    cb_kwargs=dict(location='right', shrink=1.0, aspect=40, pad=0.005),\n",
    "    convert=None,\n",
    "    do_not_show_zeros=True,\n",
    ")\n",
    "axes[1].set_yscale('log')\n",
    "#axes[1].set_title('Cascades [Aartsen et al (2019)]')\n",
    "#axes[1].set_title('Cascades [IceCube (2019)]')\n",
    "#axes[1].set_title(mesc_cascade_label)\n",
    "axes[1].text(\n",
    "    0.10, 0.97, mesc_cascade_label, color='0.6', fontsize=12,\n",
    "    va='top', ha='left', transform=axes[1].transAxes,\n",
    ")\n",
    "\n",
    "# ratio\n",
    "if add_ratio:\n",
    "    im = axes[2].pcolormesh(x_edges, y_edges, values_dnnc.T / values_mesc7yr.T, cmap=plt.cm.get_cmap('RdBu_r', 15), norm=norm_ratio)\n",
    "    cb = plt.colorbar(im, ax=axes[2], location='right', shrink=1.0)\n",
    "    cb.set_label('Ratio: This work/MESC 7yr')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlabel('Distance to Detector Boundary / m')\n",
    "    ax.set_xticks(np.r_[-500:201:100])\n",
    "\n",
    "axes[0].set_ylabel('Reconstructed Energy $E_\\mathrm{reco}$ / GeV')\n",
    "\n",
    "# add panel label\n",
    "axes[0].text(\n",
    "    .01, 0.98, 'A', \n",
    "    ha='left', va='top', color='0.', fontsize=18,\n",
    "    transform=axes[0].transAxes,\n",
    ")\n",
    "axes[1].text(\n",
    "    .01, 0.98, 'B', \n",
    "    ha='left', va='top', color='0.', fontsize=18,\n",
    "    transform=axes[1].transAxes,\n",
    ")\n",
    "\n",
    "fig.savefig(os.path.join(\n",
    "    plot_dir, 'mesc_comparison_num_events2d_energy_radius.png'), dpi=300)\n",
    "fig.savefig(os.path.join(\n",
    "    plot_dir, 'mesc_comparison_num_events2d_energy_radius.pdf'), dpi=300)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.text(\n",
    "        .01, 0.99, embargo_str, \n",
    "        ha='left', va='top', color='red', fontsize=14,\n",
    "        transform=ax.transAxes,\n",
    "    )\n",
    "fig.savefig(os.path.join(\n",
    "    plot_dir, 'mesc_comparison_num_events2d_energy_radius__embargo.png'), dpi=300)\n",
    "fig.savefig(os.path.join(\n",
    "    plot_dir, 'mesc_comparison_num_events2d_energy_radius__embargo.pdf'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "        1, 2, sharey=True, figsize=(9, 6), constrained_layout=True)\n",
    "\n",
    "axes[0].scatter(dfs['_exp']['distance_hull'], dfs['_exp']['energy'], alpha=0.2)\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].set_title('This Work')\n",
    "\n",
    "axes[1].scatter(df_mesc7yr['distance_hull'], df_mesc7yr['energy'], alpha=0.2)\n",
    "axes[1].set_yscale('log')\n",
    "#axes[1].set_title('Cascades [Aartsen et al (2019)]')\n",
    "axes[1].set_title('Cascades [IceCube (2019)]')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlabel('Distance to Detector Boundary / m')\n",
    "    ax.set_xlim(-500, 210)\n",
    "    ax.set_ylim(500, 1e7)\n",
    "    \n",
    "axes[0].set_ylabel('$E_\\mathrm{reco}$ / GeV')\n",
    "\n",
    "fig.savefig(os.path.join(\n",
    "    plot_dir, 'mesc_comparison_scatter_energy_radius.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-portfolio",
   "metadata": {},
   "source": [
    "## Get dataset overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-angel",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_mesc7yr = set()\n",
    "for i in range(len(df_mesc7yr)):\n",
    "    events_mesc7yr.add((df_mesc7yr.Run.iloc[i], df_mesc7yr.Event.iloc[i], df_mesc7yr.SubEvent.iloc[i]))\n",
    "\n",
    "events_dnncascade = set()\n",
    "for i in range(len(dfs['_exp'])):\n",
    "    events_dnncascade.add((dfs['_exp'].run.iloc[i], dfs['_exp'].event.iloc[i], dfs['_exp'].subevent.iloc[i]))  \n",
    "\n",
    "print(len(events_dnncascade), len(events_mesc7yr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-nepal",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapping = len(events_dnncascade.intersection(events_mesc7yr))\n",
    "mesc_not_in_dnn = events_mesc7yr.difference(events_dnncascade)\n",
    "dnn_not_in_mesc = events_dnncascade.difference(events_mesc7yr)\n",
    "n_mesc_not_in_dnn = len(mesc_not_in_dnn)\n",
    "n_dnn_not_in_mesc = len(dnn_not_in_mesc)\n",
    "\n",
    "print('Number of events in DNNCascade 10yr:', len(events_dnncascade))\n",
    "print('Number of events in MESC 7yr:', len(events_mesc7yr))\n",
    "print('Number of overlapping events:', overlapping)\n",
    "print('Number of events in MESC 7yr but not in DNNCascade:', n_mesc_not_in_dnn)\n",
    "print('Number of events in DNNCascade but not in MESC 7yr:', n_dnn_not_in_mesc)\n",
    "\n",
    "def get_df_from_set(event_set):\n",
    "    run = []\n",
    "    event = []\n",
    "    subevent = []\n",
    "    for set_i in event_set:\n",
    "        run.append(set_i[0])\n",
    "        event.append(set_i[1])\n",
    "        subevent.append(set_i[2])\n",
    "    df = pd.DataFrame({\n",
    "        'run':run,\n",
    "        'event': event,\n",
    "        'subevent': subevent,\n",
    "    })\n",
    "    return df\n",
    "\n",
    "if True:\n",
    "    print('Saving to {}'.format(plot_dir))\n",
    "    df_events = get_df_from_set(mesc_not_in_dnn)\n",
    "    df_events.to_pickle('{}/events_mesc_not_in_dnn.pickle'.format(plot_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesc_not_in_dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-heading",
   "metadata": {},
   "outputs": [],
   "source": [
    "(124861, 68517081, 1) in mesc_not_in_dnn\n",
    "(128027, 64761685, 0) in mesc_not_in_dnn\n",
    "(128027, 64761685, 0) in events_dnncascade\n",
    "#(115975, 40600729, 0) in mesc_not_in_dnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-copyright",
   "metadata": {},
   "source": [
    "## Energy Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-oriental",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_std(x, weights=None):\n",
    "    \"\"\"\"\n",
    "        Weighted std deviation.\n",
    "        Source: http://www.itl.nist.gov/div898/software/dataplot/refman2/ch2/weightsd.pdf\n",
    "\n",
    "        returns 0 if len(x)==1\n",
    "    \"\"\"\n",
    "    if len(x) == 1:\n",
    "        return 0\n",
    "\n",
    "    if weights is None:\n",
    "        return np.std(x, ddof=1)\n",
    "\n",
    "    x = np.asarray(x)\n",
    "    weights = np.asarray(weights)\n",
    "\n",
    "    w_mean_x = np.average(x, weights=weights)\n",
    "    n = len(weights[weights != 0])\n",
    "\n",
    "    s = n * np.sum(weights*(x - w_mean_x)*(x - w_mean_x)) / ((n - 1) * np.sum(weights))\n",
    "    return np.sqrt(s)\n",
    "\n",
    "def weighted_quantile(x, weights, quantile):\n",
    "\n",
    "    if weights is None:\n",
    "        weights = np.ones_like(x)\n",
    "\n",
    "    sorted_indices = np.argsort(x)\n",
    "    x_sorted = x[sorted_indices]\n",
    "    weights_sorted = weights[sorted_indices]\n",
    "    cum_weights = np.cumsum(weights_sorted) / np.sum(weights)\n",
    "    idx = np.searchsorted(cum_weights, quantile)\n",
    "    return x_sorted[idx]\n",
    "\n",
    "def get_relative_resolution(proxy, label, label_mids, label_width_factor, weights=None, min_events=100):\n",
    "    '''\n",
    "    Calculates resolution in terms of relative residuals for an observable that is being used\n",
    "    as a proxy for the desired label.\n",
    "\n",
    "    Parameters:\n",
    "    ---------\n",
    "    proxy: array_like\n",
    "        Observable that is meant to be used as a proxy for the label\n",
    "    label: array_like\n",
    "        The label values for which to calculate the resolution.\n",
    "    label_mids: array_like\n",
    "        The points at which to compute the resolution.\n",
    "    label_width_factor: float\n",
    "        Events within `E_i / label_width_factor` and `E_i * label_width_factor` are considered when evaluating\n",
    "        the bin at E_i.\n",
    "    weights: array_like\n",
    "        Weight for each event, If None, each event is assigned weight 1.\n",
    "    Returns:\n",
    "    --------\n",
    "    resolution: tuple\n",
    "        E_i, std_dev_i\n",
    "        The evaluated points and std. deviations at these points.\n",
    "    '''\n",
    "    label_list = []\n",
    "    q_68_list = []\n",
    "    std_dev_list = []\n",
    "    \n",
    "    for label_mid in label_mids:\n",
    "        mask = np.logical_and(\n",
    "            label >= label_mid / label_width_factor,\n",
    "            label < label_mid * label_width_factor,\n",
    "        )\n",
    "        residuals = proxy[mask] - label[mask]\n",
    "        rel_residuals = residuals / label[mask]\n",
    "        abs_rel_residuals = np.abs(rel_residuals)\n",
    "        q_68 = weighted_quantile(abs_rel_residuals, weights=weights[mask], quantile=0.68)\n",
    "        std_dev = weighted_std(rel_residuals, weights=weights[mask])\n",
    "        #std_dev = weighted_std(residuals, weights=weights[mask]) / label_mid\n",
    "        \n",
    "        if np.sum(mask) > min_events:\n",
    "            label_list.append(label_mid)\n",
    "            q_68_list.append(q_68)\n",
    "            std_dev_list.append(std_dev)\n",
    "        else:\n",
    "            print(e_i, np.sum(mask))\n",
    "        \n",
    "    label_list = np.array(label_list)\n",
    "    q_68_list = np.array(q_68_list)\n",
    "    std_dev_list = np.array(std_dev_list)\n",
    "    \n",
    "    return label_list, q_68_list, std_dev_list\n",
    "    \n",
    "def get_proxy_resolution(proxy, label, proxy_bins, label_bins, weights=None, verbose=True):\n",
    "    '''\n",
    "    Calculates resolution for an observable that is being used\n",
    "    as a proxy for the desired label.\n",
    "\n",
    "    Parameters:\n",
    "    ---------\n",
    "    proxy: array_like\n",
    "        Observable that is meant to be used as a proxy for the label\n",
    "    label: array_like\n",
    "        The label values for which to calculate the resolution.\n",
    "    proxy_bins: array_like\n",
    "        bins keyword for np.histogram that defines proxy bins\n",
    "    label_bins: array_like\n",
    "        bins keyword for np.histogram that defines label bins\n",
    "    weights: array_like\n",
    "        Weight for each event, If None, each event is assigned weight 1.\n",
    "    Returns:\n",
    "    --------\n",
    "    resolution: tuple\n",
    "            overall resolution, resolution bins, resolution, std_dev, rmse\n",
    "            A list containing the resolution for each label_bin\n",
    "    '''\n",
    "\n",
    "    if weights is None:\n",
    "        weights = np.ones(len(label))\n",
    "\n",
    "    # ---------------------\n",
    "    # get proxy and label bin_edges\n",
    "    # ---------------------\n",
    "    _, proxy_bin_edges = np.histogram(proxy, bins=proxy_bins)\n",
    "    _, label_bin_edges = np.histogram(label, bins=label_bins)\n",
    "\n",
    "    num_proxy_bins = len(proxy_bin_edges) - 1\n",
    "    num_label_bins = len(label_bin_edges) - 1\n",
    "\n",
    "    # get proxy and label bin indices for all events\n",
    "    # subtract 1 because digitize starts at one\n",
    "    proxy_bins_indices = np.digitize(proxy, bins=proxy_bin_edges) - 1\n",
    "    label_bins_indices = np.digitize(label, bins=label_bin_edges) - 1\n",
    "\n",
    "    label_bin_mids = label_bin_edges[:-1] + (\n",
    "        label_bin_edges[1:] - label_bin_edges[:-1])/2.\n",
    "\n",
    "    proxy_bin_widths = proxy_bin_edges[1:] - proxy_bin_edges[:-1]\n",
    "    label_bin_widths = label_bin_edges[1:] - label_bin_edges[:-1]\n",
    "\n",
    "    # ---------------------\n",
    "    # get distribution in proxy observable for a given label bin P(O|E=E'+-dE')\n",
    "    # for all label bins\n",
    "    # ---------------------\n",
    "    P_of_O_given_E_bins = []\n",
    "    for label_bin in range(num_label_bins):\n",
    "\n",
    "        # get a mask of all events in this label bin\n",
    "        mask_events_in_label_bin = label_bins_indices == label_bin\n",
    "\n",
    "        # get distribution in proxy observable for a given label \n",
    "        # bin P(O|E=E'+-dE')\n",
    "        if len(proxy[mask_events_in_label_bin]) > 0:\n",
    "            P_of_O_given_E, _ = np.histogram(\n",
    "                proxy[mask_events_in_label_bin],\n",
    "                bins=proxy_bin_edges,\n",
    "                weights=weights[mask_events_in_label_bin],\n",
    "                density=True)\n",
    "        else:\n",
    "            if verbose:\n",
    "                print('No events in label bin number {}'.format(label_bin))\n",
    "            P_of_O_given_E = np.zeros(num_proxy_bins)\n",
    "\n",
    "        P_of_O_given_E_bins.append(P_of_O_given_E)\n",
    "\n",
    "    P_of_O_given_E_bins = np.asarray(P_of_O_given_E_bins)\n",
    "\n",
    "    # ---------------------\n",
    "    # get distribution in label for a given proxy value bin P(E|O=O'+-dO')\n",
    "    # for all proxy bins\n",
    "    # ---------------------\n",
    "    P_of_E_given_O_bins = []\n",
    "    for proxy_bin in range(num_proxy_bins):\n",
    "\n",
    "        # get a mask of all events in this proxy bin\n",
    "        mask_events_in_proxy_bin = proxy_bins_indices == proxy_bin\n",
    "\n",
    "        # get distribution in label observable for a given proxy value bin P(E|O=O'+-dO')\n",
    "        if len(label[mask_events_in_proxy_bin]) > 0:\n",
    "            P_of_E_given_O, _ = np.histogram(\n",
    "                label[mask_events_in_proxy_bin],\n",
    "                bins=label_bin_edges,\n",
    "                weights=weights[mask_events_in_proxy_bin],\n",
    "                density=True)\n",
    "        else:\n",
    "            if verbose:\n",
    "                print('No events in proxy bin number {}'.format(proxy_bin))\n",
    "            P_of_E_given_O = np.zeros(num_label_bins)\n",
    "\n",
    "        P_of_E_given_O_bins.append(P_of_E_given_O)\n",
    "\n",
    "    P_of_E_given_O_bins = np.asarray(P_of_E_given_O_bins)\n",
    "\n",
    "    # ---------------------\n",
    "    # Calculate resolution for each label bin\n",
    "    # Todo: possible speed up through matrix operations?\n",
    "    # ---------------------\n",
    "    resolution = []\n",
    "    resolution_label_bins = []\n",
    "    overall_resolution = 0\n",
    "    overall_resolution_norm = 0\n",
    "\n",
    "    # go through all label bins\n",
    "    for label_bin in range(num_label_bins):\n",
    "\n",
    "        # perform discretized integral over all proxy bins\n",
    "        # sum of all distributions P(E|O=O')*P(O=O'|E=E')\n",
    "        # for all given proxy values O' in O\n",
    "        integral_distribution = np.zeros(num_label_bins)\n",
    "        for proxy_bin in range(num_proxy_bins):\n",
    "\n",
    "            # calculate P(E|O=O')*P(O=O'|E=E')\n",
    "            integral_distribution += (\n",
    "                P_of_E_given_O_bins[proxy_bin] * proxy_bin_widths[proxy_bin] \n",
    "                * P_of_O_given_E_bins[label_bin, proxy_bin]\n",
    "            )\n",
    "\n",
    "        # only add resolution and label bin, if any events were in it\n",
    "        inegral_sum = np.sum(integral_distribution)\n",
    "        if inegral_sum > 0.0:\n",
    "            res = weighted_std(label_bin_mids,weights=integral_distribution)\n",
    "            overall_resolution += res*inegral_sum\n",
    "            overall_resolution_norm += inegral_sum\n",
    "            resolution.append(res)\n",
    "            resolution_label_bins.append(label_bin_mids[label_bin])\n",
    "        else:\n",
    "            if verbose:\n",
    "                print('Skipping empty label bin {}'.format(label_bin))\n",
    "\n",
    "    overall_resolution /= overall_resolution_norm\n",
    "\n",
    "    std_dev_in_proxy = []\n",
    "    std_dev_residuals = []\n",
    "    rmse_residuals = []\n",
    "    for label_bin in range(num_label_bins):\n",
    "        mask_events_in_label_bin = label_bins_indices == label_bin\n",
    "        if label_bin_mids[label_bin] in resolution_label_bins:\n",
    "            std_dev_in_proxy.append(weighted_std(proxy[mask_events_in_label_bin],weights=weights[mask_events_in_label_bin]))\n",
    "            residuals = proxy[mask_events_in_label_bin] - label[mask_events_in_label_bin]\n",
    "            std_dev_residuals.append(weighted_std(residuals,weights=weights[mask_events_in_label_bin]))\n",
    "            mse = np.sum( (residuals*weights[mask_events_in_label_bin])**2) / np.sum(weights[mask_events_in_label_bin]**2)\n",
    "            rmse_residuals.append(np.sqrt(mse))\n",
    "\n",
    "    return overall_resolution, np.asarray(resolution_label_bins), np.asarray(resolution), np.asarray(std_dev_residuals), np.asarray(rmse_residuals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-resistance",
   "metadata": {},
   "source": [
    "##### Resolution Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_resolution, resolution_label_bins, resolution, std_dev_residuals, rmse_residuals = get_proxy_resolution(\n",
    "    proxy=dfs['BFRv1']['energy'], \n",
    "    label=dfs['BFRv1']['LabelsDeepLearning_PrimaryEnergy'], \n",
    "    proxy_bins=np.logspace(2.7, 6.7, 15), \n",
    "    label_bins=np.logspace(2.7, 6.7, 15), \n",
    "    weights=dfs['BFRv1']['weights'], \n",
    "    verbose=True,\n",
    ")\n",
    "resolution\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.plot(resolution_label_bins, resolution / resolution_label_bins * 100.)\n",
    "ax.plot(resolution_label_bins, std_dev_residuals / resolution_label_bins * 100.)\n",
    "ax.set_xscale('log')\n",
    "#ax.set_ylim(0)\n",
    "#ax.set_yscale('log')\n",
    "ax.set_xlabel(r'Neutrino Energy $E_\\nu$ [GeV]')\n",
    "ax.set_ylabel(r'Relative resolution $\\sigma \\, / \\, E_\\nu$ [%]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_key = 'LabelsDeepLearning_PrimaryEnergy'\n",
    "#label_key = 'LabelsDeepLearning_EnergyVisible'\n",
    "label_key = 'LabelsDeepLearning_TotalDepositedEnergy'\n",
    "\n",
    "compute_res_in_log = True\n",
    "\n",
    "def get_mask(df):\n",
    "    return df['LabelsDeepLearning_p150_p_starting_cc_e'] > 0.5\n",
    "    #return df['LabelsDeepLearning_p_starting_cc_e'] > 0.5\n",
    "    return np.ones_like(df['LabelsDeepLearning_p_starting_cc_e'], dtype=bool)\n",
    "\n",
    "mask_dep = get_mask(dfs['BFRv1'])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "if compute_res_in_log:\n",
    "    overall_resolution, resolution_label_bins, resolution, std_dev_residuals, rmse_residuals = get_proxy_resolution(\n",
    "        proxy=np.log10(dfs['BFRv1']['energy'][mask_dep]), \n",
    "        label=np.log10(dfs['BFRv1'][label_key][mask_dep]), \n",
    "        proxy_bins=np.linspace(np.log10(500), 6.7, 15), \n",
    "        label_bins=np.linspace(np.log10(500), 6.7, 15), \n",
    "        weights=dfs['BFRv1']['weights'][mask_dep], \n",
    "        verbose=True,\n",
    "    )\n",
    "    ax.plot(10**resolution_label_bins, resolution, label='resolution')\n",
    "    ax.plot(10**resolution_label_bins, std_dev_residuals, label='std. dev.')\n",
    "    ax.plot(10**resolution_label_bins, rmse_residuals, label='RMSE')\n",
    "    ax.set_ylabel(r'Energy resolution: $\\sigma_{\\log_{10}E_\\nu}$')\n",
    "else:\n",
    "    overall_resolution, resolution_label_bins, resolution, std_dev_residuals, rmse_residuals = get_proxy_resolution(\n",
    "        proxy=dfs['BFRv1']['energy'][mask_dep], \n",
    "        label=dfs['BFRv1'][label_key][mask_dep], \n",
    "        proxy_bins=np.logspace(np.log10(500), 6.7, 55), \n",
    "        label_bins=np.logspace(np.log10(500), 6.7, 55), \n",
    "        weights=dfs['BFRv1']['weights'][mask_dep], \n",
    "        verbose=True,\n",
    "    )\n",
    "    ax.plot(resolution_label_bins, resolution / resolution_label_bins, label='resolution')\n",
    "    ax.plot(resolution_label_bins, std_dev_residuals / resolution_label_bins, label='std. dev.')\n",
    "    ax.plot(resolution_label_bins, rmse_residuals / resolution_label_bins, label='RMSE')\n",
    "    ax.set_ylabel(r'Energy resolution: $\\sigma / E_\\mathrm{true}$[%]')\n",
    "resolution\n",
    "\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel(r'Neutrino Energy $E_\\nu$ / GeV')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_key = 'LabelsDeepLearning_PrimaryEnergy'\n",
    "#label_key = 'LabelsDeepLearning_EnergyVisible'\n",
    "label_key = 'LabelsDeepLearning_TotalDepositedEnergy'\n",
    "\n",
    "\n",
    "eps = 1e-6\n",
    "res = np.log10(dfs['BFRv1']['energy'] + eps) - np.log10(dfs['BFRv1'][label_key] + eps)\n",
    "res = res.values\n",
    "abs_res = np.abs(res)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(res, bins=100, weights=dfs['BFRv1']['weights'])\n",
    "ax.set_xlabel(r'$\\log_{10}(E_\\mathrm{rec}) - \\log_{10}(E_\\nu)$')\n",
    "ax.set_yscale('log')\n",
    "print(np.std(res), weighted_quantile(res, weights=dfs['BFRv1']['weights'].values, quantile=[0.16, 0.84]))\n",
    "print(np.std(abs_res), weighted_quantile(abs_res, weights=dfs['BFRv1']['weights'].values, quantile=[0.68, 0.9]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-bowling",
   "metadata": {},
   "source": [
    "#### Energy Resolution (Paper Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-entity",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(5, 4))\n",
    "gs = fig.add_gridspec(2, 2, height_ratios=[10, 3], width_ratios=[29, 1], hspace=0)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "ax_cb = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "e_range = (2.7, 6.7)\n",
    "e_range_res = (2.9, 6.6)\n",
    "compute_res_in_log = False\n",
    "show_as_percentage = True\n",
    "\n",
    "plot_resolution(\n",
    "    dfs['BFRv1'], \n",
    "    x_key='LabelsDeepLearning_PrimaryEnergy',\n",
    "    y_key='energy',\n",
    "    vmin=5e-4, vmax=5e-1,\n",
    "    bins=np.logspace(*e_range, 30),\n",
    "    fig=fig, ax=ax1, plot_colorbar=True, cb_axis=None,\n",
    "    cb_kwargs=dict(cax=ax_cb, aspect=100, pad=0.005),\n",
    ")\n",
    "if compute_res_in_log:\n",
    "    overall_resolution, resolution_label_bins, resolution, std_dev_residuals, rmse_residuals = get_proxy_resolution(\n",
    "        proxy=np.log10(dfs['BFRv1']['energy']), \n",
    "        label=np.log10(dfs['BFRv1']['LabelsDeepLearning_PrimaryEnergy']), \n",
    "        proxy_bins=np.linspace(*e_range_res, 35), \n",
    "        label_bins=np.linspace(*e_range_res, 35), \n",
    "        weights=dfs['BFRv1']['weights'], \n",
    "        verbose=True,\n",
    "    )\n",
    "    if show_as_percentage:\n",
    "        ax2.plot(10**resolution_label_bins, (10**resolution - 1)*100., color='0.3')\n",
    "        ax2.plot(10**resolution_label_bins, (10**std_dev_residuals - 1)*100., color='0.3', ls='--')\n",
    "    else:\n",
    "        ax2.plot(10**resolution_label_bins, resolution, color='0.3')\n",
    "        ax2.plot(10**resolution_label_bins, std_dev_residuals, color='0.3', ls='--')\n",
    "        \n",
    "else:\n",
    "    overall_resolution, resolution_label_bins, resolution, std_dev_residuals, rmse_residuals = get_proxy_resolution(\n",
    "        proxy=dfs['BFRv1']['energy'], \n",
    "        label=dfs['BFRv1']['LabelsDeepLearning_PrimaryEnergy'], \n",
    "        proxy_bins=np.logspace(*e_range_res, 35), \n",
    "        label_bins=np.logspace(*e_range_res, 35), \n",
    "        weights=dfs['BFRv1']['weights'], \n",
    "        verbose=True,\n",
    "    )\n",
    "    \n",
    "    if show_as_percentage:\n",
    "        pass\n",
    "        #ax2.plot(resolution_label_bins, resolution / resolution_label_bins * 100., color='0.3')\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "label_list, q_68_list, std_dev_list = get_relative_resolution(\n",
    "    proxy=dfs['BFRv1']['energy'].values, \n",
    "    label=dfs['BFRv1']['LabelsDeepLearning_PrimaryEnergy'].values, \n",
    "    label_mids=np.logspace(*e_range_res, 55), \n",
    "    label_width_factor=1.15, \n",
    "    weights=dfs['BFRv1']['weights'].values,\n",
    ")\n",
    "\n",
    "    \n",
    "if show_as_percentage:\n",
    "    ax2.set_ylabel(r'$\\sigma \\, / \\, E_\\nu$')\n",
    "    ax2.set_ylim(0, 100)\n",
    "    \n",
    "    ticks = [0, 50, 100]\n",
    "    ax2.set_yticks(ticks)\n",
    "    ax2.set_yticklabels([r'{:2.0f}%'.format(t) for t in ticks])\n",
    "    \n",
    "    ax2.plot(label_list, q_68_list * 100., color='0.3', ls='-', label='Q68%')\n",
    "    #ax2.plot(label_list, std_dev_list * 100., color='0.3', ls='-.', label='std. dev.')\n",
    "else:\n",
    "    ax2.set_ylabel(r'$\\sigma_{\\log_{10}E_\\nu}$')\n",
    "    ax2.set_ylim(0, 0.70)\n",
    "    \n",
    "ax2.set_xscale('log')\n",
    "ax2.set_xlabel(r'Neutrino Energy $E_\\nu$ / GeV ')\n",
    "ax2.grid(color='0.9', ls='--')\n",
    "\n",
    "ax1.axes.xaxis.set_ticklabels([])\n",
    "ax1.set_xlabel(None)\n",
    "ax1.set_xlim(10**e_range[0], 10**e_range[1])\n",
    "ax2.set_xlim(10**e_range[0], 10**e_range[1])\n",
    "\n",
    "#axes[1].set_xlabel('$E_\\mathrm{true}$ / GeV')\n",
    "ax1.set_ylabel('Reconstructed Energy $E_\\mathrm{reco}$ / GeV')\n",
    "\n",
    "# add panel label\n",
    "ax1.text(\n",
    "    .01, 0.98, 'A', \n",
    "    ha='left', va='top', color='0.', fontsize=18,\n",
    "    transform=ax1.transAxes,\n",
    ")\n",
    "ax2.text(\n",
    "    .01, 0.95, 'B', \n",
    "    ha='left', va='top', color='0.', fontsize=18,\n",
    "    transform=ax2.transAxes,\n",
    ")\n",
    "\n",
    "#fig.tight_layout()\n",
    "fig.savefig(os.path.join(plot_dir, 'energy_resolution.png'), dpi=300)\n",
    "fig.savefig(os.path.join(plot_dir, 'energy_resolution.pdf'), dpi=300)\n",
    "\n",
    "ax1.text(\n",
    "    .02, 0.88, embargo_str, \n",
    "    ha='left', va='top', color='red', fontsize=14,\n",
    "    transform=ax1.transAxes,\n",
    ")\n",
    "fig.savefig(os.path.join(plot_dir, 'energy_resolution__embargo.png'), dpi=300)\n",
    "fig.savefig(os.path.join(plot_dir, 'energy_resolution__embargo.pdf'), dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-litigation",
   "metadata": {},
   "source": [
    "##### Deposited Energy Resolution (Paper Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(5, 4))\n",
    "gs = fig.add_gridspec(2, 2, height_ratios=[10, 3], width_ratios=[29, 1], hspace=0)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "ax_cb = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "e_range = (2.7, 6.7)\n",
    "e_range_res = (2.9, 6.6)\n",
    "compute_res_in_log = False\n",
    "show_as_percentage = True\n",
    "label_key = 'LabelsDeepLearning_TotalDepositedEnergy'\n",
    "#label_key = 'LabelsDeepLearning_EnergyVisible'\n",
    "#label_key = 'LabelsDeepLearning_PrimaryEnergy'\n",
    "\n",
    "def get_mask(df):\n",
    "    return df['LabelsDeepLearning_p150_p_starting_cc_e'] > 0.5\n",
    "    #return df['LabelsDeepLearning_p_starting_cc_e'] > 0.5\n",
    "    return np.ones_like(df['LabelsDeepLearning_p_starting_cc_e'], dtype=bool)\n",
    "\n",
    "mask_dep = get_mask(dfs['BFRv1'])\n",
    "\n",
    "plot_resolution(\n",
    "    dfs['BFRv1'], \n",
    "    x_key=label_key,\n",
    "    y_key='energy',\n",
    "    vmin=5e-4, vmax=5e-1,\n",
    "    bins=np.logspace(*e_range, 30),\n",
    "    fig=fig, ax=ax1, plot_colorbar=True, cb_axis=None,\n",
    "    cb_kwargs=dict(cax=ax_cb, aspect=100, pad=0.005),\n",
    "    mask_func=get_mask,\n",
    ")\n",
    "\n",
    "if compute_res_in_log:\n",
    "    overall_resolution, resolution_label_bins, resolution, std_dev_residuals, rmse_residuals = get_proxy_resolution(\n",
    "        proxy=np.log10(dfs['BFRv1']['energy'][mask_dep]), \n",
    "        label=np.log10(dfs['BFRv1'][label_key][mask_dep]), \n",
    "        proxy_bins=np.linspace(*e_range_res, 35), \n",
    "        label_bins=np.linspace(*e_range_res, 35), \n",
    "        weights=dfs['BFRv1']['weights'][mask_dep], \n",
    "        verbose=True,\n",
    "    )\n",
    "    if show_as_percentage:\n",
    "        ax2.plot(10**resolution_label_bins, (10**resolution - 1)*100., color='0.3')\n",
    "        ax2.plot(10**resolution_label_bins, (10**std_dev_residuals - 1)*100., color='0.3', ls='--')\n",
    "    else:\n",
    "        ax2.plot(10**resolution_label_bins, resolution, color='0.3')\n",
    "        ax2.plot(10**resolution_label_bins, std_dev_residuals, color='0.3', ls='--')\n",
    "else:\n",
    "    overall_resolution, resolution_label_bins, resolution, std_dev_residuals, rmse_residuals = get_proxy_resolution(\n",
    "        proxy=dfs['BFRv1']['energy'][mask_dep], \n",
    "        label=dfs['BFRv1'][label_key][mask_dep], \n",
    "        proxy_bins=np.logspace(*e_range_res, 35), \n",
    "        label_bins=np.logspace(*e_range_res, 35), \n",
    "        weights=dfs['BFRv1']['weights'][mask_dep], \n",
    "        verbose=True,\n",
    "    )\n",
    "    if show_as_percentage:\n",
    "        pass\n",
    "        #ax2.plot(resolution_label_bins, resolution / resolution_label_bins * 100., color='0.3')\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "label_list, q_68_list, std_dev_list = get_relative_resolution(\n",
    "    proxy=dfs['BFRv1']['energy'][mask_dep].values, \n",
    "    label=dfs['BFRv1'][label_key][mask_dep].values, \n",
    "    label_mids=np.logspace(*e_range_res, 55), \n",
    "    label_width_factor=1.1, \n",
    "    weights=dfs['BFRv1']['weights'][mask_dep].values,\n",
    ")\n",
    "\n",
    "if show_as_percentage:\n",
    "    ax2.set_ylabel(r'$\\sigma \\, / \\, E_\\mathrm{dep}$')\n",
    "    ax2.set_ylim(0, 20)\n",
    "    \n",
    "    ticks = [0, 10, 20]\n",
    "    ax2.set_yticks(ticks)\n",
    "    ax2.set_yticklabels([r'{:2.0f}%'.format(t) for t in ticks])\n",
    "    \n",
    "    ax2.plot(label_list, q_68_list * 100., color='0.3', ls='-', label='Q68%')\n",
    "    #ax2.plot(label_list, std_dev_list * 100., color='0.3', ls='-.', label='std. dev.')\n",
    "else:\n",
    "    ax2.set_ylabel(r'$\\sigma_{\\log_{10}E_\\mathrm{dep}}$')\n",
    "    ax2.set_ylim(0, 0.15)\n",
    "    \n",
    "\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_xlabel(r'Deposited Energy $E_\\mathrm{dep}$ / GeV')\n",
    "ax2.grid(color='0.9', ls='--')\n",
    "\n",
    "ax1.axes.xaxis.set_ticklabels([])\n",
    "ax1.set_xlabel(None)\n",
    "ax1.set_xlim(10**e_range[0], 10**e_range[1])\n",
    "ax2.set_xlim(10**e_range[0], 10**e_range[1])\n",
    "\n",
    "#axes[1].set_xlabel('$E_\\mathrm{true}$ / GeV')\n",
    "ax1.set_ylabel('Reconstructed Energy $E_\\mathrm{reco}$ / GeV')\n",
    "\n",
    "#ax1.text(600, 2e6, s=r'Charged-Current $\\nu_e$', ha='left', color='0.6')\n",
    "ax1.text(\n",
    "    .12, 0.95, r'Charged-Current $\\nu_e$',\n",
    "    ha='left', va='top', color='0.6',\n",
    "    transform=ax1.transAxes,\n",
    ")\n",
    "\n",
    "# add panel label\n",
    "ax1.text(\n",
    "    .01, 0.98, 'C', \n",
    "    ha='left', va='top', color='0.', fontsize=18,\n",
    "    transform=ax1.transAxes,\n",
    ")\n",
    "ax2.text(\n",
    "    .01, 0.95, 'D', \n",
    "    ha='left', va='top', color='0.', fontsize=18,\n",
    "    transform=ax2.transAxes,\n",
    ")\n",
    "\n",
    "#fig.tight_layout()\n",
    "fig.savefig(os.path.join(plot_dir, 'energy_resolution_deposited.png'), dpi=300)\n",
    "fig.savefig(os.path.join(plot_dir, 'energy_resolution_deposited.pdf'), dpi=300)\n",
    "\n",
    "ax1.text(\n",
    "    .02, 0.88, embargo_str, \n",
    "    ha='left', va='top', color='red', fontsize=14,\n",
    "    transform=ax1.transAxes,\n",
    ")\n",
    "fig.savefig(os.path.join(plot_dir, 'energy_resolution_deposited__embargo.png'), dpi=300)\n",
    "fig.savefig(os.path.join(plot_dir, 'energy_resolution_deposited__embargo.pdf'), dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-public",
   "metadata": {},
   "source": [
    "##### Correlation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-orange",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_resolution(\n",
    "    dfs['BFRv1'], \n",
    "    x_key='LabelsDeepLearning_PrimaryEnergy',\n",
    "    y_key='energy',\n",
    "    vmin=5e-6, vmax=5e-1,\n",
    "    figsize=(6, 4),\n",
    ")\n",
    "ax.set_xlabel('$E_\\mathrm{true}$ / GeV')\n",
    "ax.set_ylabel('$E_\\mathrm{reco}$ / GeV')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(plot_dir, 'correlation_energy_reco_true.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-amber",
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_keys = [\n",
    "    'EventGeneratorSelectedRecoNN_I3Particle',\n",
    "]\n",
    "energy_keys = [\n",
    "    'LabelsDeepLearning_TotalDepositedEnergy',\n",
    "    'LabelsDeepLearning_EnergyVisible',\n",
    "    'LabelsDeepLearning_PrimaryEnergy',\n",
    "]\n",
    "\n",
    "for reco_key in reco_keys:\n",
    "    for energy_key in energy_keys:\n",
    "        fig, ax = plot_resolution(\n",
    "            dfs['BFRv1'], \n",
    "            x_key=energy_key,\n",
    "            y_key=reco_key + '_energy',\n",
    "            vmin=5e-6, vmax=5e-1,\n",
    "            figsize=(6, 4),\n",
    "        )\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(os.path.join(\n",
    "            plot_dir, 'correlation_{}_{}.png'.format(reco_key, energy_key)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-system",
   "metadata": {},
   "source": [
    "##### Masked energy resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_keys = [\n",
    "    'EventGeneratorSelectedRecoNN_I3Particle',\n",
    "]\n",
    "energy_keys = [\n",
    "    'LabelsDeepLearning_TotalDepositedEnergy',\n",
    "    'LabelsDeepLearning_EnergyVisible',\n",
    "    'LabelsDeepLearning_PrimaryEnergy',\n",
    "]\n",
    "vmin = 5e-6\n",
    "vmax = 5e-1\n",
    "\n",
    "for reco_key in reco_keys:\n",
    "    for energy_key in energy_keys:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n",
    "        \n",
    "        axes[0].set_title('All Events')\n",
    "        plot_resolution(\n",
    "            dfs['BFRv1'], \n",
    "            x_key=energy_key,\n",
    "            y_key=reco_key + '_energy',\n",
    "            fig=fig, ax=axes[0],\n",
    "            vmin=vmin, vmax=vmax,\n",
    "        )\n",
    "        \n",
    "        axes[1].set_title('Uncontained Events')\n",
    "        plot_resolution(\n",
    "            dfs['BFRv1'], \n",
    "            x_key=energy_key,\n",
    "            y_key=reco_key + '_energy',\n",
    "            fig=fig, ax=axes[1],\n",
    "            mask_func=get_non_contained_mask,\n",
    "            vmin=vmin, vmax=vmax,\n",
    "        )\n",
    "        \n",
    "        axes[2].set_title('Dust Layer Events')\n",
    "        plot_resolution(\n",
    "            dfs['BFRv1'], \n",
    "            x_key=energy_key,\n",
    "            y_key=reco_key + '_energy',\n",
    "            fig=fig, ax=axes[2],\n",
    "            mask_func=get_dust_layer_mask,\n",
    "            vmin=vmin, vmax=vmax,\n",
    "        )\n",
    "        \n",
    "        fig.tight_layout()\n",
    "        fig.savefig(os.path.join(\n",
    "            plot_dir, 'correlation_masked_{}_{}.png'.format(reco_key, energy_key)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-apple",
   "metadata": {},
   "source": [
    "### Relative Contributions of atmospheric background\n",
    "\n",
    "We make statements in the paper on the values, here we calculate their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([k for k in dfs['BFRv1'].keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "atmo_weight = (\n",
    "    dfs['BFRv1']['weights_MCEq_H3a_sibyll2_3c_total']\n",
    "     * dfs['BFRv1']['nuveto_pf_dnn_cascade_selection_H3a_SIBYLL2_3c_total']\n",
    ")\n",
    "\n",
    "conversion = {\n",
    "    -16: 'nutau',\n",
    "    16: 'nutau',\n",
    "    -14: 'numu',\n",
    "    14: 'numu',\n",
    "    -12: 'nue',\n",
    "    12: 'nue',\n",
    "}\n",
    "\n",
    "# make sure all types are covered\n",
    "assert sorted(np.unique(dfs['BFRv1']['I3MCWeightDict_PrimaryNeutrinoType'])) == sorted(conversion.keys())\n",
    "\n",
    "total_weight = 0\n",
    "weight_sum_dict = {'nutau': 0, 'numu': 0, 'nue': 0}\n",
    "for pdg_key, name in conversion.items():\n",
    "    mask = dfs['BFRv1']['I3MCWeightDict_PrimaryNeutrinoType'] == pdg_key\n",
    "    n_events = np.sum(atmo_weight[mask]) * livetime\n",
    "    total_weight += n_events\n",
    "    weight_sum_dict[name] += n_events\n",
    "    \n",
    "assert np.allclose(total_weight, weight_sum_dict['numu'] + weight_sum_dict['nue'] + weight_sum_dict['nutau'])\n",
    "\n",
    "for key, n_events in weight_sum_dict.items():\n",
    "    print('Flavor: {}\\t| Fraction: {:3.3f}%'.format(key, n_events/total_weight * 100))\n",
    "\n",
    "\n",
    "mask_numu_cc = dfs['BFRv1']['LabelsDeepLearning_p150_p_starting_cc_mu'] > 0.5\n",
    "print('NuMu CC  \\t| Fraction: {:3.3f}%'.format(np.sum(atmo_weight[mask_numu_cc])*livetime/total_weight * 100))\n",
    "\n",
    "for l in [15, 20, 50, 100, 125, 150, 200, 300]:\n",
    "    mask_length = dfs['BFRv1']['LabelsDeepLearning_LengthInDetector'] > l\n",
    "    print('Tracklength > {}m\\t| Fraction: {:3.3f}%'.format(l, np.sum(atmo_weight[mask_length])*livetime/total_weight * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-investigator",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2.3_py3-v4.1.0_csky",
   "language": "python",
   "name": "tensorflow2.3_py3-v4.1.0_csky"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-projection",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#PDFs in BDT and sindec?\n",
    "import os\n",
    "\n",
    "# set env flags to catch BLAS used for scipy/numpy \n",
    "# to only use 1 cpu, n_cpus will be totally controlled by csky\n",
    "os.environ['MKL_NUM_THREADS'] = \"1\"\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = \"1\"\n",
    "os.environ['OMP_NUM_THREADS'] = \"1\"\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = \"1\"\n",
    "os.environ['VECLIB_MAXIMUM_THREADS'] = \"1\"\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.facecolor'] = 'w'\n",
    "mpl.rcParams['savefig.facecolor'] = 'w'\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors, cm\n",
    "import csky as cy\n",
    "from csky import cext\n",
    "import numpy as np\n",
    "import astropy\n",
    "#from icecube import astro\n",
    "import histlite as hl\n",
    "import healpy\n",
    "import socket\n",
    "import pickle\n",
    "import copy\n",
    "healpy.disable_warnings()\n",
    "plt.rc('figure', facecolor = 'w')\n",
    "plt.rc('figure', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-investigator",
   "metadata": {},
   "source": [
    "## Define Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_version = 'version-001-p01'\n",
    "\n",
    "host_name = socket.gethostname()\n",
    "\n",
    "if 'cobalt' in host_name:\n",
    "    print('Working on Cobalts')\n",
    "    data_prefix = '/data/user/ssclafani/data/cscd/final'\n",
    "    ana_dir = '/data/user/ssclafani/data/analyses/'\n",
    "    plot_dir = '/home/mhuennefeld/public_html/analyses/DNNCascade/plots/review/containment_performance'\n",
    "    \n",
    "elif 'phobos' in host_name:\n",
    "    print('Working on Phobos')\n",
    "    data_prefix = '/net/big-tank/POOL/users/mhuennefeld/analyses/DNNCascade/data/cscd/final'\n",
    "    ana_dir = '/net/big-tank/POOL/users/mhuennefeld/analyses/DNNCascade/csky/analyses/'\n",
    "    plot_dir = '/home/mhuennefeld/analyses/DNNCascade/plots/review/containment_performance'\n",
    "    \n",
    "else:\n",
    "    raise ValueError('Unknown host:', host_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-alabama",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir_path in [plot_dir]:\n",
    "    if not os.path.exists(dir_path):\n",
    "        print('Creating directory:', dir_path)\n",
    "        os.makedirs(dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-burns",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnn_cascade_selection.utils.notebook import coordinates\n",
    "from ic3_labels.labels.utils import geometry\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from dnn_reco.ic3 import llh\n",
    "\n",
    "def get_circular_unc(df, reco_key='DeepLearningReco_event_selection_egen_seed_dir_01'):\n",
    "    sigmas = np.empty_like(df[reco_key + '_PrimaryDirectionX'])\n",
    "    for i in tqdm(range(len(sigmas)), total=len(sigmas)):\n",
    "        llh_obj = llh.DNN_LLH_Circular_Dir(\n",
    "            dir_x=df[reco_key + '_PrimaryDirectionX'][i],\n",
    "            dir_y=df[reco_key + '_PrimaryDirectionY'][i],\n",
    "            dir_z=df[reco_key + '_PrimaryDirectionZ'][i],\n",
    "            unc_x=df[reco_key + '_PrimaryDirectionX_uncertainty'][i],\n",
    "            unc_y=df[reco_key + '_PrimaryDirectionY_uncertainty'][i],\n",
    "            unc_z=df[reco_key + '_PrimaryDirectionZ_uncertainty'][i],\n",
    "            num_samples=10,\n",
    "        )\n",
    "        sigmas[i] = np.sqrt(llh_obj.cov[0, 0])\n",
    "    return sigmas\n",
    "\n",
    "class DNNCascade_10yr_dnn_reco(cy.selections.DNNCascadeDataSpecs.DNNCascade_10yr):\n",
    "    def dataset_modifications(self, ds):\n",
    "        n_jobs = 25\n",
    "        reco_key = 'DeepLearningReco_event_selection_egen_seed_dir_01'\n",
    "        energy_key = 'DeepLearningReco_event_selection_egen_seed_energy_01'\n",
    "        print('Swapping reconstrucion to DNN-reco ({}, {})'.format(reco_key, energy_key))\n",
    "        \n",
    "        # add reconstructed vertex\n",
    "        print('Loading reco for data...')\n",
    "        dfs = []\n",
    "        for data_path in self._path_data:\n",
    "            path_exp_df = (\n",
    "                '/data/ana/PointSource/DNNCascade/analysis/' + \n",
    "                data_path.format(version=self._version).replace('dnn_cascades/', '').replace('.npy', '.hdf')\n",
    "            )\n",
    "            dfs.append(pd.read_hdf(path_exp_df, key='df'))\n",
    "        df = pd.concat(dfs)\n",
    "        assert np.allclose(df['run'], ds.data.run)\n",
    "        assert np.allclose(df['energy'], ds.data.energy)\n",
    "        for k in df.keys():\n",
    "            if reco_key in k or energy_key in k:\n",
    "                ds.data[k] = df[k]\n",
    "                \n",
    "        print('Loading reco for MC...')\n",
    "        path_sig_df = (\n",
    "            '/data/ana/PointSource/DNNCascade/analysis/' + \n",
    "            self._path_sig.format(version=self._version).replace('dnn_cascades/', '').replace('.npy', '.hdf')\n",
    "        )\n",
    "        df = pd.read_hdf(path_sig_df, key='df')\n",
    "        assert np.allclose(df['run'], ds.sig.run)\n",
    "        assert np.allclose(df['energy'], ds.sig.energy)\n",
    "        assert np.allclose(df['ow'], ds.sig.oneweight)\n",
    "        for k in df.keys():\n",
    "            if reco_key in k or energy_key in k:\n",
    "                ds.sig[k] = df[k]\n",
    "        \n",
    "        # swap energy reco\n",
    "        print('Swapping energy reco...')\n",
    "        ds.data['log10energy'] = np.log10(ds.data[energy_key + '_I3Particle_energy'])\n",
    "        ds.data['energy'] = ds.data[energy_key + '_I3Particle_energy']\n",
    "        ds.sig['log10energy'] = np.log10(ds.sig[energy_key + '_I3Particle_energy'])\n",
    "        ds.sig['energy'] = ds.sig[energy_key + '_I3Particle_energy']\n",
    "        \n",
    "        # swap direction reco\n",
    "        print('Swapping direction reco...')\n",
    "        ds.data['azimuth'] = ds.data[reco_key + '_I3Particle_azimuth']\n",
    "        ds.data['zenith'] = ds.data[reco_key + '_I3Particle_zenith']\n",
    "        ds.data['ra'], ds.data['dec'] = coordinates.dir_to_equa(\n",
    "            ds.data.zenith, ds.data.azimuth, ds.data.mjd, n_jobs=n_jobs)\n",
    "        \n",
    "        ds.sig['azimuth'] = ds.sig[reco_key + '_I3Particle_azimuth']\n",
    "        ds.sig['zenith'] = ds.sig[reco_key + '_I3Particle_zenith']\n",
    "        ds.sig['ra'], ds.sig['dec'] = coordinates.dir_to_equa(\n",
    "            ds.sig.zenith, ds.sig.azimuth, ds.sig.mjd, n_jobs=n_jobs)\n",
    "        \n",
    "        # xdec, xra\n",
    "        print('Computing xra, xdec...')\n",
    "        xdec, xra = cy.coord.rotate_source_to_xaxis(\n",
    "            ds.sig.true_dec, ds.sig.true_ra, ds.sig.dec, ds.sig.ra, latlon=True\n",
    "        )\n",
    "        xra[xra < np.pi] += 2*np.pi\n",
    "        xra[xra > np.pi] -= 2*np.pi\n",
    "        ds.sig['xra'] = xra\n",
    "        ds.sig['xdec'] = xdec\n",
    "        #ds.sig['dpsi'] = np.sqrt(xra**2 + xdec**2)\n",
    "        \n",
    "        print('Computing sigma...')\n",
    "        ds.data['sigma'] = get_circular_unc(df=ds.data, reco_key=reco_key)\n",
    "        ds.sig['sigma'] = get_circular_unc(df=ds.sig, reco_key=reco_key)\n",
    "        \n",
    "\n",
    "def get_distance_to_hull(df, reco_key='EventGeneratorSelectedRecoNN_I3Particle'):\n",
    "    pos = np.array([\n",
    "        df[reco_key + '_x'],\n",
    "        df[reco_key + '_y'],\n",
    "        df[reco_key + '_z'],\n",
    "    ]).T\n",
    "    distances = np.empty_like(df[reco_key + '_x'])\n",
    "    for i, pos_i in tqdm(enumerate(pos), total=len(pos)):\n",
    "        distances[i] = geometry.distance_to_icecube_hull(pos_i)\n",
    "    return distances\n",
    "\n",
    "\n",
    "class DNNCascade_10yr_contained(cy.selections.DNNCascadeDataSpecs.DNNCascade_10yr):\n",
    "    def dataset_modifications(self, ds):\n",
    "        print('Removing non-contained events weights to MC')\n",
    "        \n",
    "        # add reconstructed vertex\n",
    "        print('Loading vertex for data...')\n",
    "        dfs = []\n",
    "        for data_path in self._path_data:\n",
    "            path_exp_df = (\n",
    "                '/data/ana/PointSource/DNNCascade/analysis/' + \n",
    "                data_path.format(version=self._version).replace('dnn_cascades/', '').replace('.npy', '.hdf')\n",
    "            )\n",
    "            dfs.append(pd.read_hdf(path_exp_df, key='df'))\n",
    "        df = pd.concat(dfs)\n",
    "        assert np.allclose(df['run'], ds.data.run)\n",
    "        assert np.allclose(df['energy'], ds.data.energy)\n",
    "        for k in df.keys():\n",
    "            if 'EventGeneratorSelectedRecoNN_I3Particle' in k:\n",
    "                ds.data[k] = df[k]\n",
    "                \n",
    "        print('Loading vertex for MC...')\n",
    "        path_sig_df = (\n",
    "            '/data/ana/PointSource/DNNCascade/analysis/' + \n",
    "            self._path_sig.format(version=self._version).replace('dnn_cascades/', '').replace('.npy', '.hdf')\n",
    "        )\n",
    "        df = pd.read_hdf(path_sig_df, key='df')\n",
    "        assert np.allclose(df['run'], ds.sig.run)\n",
    "        assert np.allclose(df['energy'], ds.sig.energy)\n",
    "        assert np.allclose(df['ow'], ds.sig.oneweight)\n",
    "        for k in df.keys():\n",
    "            if 'EventGeneratorSelectedRecoNN_I3Particle' in k:\n",
    "                ds.sig[k] = df[k]\n",
    "        \n",
    "        # angular error floor\n",
    "        print('Removing events...')\n",
    "        ds.data = ds.data._subsample(get_distance_to_hull(ds.data) <= 0.)\n",
    "        ds.sig = ds.sig._subsample(get_distance_to_hull(ds.sig) <= 0.)\n",
    "\n",
    "\n",
    "class DNNCascade_10yr_uncorrected(cy.selections.DNNCascadeDataSpecs.DNNCascade_10yr):\n",
    "    def dataset_modifications(self, ds):\n",
    "        print('Using uncorrected sigma')\n",
    "        \n",
    "        # add uncorrected sigma\n",
    "        print('Loading sigma for data...')\n",
    "        dfs = []\n",
    "        for data_path in self._path_data:\n",
    "            path_exp_df = (\n",
    "                '/data/ana/PointSource/DNNCascade/analysis/' + \n",
    "                data_path.format(version=self._version).replace('dnn_cascades/', '').replace('.npy', '.hdf')\n",
    "            )\n",
    "            dfs.append(pd.read_hdf(path_exp_df, key='df'))\n",
    "        df = pd.concat(dfs)\n",
    "        assert np.allclose(df['run'], ds.data.run)\n",
    "        assert np.allclose(df['energy'], ds.data.energy)\n",
    "        for k in df.keys():\n",
    "            if 'angErr' in k:\n",
    "                ds.data[k] = df[k]\n",
    "                \n",
    "        print('Loading sigma for MC...')\n",
    "        path_sig_df = (\n",
    "            '/data/ana/PointSource/DNNCascade/analysis/' + \n",
    "            self._path_sig.format(version=self._version).replace('dnn_cascades/', '').replace('.npy', '.hdf')\n",
    "        )\n",
    "        df = pd.read_hdf(path_sig_df, key='df')\n",
    "        assert np.allclose(df['run'], ds.sig.run)\n",
    "        assert np.allclose(df['energy'], ds.sig.energy)\n",
    "        assert np.allclose(df['ow'], ds.sig.oneweight)\n",
    "        for k in df.keys():\n",
    "            if 'angErr' in k:\n",
    "                ds.sig[k] = df[k]\n",
    "        \n",
    "        # swap sigma\n",
    "        print('Swapping sigma...')\n",
    "        ds.data['sigma'] = ds.data.angErr_uncorrected\n",
    "        ds.sig['sigma'] = ds.sig.angErr_uncorrected\n",
    "\n",
    "specs_uncorrected = [DNNCascade_10yr_uncorrected]\n",
    "specs_contained = [DNNCascade_10yr_contained]\n",
    "specs_dnn_reco = [DNNCascade_10yr_dnn_reco]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = cy.selections.Repository()\n",
    "specs = cy.selections.DNNCascadeDataSpecs.DNNC_10yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ana = cy.get_analysis(\n",
    "    repo, selection_version, specs, \n",
    "    #gammas=np.r_[0.1:6.01:0.125],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ana.anas[0]\n",
    "a.sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.bg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-shape",
   "metadata": {},
   "source": [
    "##### Load Uncorrected Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_uncorrected = cy.get_analysis(\n",
    "    cy.selections.Repository(), selection_version, specs_uncorrected, \n",
    "    #gammas=np.r_[0.1:6.01:0.125],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-montreal",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_uncorrected = ana_uncorrected.anas[0]\n",
    "a_uncorrected.sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-marketing",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_uncorrected.bg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-audit",
   "metadata": {},
   "source": [
    "##### Load DNN-reco Modifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-diagnosis",
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_dnn_reco = cy.get_analysis(\n",
    "    cy.selections.Repository(), selection_version, specs_dnn_reco, \n",
    "    #gammas=np.r_[0.1:6.01:0.125],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dnn_reco = ana_dnn_reco.anas[0]\n",
    "a_dnn_reco.sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dnn_reco.bg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-aquarium",
   "metadata": {},
   "source": [
    "##### Load Containment Modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-flight",
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_cont = cy.get_analysis(\n",
    "    cy.selections.Repository(), selection_version, specs_contained, \n",
    "    #gammas=np.r_[0.1:6.01:0.125],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-floating",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_cont = ana_cont.anas[0]\n",
    "a_cont.sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_cont.bg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-demonstration",
   "metadata": {},
   "source": [
    "## Setup Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_template = cy.selections.Repository(local_root='/data/user/ssclafani/data/analyses')\n",
    "kra_template, energy_bins = repo_template.get_template(\n",
    "          'KRA-gamma_5PeV_maps_energies', per_pixel_flux=True)\n",
    "kra_flux = cy.hyp.BinnedFlux(\n",
    "    bins_energy=energy_bins,  \n",
    "    flux=kra_template.sum(axis=0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kra_tr(ana, cpus=15, sigsub=True):\n",
    "    \n",
    "    gp_conf = {\n",
    "        'template': kra_template,\n",
    "        'bins_energy': energy_bins,\n",
    "        'randomize' : ['ra'],\n",
    "        'update_bg' : True,\n",
    "        'sigsub': sigsub,\n",
    "        cy.pdf.CustomFluxEnergyPDFRatioModel : dict(\n",
    "            hkw=dict(bins=(\n",
    "                   np.linspace(-1,1, 20), \n",
    "                   np.linspace(np.log10(500), 8.001, 20)\n",
    "                   )), \n",
    "            flux=kra_flux,\n",
    "            features=['sindec', 'log10energy'],\n",
    "            normalize_axes = ([1])), \n",
    "        'energy' : False,\n",
    "    }\n",
    "    return cy.get_trial_runner(gp_conf, ana=ana, mp_cpus=cpus)\n",
    "\n",
    "def get_kra_tr_mod(ana, cpus=15, sigsub=True):\n",
    "    \n",
    "    gp_conf = {\n",
    "        'template': kra_template,\n",
    "        'bins_energy': energy_bins,\n",
    "        #'randomize' : ['ra'],\n",
    "        'randomize' : ['ra', cy.inj.DecRandomizer],\n",
    "        'sindec_bandwidth' : np.radians(5),\n",
    "        'dec_rand_method' : 'gaussian_fixed',\n",
    "        'dec_rand_kwargs' : dict(randomization_width = np.radians(3)),\n",
    "        'dec_rand_pole_exlusion' : np.radians(8),\n",
    "        #'bg_replace': True,\n",
    "        \n",
    "        'update_bg' : True,\n",
    "        'sigsub': sigsub,\n",
    "        cy.pdf.CustomFluxEnergyPDFRatioModel : dict(\n",
    "            hkw=dict(bins=(\n",
    "                   np.linspace(-1,1, 20), \n",
    "                   np.linspace(np.log10(500), 8.001, 20)\n",
    "                   )), \n",
    "            flux=kra_flux,\n",
    "            features=['sindec', 'log10energy'],\n",
    "            normalize_axes = ([1])), \n",
    "        'energy' : False,\n",
    "    }\n",
    "    return cy.get_trial_runner(gp_conf, ana=ana, mp_cpus=cpus)\n",
    "\n",
    "def get_catalog_tr(ana, catalog, gamma, cpus, cutoff_TeV=np.inf, sigsub=True):\n",
    "    \n",
    "    catalog = catalog.lower()\n",
    "    if catalog not in ['snr', 'pwn', 'unid']:\n",
    "        raise ValueError('Catalog not understood: {}'.format(catalog))\n",
    "    \n",
    "    # get catalog and sources\n",
    "    cat = np.load('../../catalogs/{}_ESTES_12.pickle'.format(catalog),\n",
    "        allow_pickle=True)\n",
    "    src = cy.utils.Sources(dec=cat['dec_deg'], ra=cat['ra_deg'], deg=True)\n",
    "        \n",
    "    cutoff_GeV = cutoff_TeV * 1e3\n",
    "    conf = {\n",
    "        'src' : src, \n",
    "        'flux' : cy.hyp.PowerLawFlux(gamma, energy_cutoff = cutoff_GeV),\n",
    "        'update_bg': True,\n",
    "        'sigsub' :  sigsub,\n",
    "        'randomize' : ['ra', cy.inj.DecRandomizer],\n",
    "        'sindec_bandwidth' : np.radians(5),\n",
    "        'dec_rand_method' : 'gaussian_fixed',\n",
    "        'dec_rand_kwargs' : dict(randomization_width = np.radians(3)),\n",
    "        'dec_rand_pole_exlusion' : np.radians(8),\n",
    "    }\n",
    "    tr = cy.get_trial_runner(ana=ana, conf= conf, mp_cpus=cpus)\n",
    "    return tr, src\n",
    "\n",
    "def get_catalog_tr_no_sigsub(*args, **kwargs):\n",
    "    if 'sigsub' in kwargs: raise KeyError('sigsub is defined!')\n",
    "    return get_catalog_tr(*args, sigsub=False, **kwargs)\n",
    "\n",
    "def get_trial_runner(sindec, gamma, cpus, ra=0., cutoff_TeV=np.inf, sigsub=True):\n",
    "    src = cy.utils.sources(ra, np.arcsin(sindec), deg=False)\n",
    "    cutoff_GeV = cutoff_TeV * 1e3\n",
    "    conf = {\n",
    "        'src' : src, \n",
    "        'flux' : cy.hyp.PowerLawFlux(gamma, energy_cutoff = cutoff_GeV),\n",
    "        'update_bg': True,\n",
    "        'sigsub' :  sigsub,\n",
    "        'randomize' : ['ra', cy.inj.DecRandomizer],\n",
    "        'sindec_bandwidth' : np.radians(5),\n",
    "        'dec_rand_method' : 'gaussian_fixed',\n",
    "        'dec_rand_kwargs' : dict(randomization_width = np.radians(3)),\n",
    "        'dec_rand_pole_exlusion' : np.radians(8)\n",
    "    }\n",
    "    tr = cy.get_trial_runner(ana=ana, conf= conf, mp_cpus=cpus)\n",
    "    return tr, src\n",
    "\n",
    "def get_trial_runner_no_sigsub(*args, **kwargs):\n",
    "    if 'sigsub' in kwargs: raise KeyError('sigsub is defined!')\n",
    "    return get_trial_runner(*args, sigsub=False, **kwargs)\n",
    "\n",
    "def get_bias_allt(tr, ntrials=200, n_sigs=np.r_[:101:10], quiet=False):\n",
    "    trials = [\n",
    "        (None if quiet else print(f'\\r{n_sig:4d} ...', end='', flush=True))\n",
    "        or\n",
    "        tr.get_many_fits(ntrials, n_sig=n_sig, logging=False, seed=n_sig)\n",
    "        for n_sig in n_sigs]\n",
    "    if not quiet:\n",
    "        print()\n",
    "    for (n_sig, t) in zip(n_sigs, trials):\n",
    "        t['ntrue'] = np.repeat(n_sig, len(t))\n",
    "    allt = cy.utils.Arrays.concatenate(trials)\n",
    "    return allt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-merit",
   "metadata": {},
   "source": [
    "### Plotting Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cycler import cycle\n",
    "from copy import deepcopy\n",
    "\n",
    "soft_colors = cy.plotting.soft_colors\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "def get_color_cycler():\n",
    "    return cycle(colors)\n",
    "\n",
    "def plot_ns_bias(ax, tr, allt, label=''):\n",
    "\n",
    "    n_sigs = np.unique(allt.ntrue)\n",
    "    dns = np.mean(np.diff(n_sigs))\n",
    "    ns_bins = np.r_[n_sigs - 0.5*dns, n_sigs[-1] + 0.5*dns]\n",
    "    expect_kw = dict(color='C0', ls='--', lw=1, zorder=-10)\n",
    "\n",
    "    h = hl.hist((allt.ntrue, allt.ns), bins=(ns_bins, 100))\n",
    "    hl.plot1d(ax, h.contain_project(1),errorbands=True, \n",
    "              drawstyle='default', label=label)\n",
    "    lim = ns_bins[[0, -1]]\n",
    "    ax.set_xlim(ax.set_ylim(lim))\n",
    "    ax.plot(lim, lim, **expect_kw)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    ax.set_xlabel(r'$n_{inj}$')\n",
    "    ax.set_ylabel(r'$n_s$')\n",
    "    ax.grid()\n",
    "\n",
    "def plot_gamma_bias(ax, tr, allt, label=''):\n",
    "\n",
    "    n_sigs = np.unique(allt.ntrue)\n",
    "    dns = np.mean(np.diff(n_sigs))\n",
    "    ns_bins = np.r_[n_sigs - 0.5*dns, n_sigs[-1] + 0.5*dns]\n",
    "    expect_kw = dict(color='C0', ls='--', lw=1, zorder=-10)\n",
    "    expect_gamma = tr.sig_injs[0].flux[0].gamma\n",
    "\n",
    "    h = hl.hist((allt.ntrue, allt.gamma), bins=(ns_bins, 100))\n",
    "    hl.plot1d(ax, h.contain_project(1),errorbands=True, \n",
    "              drawstyle='default', label=label)\n",
    "    lim = ns_bins[[0, -1]]\n",
    "    ax.set_xlim(lim)\n",
    "    ax.set_ylim(1, 4)\n",
    "    ax.axhline(expect_gamma, **expect_kw)\n",
    "\n",
    "    ax.set_xlabel(r'$n_{inj}$')\n",
    "    ax.set_ylabel(r'$\\gamma$')\n",
    "    ax.grid()\n",
    "\n",
    "def plot_bkg_trials(\n",
    "            bg, fig=None, ax=None, \n",
    "            label='{} bg trials', \n",
    "            label_fit=r'$\\chi^2[{:.2f}\\mathrm{{dof}},\\ \\eta={:.3f}]$', \n",
    "            color=colors[0],\n",
    "            density=False,\n",
    "            bins=50,\n",
    "        ):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    \n",
    "    if density:\n",
    "        h = bg.get_hist(bins=bins).normalize()\n",
    "    else:\n",
    "        h = bg.get_hist(bins=bins)\n",
    "    if label is not None:\n",
    "        label = label.format(bg.n_total)\n",
    "    hl.plot1d(ax, h, crosses=True, color=color, label=label)\n",
    "\n",
    "    # compare with the chi2 fit:\n",
    "    x = h.centers[0]\n",
    "    norm = h.integrate().values\n",
    "    if label_fit is not None:\n",
    "        label_fit = label_fit.format(bg.ndof, bg.eta)\n",
    "    if density:\n",
    "        ax.semilogy(x, bg.pdf(x), lw=1, ls='--', label=label_fit, color=color)\n",
    "    else:\n",
    "        ax.semilogy(x, norm * bg.pdf(x), lw=1, ls='--', label=label_fit, color=color)\n",
    "\n",
    "    ax.set_xlabel(r'TS')\n",
    "    if density:\n",
    "        ax.set_ylabel(r'Density')\n",
    "    else:\n",
    "        ax.set_ylabel(r'number of trials')\n",
    "    ax.legend()\n",
    "        \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-prospect",
   "metadata": {},
   "source": [
    "## Test Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-concern",
   "metadata": {},
   "source": [
    "#### Kra-Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-unknown",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mp_cpus = 25\n",
    "\n",
    "runners_to_check = [\n",
    "    (get_kra_tr, '$\\Psi$ * $E_{kra-\\gamma}$'),\n",
    "    #(get_kra_tr_mod, '$\\Psi$ * $E_{kra-\\gamma}$ [mod]'),\n",
    "]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for ana_i, suffix in zip([ana, ana_cont, ana_dnn_reco], ['all', 'contained', 'dnn-reco']):\n",
    "    for trial_run_func, label in runners_to_check:\n",
    "        trial_runner = trial_run_func(ana=ana_i, cpus=mp_cpus)\n",
    "        allt_i = get_bias_allt(\n",
    "            trial_runner, ntrials=200, n_sigs=np.r_[:200:10])\n",
    "        plot_ns_bias(ax, trial_runner, allt_i, label=label + ' [{}]'.format(suffix))\n",
    "    \n",
    "ax.set(title=r'Kra-Gamma 5PeV Template')\n",
    "ax.legend(fontsize=8)\n",
    "fig.tight_layout()\n",
    "fig.savefig('{}/bias_kra_gamma.png'.format(plot_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-product",
   "metadata": {},
   "source": [
    "#### Test Sensitivity/Discovery Potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mp_cpus = 15\n",
    "n_trials = 100000\n",
    "seed = 592837 #592836\n",
    "tol = 0.03\n",
    "\n",
    "runners_to_check = [\n",
    "    #(get_kra_tr_mod, '$\\Psi$ * $E_{kra-\\gamma}$ [mod]'),\n",
    "    (get_kra_tr, '$\\Psi$ * $E_{kra-\\gamma}$'),\n",
    "]\n",
    "\n",
    "results = {}\n",
    "bg_trials = {}\n",
    "\n",
    "\n",
    "for ana_i, suffix in zip([ana_uncorrected, ana, ana_cont, ana_dnn_reco], ['uncorrected', 'all', 'contained', 'dnn-reco']):\n",
    "    for i, (trial_run_func, label) in enumerate(runners_to_check):\n",
    "        tr = trial_run_func(ana=ana_i, cpus=mp_cpus)\n",
    "\n",
    "        bg = cy.dists.Chi2TSD(tr.get_many_fits (\n",
    "          n_trials, n_sig=0, poisson=False, seed=seed, logging=True))\n",
    "        print ('Finished bg trials')\n",
    "\n",
    "        batch_size = 1000\n",
    "        template_sens = tr.find_n_sig(\n",
    "            bg.median(), 0.9, n_sig_step=10, seed=seed+4,\n",
    "              batch_size = batch_size, tol=tol, mp_cups=mp_cpus)\n",
    "        template_disc = tr.find_n_sig(\n",
    "            bg.isf_nsigma(5), 0.5, n_sig_step=30, seed=seed+5,\n",
    "            batch_size=batch_size, tol=tol, mp_cups=mp_cpus)\n",
    "\n",
    "\n",
    "        for t in [template_sens, template_disc]:\n",
    "            t['model_norm'] = tr.to_model_norm(t['n_sig'])\n",
    "            t['model_norm_upper'] = tr.to_model_norm(t['n_sig'] * (1+t['n_sig_error']))\n",
    "            t['model_norm_lower'] = tr.to_model_norm(t['n_sig'] * (1-t['n_sig_error']))\n",
    "\n",
    "\n",
    "        results['{}_{}_{:02d}_sens'.format('kra5PeV', suffix, i)] = template_sens\n",
    "        results['{}_{}_{:02d}_disc'.format('kra5PeV', suffix, i)] = template_disc\n",
    "        bg_trials['{}_{}_{:02d}'.format('kra5PeV', suffix, i)] = bg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-perspective",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "bins = np.linspace(0, 20, 40)\n",
    "for i, (name, bg) in enumerate(bg_trials.items()):\n",
    "    plot_bkg_trials(bg, fig=fig, ax=ax, label=name, color=colors[i], density=True, bins=bins)\n",
    "    ax.axvline(bg.isf_nsigma(3), color=colors[i], ls='--')\n",
    "    ax.axvline(bg.isf_nsigma(5), color=colors[i], ls='-.')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-reporter",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sensitivity:')\n",
    "for name, values in results.items():\n",
    "    i = int(name.split('_')[-2])\n",
    "    if 'sens' in name:\n",
    "        print('  {:3.3f} [{:3.3f}, {:3.3f}] | {} | {} events'.format(\n",
    "            values['model_norm'], \n",
    "            values['model_norm_lower'], \n",
    "            values['model_norm_upper'], \n",
    "            runners_to_check[i][1],\n",
    "            name.split('_')[1],\n",
    "        ))\n",
    "\n",
    "print('5sigma Discovery Potential:')\n",
    "for name, values in results.items():\n",
    "    i = int(name.split('_')[-2])\n",
    "    print()\n",
    "    if 'disc' in name:\n",
    "        print('  {:3.3f} [{:3.3f}, {:3.3f}] | {} | {} events'.format(\n",
    "            values['model_norm'], \n",
    "            values['model_norm_lower'], \n",
    "            values['model_norm_upper'], \n",
    "            runners_to_check[i][1],\n",
    "            name.split('_')[1],\n",
    "        ))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-norway",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-constraint",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test systematic\n",
    "raise NotImplementedError('Just an example...')\n",
    "\n",
    "# (if only one llh model)\n",
    "assert len(tr.llh_models) == 1\n",
    "\n",
    "src = cy.utils.Sources(dec=0, ra=0, deg=True)\n",
    "conf = {\n",
    "        'src' : src, \n",
    "        'flux' : cy.hyp.PowerLawFlux(2.),\n",
    "        'update_bg': True,\n",
    "        'sigsub' :  True,\n",
    "        'randomize' : ['ra', cy.inj.DecRandomizer],\n",
    "        'sindec_bandwidth' : np.radians(5),\n",
    "        'dec_rand_method' : 'gaussian_fixed',\n",
    "        'dec_rand_kwargs' : dict(randomization_width = np.radians(3)),\n",
    "        'dec_rand_pole_exlusion' : np.radians(8)\n",
    "    }\n",
    "truth, bg, sig = cy.conf.get_injs(a=a_cont, llh_model=tr.llh_models[0], llh_conf=llh_conf, conf=conf)\n",
    "\n",
    "llh_conf = dict(tr.llh_kw)\n",
    "llh_conf['src'] = src\n",
    "truth, bg, sig = cy.conf.get_injs(a=a_sys, llh_model=tr.llh_models[0], llh_conf=llh_conf, conf=conf_sys)\n",
    "tr.sig_injs = [sig]\n",
    "tr.bg_injs = [bg]\n",
    "tr.truth_injs = [truth]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2.3_py3-v4.1.0_csky",
   "language": "python",
   "name": "tensorflow2.3_py3-v4.1.0_csky"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

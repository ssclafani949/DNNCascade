{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-trading",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#PDFs in BDT and sindec?\n",
    "import os\n",
    "\n",
    "# set env flags to catch BLAS used for scipy/numpy \n",
    "# to only use 1 cpu, n_cpus will be totally controlled by csky\n",
    "if False:\n",
    "    os.environ['MKL_NUM_THREADS'] = \"1\"\n",
    "    os.environ['NUMEXPR_NUM_THREADS'] = \"1\"\n",
    "    os.environ['OMP_NUM_THREADS'] = \"1\"\n",
    "    os.environ['OPENBLAS_NUM_THREADS'] = \"1\"\n",
    "    os.environ['VECLIB_MAXIMUM_THREADS'] = \"1\"\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.facecolor'] = 'w'\n",
    "mpl.rcParams['savefig.facecolor'] = 'w'\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors, cm\n",
    "import csky as cy\n",
    "from csky import cext\n",
    "import numpy as np\n",
    "import astropy\n",
    "#from icecube import astro\n",
    "import histlite as hl\n",
    "import healpy\n",
    "import healpy as hp\n",
    "import socket\n",
    "import pickle\n",
    "import copy\n",
    "healpy.disable_warnings()\n",
    "plt.rc('figure', facecolor = 'w')\n",
    "plt.rc('figure', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-narrative",
   "metadata": {},
   "source": [
    "## Define Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_version = 'version-001-p00'\n",
    "\n",
    "host_name = socket.gethostname()\n",
    "\n",
    "if 'cobalt' in host_name:\n",
    "    print('Working on Cobalts')\n",
    "    data_prefix = '/data/user/ssclafani/data/cscd/final'\n",
    "    ana_dir = '/data/user/ssclafani/data/analyses/'\n",
    "    plot_dir = '/data/user/mhuennefeld/data/analyses/DNNCascadeCodeReview/unblinding_checks/plots/followup/template_stacking_feasibility'\n",
    "    \n",
    "else:\n",
    "    raise ValueError('Unknown host:', host_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir_path in [plot_dir]:\n",
    "    if not os.path.exists(dir_path):\n",
    "        print('Creating directory:', dir_path)\n",
    "        os.makedirs(dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-neighbor",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-hybrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = cy.selections.Repository()\n",
    "specs = cy.selections.DNNCascadeDataSpecs.DNNC_10yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ana = cy.get_analysis(\n",
    "    repo, selection_version, specs, \n",
    "    #gammas=np.r_[0.1:6.01:0.125],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ana.anas[0]\n",
    "a.sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.bg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-convention",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cycler import cycle\n",
    "from copy import deepcopy\n",
    "\n",
    "soft_colors = cy.plotting.soft_colors\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "\n",
    "def get_bias_allt(tr, ntrials=200, n_sigs=np.r_[:101:10], quiet=False):\n",
    "    trials = [\n",
    "        (None if quiet else print(f'\\r{n_sig:4d} ...', end='', flush=True))\n",
    "        or\n",
    "        tr.get_many_fits(ntrials, n_sig=n_sig, logging=False, seed=n_sig)\n",
    "        for n_sig in n_sigs]\n",
    "    if not quiet:\n",
    "        print()\n",
    "    for (n_sig, t) in zip(n_sigs, trials):\n",
    "        t['ntrue'] = np.repeat(n_sig, len(t))\n",
    "    allt = cy.utils.Arrays.concatenate(trials)\n",
    "    return allt\n",
    "\n",
    "def get_color_cycler():\n",
    "    return cycle(colors)\n",
    "\n",
    "def plot_bias(ax, x_fit, y_true, label=''):\n",
    "    \n",
    "    y_unique = np.unique(y_true)\n",
    "    dy = np.mean(np.diff(y_unique))\n",
    "    y_bins = np.r_[y_unique - 0.5*dy, y_unique[-1] + 0.5*dy]\n",
    "    expect_kw = dict(color='C0', ls='--', lw=1, zorder=-10)\n",
    "\n",
    "    h = hl.hist((y_true, x_fit), bins=(y_bins, 100))\n",
    "    hl.plot1d(ax, h.contain_project(1), errorbands=True, \n",
    "              drawstyle='default', label=label)\n",
    "    lim = y_bins[[0, -1]]\n",
    "    ax.set_xlim(ax.set_ylim(lim))\n",
    "    ax.plot(lim, lim, **expect_kw)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    ax.grid()\n",
    "    return h\n",
    "\n",
    "def plot_ns_bias(ax, tr, allt, label=''):\n",
    "\n",
    "    n_sigs = np.unique(allt.ntrue)\n",
    "    dns = np.mean(np.diff(n_sigs))\n",
    "    ns_bins = np.r_[n_sigs - 0.5*dns, n_sigs[-1] + 0.5*dns]\n",
    "    expect_kw = dict(color='C0', ls='--', lw=1, zorder=-10)\n",
    "\n",
    "    h = hl.hist((allt.ntrue, allt.ns), bins=(ns_bins, 100))\n",
    "    hl.plot1d(ax, h.contain_project(1),errorbands=True, \n",
    "              drawstyle='default', label=label)\n",
    "    lim = ns_bins[[0, -1]]\n",
    "    ax.set_xlim(ax.set_ylim(lim))\n",
    "    ax.plot(lim, lim, **expect_kw)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    ax.set_xlabel(r'$n_{inj}$')\n",
    "    ax.set_ylabel(r'$n_s$')\n",
    "    ax.grid()\n",
    "\n",
    "def plot_gamma_bias(ax, tr, allt, label=''):\n",
    "\n",
    "    n_sigs = np.unique(allt.ntrue)\n",
    "    dns = np.mean(np.diff(n_sigs))\n",
    "    ns_bins = np.r_[n_sigs - 0.5*dns, n_sigs[-1] + 0.5*dns]\n",
    "    expect_kw = dict(color='C0', ls='--', lw=1, zorder=-10)\n",
    "    expect_gamma = tr.sig_injs[0].flux[0].gamma\n",
    "\n",
    "    h = hl.hist((allt.ntrue, allt.gamma), bins=(ns_bins, 100))\n",
    "    hl.plot1d(ax, h.contain_project(1),errorbands=True, \n",
    "              drawstyle='default', label=label)\n",
    "    lim = ns_bins[[0, -1]]\n",
    "    ax.set_xlim(lim)\n",
    "    ax.set_ylim(1, 4)\n",
    "    ax.axhline(expect_gamma, **expect_kw)\n",
    "\n",
    "    ax.set_xlabel(r'$n_{inj}$')\n",
    "    ax.set_ylabel(r'$\\gamma$')\n",
    "    ax.grid()\n",
    "\n",
    "def plot_bkg_trials(\n",
    "            bg, fig=None, ax=None, \n",
    "            label='{} bg trials', \n",
    "            label_fit=r'$\\chi^2[{:.2f}\\mathrm{{dof}},\\ \\eta={:.3f}]$', \n",
    "            color=colors[0],\n",
    "            density=False,\n",
    "            bins=50,\n",
    "        ):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    \n",
    "    if density:\n",
    "        h = bg.get_hist(bins=bins).normalize()\n",
    "    else:\n",
    "        h = bg.get_hist(bins=bins)\n",
    "    if label is not None:\n",
    "        label = label.format(bg.n_total)\n",
    "    hl.plot1d(ax, h, crosses=True, color=color, label=label)\n",
    "\n",
    "    # compare with the chi2 fit:\n",
    "    if hasattr(bg, 'pdf'):\n",
    "        x = h.centers[0]\n",
    "        norm = h.integrate().values\n",
    "        if label_fit is not None:\n",
    "            label_fit = label_fit.format(bg.ndof, bg.eta)\n",
    "        if density:\n",
    "            ax.semilogy(x, bg.pdf(x), lw=1, ls='--', label=label_fit, color=color)\n",
    "        else:\n",
    "            ax.semilogy(x, norm * bg.pdf(x), lw=1, ls='--', label=label_fit, color=color)\n",
    "\n",
    "    ax.set_xlabel(r'TS')\n",
    "    if density:\n",
    "        ax.set_ylabel(r'Density')\n",
    "    else:\n",
    "        ax.set_ylabel(r'number of trials')\n",
    "    ax.legend()\n",
    "        \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-acrobat",
   "metadata": {},
   "source": [
    "## Setup Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "import config as cg\n",
    "\n",
    "cg.base_dir = '/data/user/mhuennefeld/data/analyses/unblinding_v1.0.0/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gp_tr(template_str, cutoff=np.inf, gamma=None, cpus=20):\n",
    "    cutoff_GeV = cutoff * 1e3\n",
    "    gp_conf = cg.get_gp_conf(\n",
    "        template_str=template_str, gamma=gamma, cutoff_GeV=cutoff_GeV, base_dir=cg.base_dir)\n",
    "    tr = cy.get_trial_runner(gp_conf, ana=ana, mp_cpus=cpus)\n",
    "    return tr\n",
    "\n",
    "def get_template_tr(template, gamma=2.7, cutoff_tev=np.inf, cpus=20, **kwargs):\n",
    "    cutoff_gev = cutoff_tev * 1000.\n",
    "    gp_conf = {\n",
    "        'template': template,\n",
    "        'flux': cy.hyp.PowerLawFlux(gamma, energy_cutoff=cutoff_gev),\n",
    "        'randomize': ['ra'],\n",
    "        'fitter_args': dict(gamma=gamma),\n",
    "        'sigsub': True,\n",
    "        'update_bg': True,\n",
    "        'fast_weight': False,\n",
    "        **kwargs\n",
    "    }\n",
    "    tr = cy.get_trial_runner(gp_conf, ana=ana, mp_cpus=cpus)\n",
    "    return tr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-eligibility",
   "metadata": {},
   "source": [
    "#### Get TrialRunners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dict = {\n",
    "    'fermibubbles_50TeV': get_gp_tr('fermibubbles', cutoff=50),\n",
    "    'pi0': get_gp_tr('pi0'),\n",
    "    'kra5': get_gp_tr('kra5'),\n",
    "    'kra50': get_gp_tr('kra50'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-anime",
   "metadata": {},
   "source": [
    "#### Get Results for each template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = {}\n",
    "for key in tr_dict.keys():\n",
    "    f_path = os.path.join(\n",
    "        cg.base_dir, \n",
    "        'gp/results/{}/{}_unblinded.npy'.format(key, key), \n",
    "    )\n",
    "    if os.path.exists(f_path):\n",
    "        res_dict[key] = np.load(f_path)\n",
    "    else:\n",
    "        print('File does not exist: {}'.format(f_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-basics",
   "metadata": {},
   "source": [
    "#### Print best fit fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dNdE = tr_dict['pi0'].to_dNdE(ns=res_dict['pi0'][1], E0=1e5)\n",
    "E2dNdE = tr_dict['pi0'].to_E2dNdE(ns=res_dict['pi0'][1], E0=100, unit=1e3)\n",
    "print(dNdE, E2dNdE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-seventh",
   "metadata": {},
   "source": [
    "#### Get bkg fits for each template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_file_dict = {\n",
    "    'pi0': '{}/gp/trials/{}/{}/trials.dict'.format(cg.base_dir, 'DNNC', 'pi0'),\n",
    "    'kra5': '{}/gp/trials/{}/{}/trials.dict'.format(cg.base_dir, 'DNNC', 'kra5'),\n",
    "    'kra50': '{}/gp/trials/{}/{}/trials.dict'.format(cg.base_dir, 'DNNC', 'kra50'),\n",
    "}\n",
    "n_bkg_trials = 20000\n",
    "seed = 1337\n",
    "\n",
    "bkg_dict = {}\n",
    "for key, tr in tr_dict.items():\n",
    "    if 'fermibubbles' in key: continue\n",
    "    if key in bkg_file_dict:\n",
    "        print('Loading background trials for template {}'.format(key))\n",
    "        sig = np.load(bkg_file_dict[key], allow_pickle=True)\n",
    "        bkg_dict[key] = sig['poisson']['nsig'][0.0]['ts']\n",
    "    \n",
    "    else:\n",
    "        print('Running background trials for template {}'.format(key))\n",
    "        bkg_dict[key] = tr.get_many_fits(\n",
    "            n_trials=n_bkg_trials, seed=seed, mp_cpus=20)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, values in bkg_dict.items():\n",
    "    print(k, len(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-closing",
   "metadata": {},
   "source": [
    "#### Plot ts distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-convenience",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key, bg in bkg_dict.items():\n",
    "    bg_tsd = cy.dists.TSD(bg)\n",
    "    fig, ax = plot_bkg_trials(bg_tsd)\n",
    "    ts = res_dict[key][0]\n",
    "    ns = res_dict[key][1]\n",
    "    ax.axvline(\n",
    "        ts, color='0.8', ls='--', lw=2,\n",
    "        label='TS: {:3.3f} | ns: {:3.1f}'.format(ts, ns), \n",
    "    )\n",
    "    ts_5sig = bg_tsd.isf_nsigma(5)\n",
    "    ax.axvline(\n",
    "        ts_5sig, ls='--', lw=1,\n",
    "        label='5-sigma TS: {:3.3f}'.format(ts_5sig), \n",
    "    )\n",
    "    ax.set_title('Template: {}'.format(key))\n",
    "    ax.set_yscale('log')\n",
    "    ax.legend()\n",
    "    fig.savefig('{}/ts_dist_{}.png'.format(plot_dir, key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-decline",
   "metadata": {},
   "source": [
    "#### Compute Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-smell",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val_dict = {}\n",
    "sigma_dict = {}\n",
    "max_n = 300000000\n",
    "for key, bg in bkg_dict.items():\n",
    "    print(key)\n",
    "    bg_tsd = cy.dists.TSD(bg[:max_n])\n",
    "    p_val_dict[key] = bg_tsd.sf(bg[:max_n])\n",
    "    sigma_dict[key] = bg_tsd.sf_nsigma(bg[:max_n])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-gallery",
   "metadata": {},
   "source": [
    "#### Plot Trial Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(bkg_dict['pi0'][:max_n])\n",
    "sigma_threshold = 0.5\n",
    "\n",
    "for key, tr in sigma_dict.items():\n",
    "\n",
    "    mask = np.logical_or(mask, sigma_dict[key] > sigma_threshold)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-darwin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "def plot_corr_ax(ax, key1, key2, mask=None, norm=None):\n",
    "    \n",
    "    if mask is None:\n",
    "        mask = np.ones_like(sigma_dict[key1], dtype=bool)\n",
    "        \n",
    "    ax.hist2d(\n",
    "        sigma_dict[key1][mask], sigma_dict[key2][mask],\n",
    "        bins=bins, norm=norm, cmin=1,\n",
    "    )\n",
    "    ax.plot(\n",
    "        (bins[0][0], bins[0][-1]), (bins[0][0], bins[0][-1]), \n",
    "        ls='--', color='0.7', lw=3,\n",
    "    )\n",
    "    ax.set_xlabel('$n\\cdot \\sigma$ of {}'.format(key1))\n",
    "    ax.set_ylabel('$n\\cdot \\sigma$ of {}'.format(key2))\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(9, 9))\n",
    "\n",
    "bins = (np.linspace(0, 6, 50), np.linspace(0, 6, 50))\n",
    "norm = mpl.colors.LogNorm(vmin=1, vmax=1e5)\n",
    "mask = None\n",
    "plot_corr_ax(axes[0], 'pi0', 'kra5', mask=mask, norm=norm)\n",
    "plot_corr_ax(axes[1], 'kra5', 'kra50', mask=mask, norm=norm)\n",
    "plot_corr_ax(axes[2], 'pi0', 'kra50', mask=mask, norm=norm)\n",
    "fig.tight_layout()\n",
    "fig.savefig('{}/gp_trial_correlation.png'.format(plot_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_keys = ['pi0', 'kra5', 'kra50']\n",
    "\n",
    "max_nsigma = np.max(\n",
    "    np.stack([sigma_dict[k] for k in corr_keys]),\n",
    "    axis=0,\n",
    ")\n",
    "bg_max = cy.dists.TSD(max_nsigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-swimming",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "nsigma_chosen = res_dict['pi0'][3]# 4.705\n",
    "pval_chosen = stats.norm.sf(nsigma_chosen)\n",
    "nsigma_corrected = bg_max.sf_nsigma(nsigma_chosen)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(max_nsigma, bins=np.linspace(0, 6, 200), label='Correlated bkg trials')\n",
    "ax.set_xlabel('Max n-sigma')\n",
    "ax.set_ylabel('Number of trials')\n",
    "ax.set_yscale('log')\n",
    "ax.axvline(\n",
    "    nsigma_chosen, ls='--', color='0.7', \n",
    "    label='Unblinded: {:3.3f}$\\sigma$ | Corrected: {:3.3f}$\\sigma$'.format(\n",
    "        nsigma_chosen, nsigma_corrected),\n",
    ")\n",
    "ax.legend(loc='upper right')\n",
    "fig.savefig('{}/gp_trial_correction_hist.png'.format(plot_dir))\n",
    "\n",
    "pval_corrected = bg_max.sf(nsigma_chosen)\n",
    "print('Correcting for: {}'.format(corr_keys))\n",
    "print('Pre-trial N-sigma of: {}'.format(nsigma_chosen))\n",
    "print('Pre-trial p-value of: {}'.format(pval_chosen))\n",
    "print('Post-trial correlated n-sigma: {} | factor: {}'.format(nsigma_corrected, pval_corrected/pval_chosen))\n",
    "print('Post-trial correlated p-value: {} | factor: {}'.format(pval_corrected, pval_corrected/pval_chosen))\n",
    "print('Post-trial conservative n-sigma: {} | factor: {}'.format(stats.norm.isf(pval_chosen * len(corr_keys)), len(corr_keys)))\n",
    "print('Post-trial conservative p-value: {} | factor: {}'.format(pval_chosen * len(corr_keys), pval_chosen * len(corr_keys)/pval_chosen))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsigma_chosen = res_dict['pi0'][3]# 4.705\n",
    "pval_chosen = stats.norm.sf(nsigma_chosen)\n",
    "pval_conservative = pval_chosen * 3\n",
    "nsigma_conservative = stats.norm.isf(pval_conservative)\n",
    "\n",
    "print('Pre-trial N-sigma of: {}'.format(nsigma_chosen))\n",
    "print('Post-trial conservative: {} | factor: {}'.format(nsigma_conservative, pval_conservative/pval_chosen))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-indicator",
   "metadata": {},
   "source": [
    "## Load and Plot Skymaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-morocco",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_results = np.load(\n",
    "    os.path.join(\n",
    "        cg.base_dir, 'skyscan/results/unblinded_skyscan.npy'),\n",
    "    allow_pickle=True,\n",
    ")[()]\n",
    "ss_trial = ss_results['ss_trial']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-induction",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['mlog10p', 'ts', 'ns', 'gamma']\n",
    "for loc in ['south', 'north']:\n",
    "    print('Hottest spot in {}:'.format(loc))\n",
    "    for i, name in enumerate(names):\n",
    "        print('  {}: {}'.format(name, ss_trial[i,ss_results['ipix_max_{}'.format(loc)]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-vegetation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.nasa.gov/mission_pages/GLAST/news/gammaray_best.html\n",
    "# https://www.nasa.gov/images/content/317870main_Fermi_3_month_labeled_new.jpg\n",
    "fermi_sources = {\n",
    "    # ra, dec\n",
    "    'NGC 1275': (049.9506656698585, +41.5116983765094),\n",
    "    '3C 454.3': (343.49061658, +16.14821142),\n",
    "    '47 Tuc': (006.022329, -72.081444),\n",
    "    '0FGL J1813.5-1248': (273.349033, -12.766842),\n",
    "    '0FGL J0614.3-3330': (093.5431162, -33.4983656),\n",
    "    'PKS 0727-115': (112.57963530917, -11.68683347528),\n",
    "    'Vela': (128.5000, -45.8333),\n",
    "    'Geminga': (098.475638, +17.770253),\n",
    "    'Crab': (083.63308, +22.01450),\n",
    "    'LSI +61 303': (040.1319341179735, +61.2293308716971),\n",
    "    'PSR J1836+5925': (279.056921, +59.424936),\n",
    "    'PKS 1502+106': (226.10408242258, +10.49422183753),\n",
    "    #'Cygnus X-3': (308.10742, +40.95775), # not one of the top Fermi sources\n",
    "}\n",
    "\n",
    "cat_dict = {}\n",
    "for cat_str in ['pwn', 'snr', 'unid']:\n",
    "    catalog_file = os.path.join(\n",
    "        cg.catalog_dir, '{}_ESTES_12.pickle'.format(cat_str))\n",
    "    cat_dict[cat_str] = np.load(catalog_file, allow_pickle=True)\n",
    "\n",
    "src_list_file = os.path.join(cg.catalog_dir, 'Source_List_DNNC.pickle')\n",
    "sourcelist = np.load(src_list_file, allow_pickle=True)\n",
    "sourcelist['ra_deg'] = sourcelist['RA']\n",
    "sourcelist['dec_deg'] = sourcelist['DEC']\n",
    "cat_dict['Source List'] = sourcelist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-deposit",
   "metadata": {},
   "source": [
    "#### Plot template contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-cable",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContourSkymap:\n",
    "    def __init__(self, skymap, nside=None):\n",
    "        \n",
    "        # upscale skymap\n",
    "        if nside is not None:\n",
    "            skymap = hp.ud_grade(skymap, nside_out=nside)\n",
    "        else:\n",
    "            nside = hp.get_nside(skymap)\n",
    "        \n",
    "        # normalize such that sum of pixel values equals one\n",
    "        self.prob_values = skymap / np.sum(skymap)\n",
    "        self.neg_llh_values = -np.log10(self.prob_values)\n",
    "        self.nside = hp.get_nside(self.prob_values)\n",
    "        self.npix = hp.nside2npix(self.nside)\n",
    "        \n",
    "        self.theta, self.phi = self.get_healpix_grid()\n",
    "        \n",
    "        # sort healpix points according to neg llh\n",
    "        sorted_indices = np.argsort(self.neg_llh_values)\n",
    "        self.theta_s = self.theta[sorted_indices]\n",
    "        self.phi_s = self.phi[sorted_indices]\n",
    "        self.neg_llh_values_s = self.neg_llh_values[sorted_indices]\n",
    "        self.prob_values_s = self.prob_values[sorted_indices]\n",
    "    \n",
    "        self.cdf_values_s = np.cumsum(self.prob_values_s)\n",
    "    \n",
    "    def get_healpix_grid(self):\n",
    "        npix = hp.nside2npix(self.nside)\n",
    "        theta, phi = hp.pix2ang(self.nside, np.r_[:npix])\n",
    "        return theta, phi\n",
    "    \n",
    "    def quantile_to_pdf_value(self, quantile):\n",
    "        \"\"\"Get pixel probability value\n",
    "        \"\"\"\n",
    "        assert quantile >= 0., quantile\n",
    "        assert quantile <= 1., quantile\n",
    "\n",
    "        index = np.searchsorted(self.cdf_values_s, quantile)\n",
    "        return self.prob_values_s[index]\n",
    "    \n",
    "    def _get_level_indices(self, level=0.5, delta=0.01):\n",
    "        \"\"\"Get indices of healpix map, which belong to the specified\n",
    "        contour as defined by: level +- delta.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : float, optional\n",
    "            The contour level. Example: a level of 0.7 means that 70% of events\n",
    "            are within this contour.\n",
    "        delta : float, optional\n",
    "            The contour is provided by selecting directions from the sampled\n",
    "            ones which have cdf values within [level - delta, level + delta].\n",
    "            The smaller delta, the more accurate the contour will be. However,\n",
    "            the number of available sample points for the contour will also\n",
    "            decrease.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int, int\n",
    "            The starting and stopping index for a slice of sampled events\n",
    "            that lie within the contour [level - delta, level + delta].\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            If number of resulting samples is too low.\n",
    "        \"\"\"\n",
    "        assert level >= 0., level\n",
    "        assert level <= 1., level\n",
    "\n",
    "        index_min = np.searchsorted(self.cdf_values_s, level - delta)\n",
    "        index_max = min(self.npix,\n",
    "                        np.searchsorted(self.cdf_values_s, level + delta))\n",
    "\n",
    "        if index_max - index_min <= 10:\n",
    "            raise ValueError('Number of samples is too low!')\n",
    "\n",
    "        return index_min, index_max\n",
    "    \n",
    "    def contour(self, level=0.5, delta=0.01):\n",
    "        \"\"\"Get zenith/azimuth paris of points that lie with the specified\n",
    "        contour [level - delta, level + delta].\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : float, optional\n",
    "            The contour level. Example: a level of 0.7 means that 70% of events\n",
    "            are within this contour.\n",
    "        delta : float, optional\n",
    "            The contour is provided by selecting directions from the sampled\n",
    "            ones which have cdf values within [level - delta, level + delta].\n",
    "            The smaller delta, the more accurate the contour will be. However,\n",
    "            the number of available sample points for the contour will also\n",
    "            decrease.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array, np.array\n",
    "            The theta/phi pairs that lie within the contour\n",
    "            [level - delta, level + delta].\n",
    "        \"\"\"\n",
    "        index_min, index_max = self._get_level_indices(level, delta)\n",
    "        return (self.theta_s[index_min:index_max],\n",
    "                self.phi_s[index_min:index_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_smeared_template(key_or_tr, smearing=5):\n",
    "    if isinstance(key_or_tr, str):\n",
    "        tr = tr_dict[key_or_tr]\n",
    "    else:\n",
    "        tr = key_or_tr\n",
    "    space_pdf = tr.llh_models[0].pdf_ratio_model.models[0]\n",
    "    sigma_idx = np.searchsorted(np.rad2deg(space_pdf.sigmas), smearing)\n",
    "    template_smeared = space_pdf.pdf_space_sig[sigma_idx]\n",
    "    return np.array(template_smeared)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-commercial",
   "metadata": {},
   "source": [
    "#### Skymap Plotting Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "sys.path.insert(0, '../unblinding')\n",
    "import contour_compute\n",
    "\n",
    "\n",
    "class SkymapPlotter:\n",
    "    \n",
    "    def __init__(self, fermi_sources=fermi_sources, cat_dict=cat_dict, ss_results=ss_results, **kwargs):\n",
    "        self.cat_dict = cat_dict\n",
    "        self.fermi_sources = fermi_sources\n",
    "        self.ss_results = ss_results\n",
    "        self.coord = None\n",
    "        \n",
    "        self.fig, self.ax, self.sp, self.cb, self.pc = self.plot_skymap(**kwargs)\n",
    "    \n",
    "    def add_skymap_layer(self, m, ax=None, input_coord='C', **kw):\n",
    "        \n",
    "        if input_coord == 'C' and self.sp.coord == 'G':\n",
    "            m = SkymapPlotter.equatorial_to_galactic(m)\n",
    "                \n",
    "        if ax is None:\n",
    "            ax = self.ax\n",
    "        lat, lon, Z = self.sp.map_to_latlonz(m)\n",
    "        pc = ax.pcolormesh(lon, lat, Z, **kw)\n",
    "        return lat, lon, Z, pc\n",
    "        \n",
    "    @staticmethod\n",
    "    def plot_skymap(\n",
    "                skymap, fig=None, ax=None, outfile=None, figsize=(9, 6),\n",
    "                vmin=None, vmax=None, label=None, norm=None,\n",
    "                cmap=cy.plotting.skymap_cmap,\n",
    "                input_coord='C',\n",
    "                n_cb_ticks=4,\n",
    "                gp_kw=dict(color='.3', alpha=0.5), gp_lw=1.,\n",
    "                plot_gp=True, annotate=True,\n",
    "                **kwargs\n",
    "            ):\n",
    "        \"\"\"Plot a skymap\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        skymap : array_like\n",
    "            The skymap to plot.\n",
    "        outfile : str, optional\n",
    "            The output file path to which to plot if provided.\n",
    "        vmin : float, optional\n",
    "            The minimum value for the colorbar.\n",
    "        vmax : float, optional\n",
    "            The maximum value for the colorbar.\n",
    "        figsize : tuple, optional\n",
    "            The figure size to use.\n",
    "        label : str, optional\n",
    "            The label for the colorbar.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        fig, ax\n",
    "            The matplotlib figure and axis.\n",
    "        \"\"\"\n",
    "        if fig is None:\n",
    "            fig, ax = plt.subplots(\n",
    "                subplot_kw=dict(projection='aitoff'), figsize=figsize)\n",
    "\n",
    "        if 'coord' in kwargs and kwargs['coord'] == 'G':\n",
    "            nohr = True\n",
    "            if input_coord == 'C':\n",
    "                skymap = SkymapPlotter.equatorial_to_galactic(skymap)\n",
    "        else:\n",
    "            nohr = False\n",
    "\n",
    "        sp = cy.plotting.SkyPlotter(\n",
    "            pc_kw=dict(cmap=cmap, vmin=vmin, vmax=vmax, norm=norm), \n",
    "            **kwargs\n",
    "        )\n",
    "        pc, cb = sp.plot_map(ax, skymap, n_ticks=n_cb_ticks, nohr=nohr)\n",
    "    \n",
    "        SkymapPlotter.annotate_skymap(\n",
    "            ax=ax, sp=sp, annotate=annotate, plot_gp=plot_gp, gp_kw=gp_kw, gp_lw=gp_lw,\n",
    "        )\n",
    "        if False:\n",
    "            if sp.coord == 'G' and annotate:\n",
    "                kw = dict(xycoords='axes fraction', textcoords='offset pixels', verticalalignment='center')\n",
    "                ax.annotate(r'l = -180째', xy=(1, .5), xytext=(10, 0), horizontalalignment='left', **kw)\n",
    "                ax.annotate(r'l = 180째', xy=(0, .5), xytext=(-10, 0), horizontalalignment='right', **kw)\n",
    "\n",
    "            if sp.coord != 'G' and plot_gp:\n",
    "                sp.plot_gp(ax, lw=gp_lw, **gp_kw)\n",
    "                sp.plot_gc(ax, **gp_kw)\n",
    "            kw = dict(color='.5', alpha=.5)\n",
    "            ax.grid(**kw)\n",
    "        cb.set_label(label)\n",
    "        fig.tight_layout()\n",
    "        if outfile is not None:\n",
    "            fig.savefig(outfile)\n",
    "\n",
    "        return fig, ax, sp, cb, pc\n",
    "    \n",
    "    @staticmethod\n",
    "    def annotate_skymap(ax, sp, annotate=True, plot_gp=True, gp_kw=dict(color='.3', alpha=0.5), gp_lw=1.):\n",
    "        if sp.coord == 'G' and annotate:\n",
    "            kw = dict(xycoords='axes fraction', textcoords='offset pixels', verticalalignment='center')\n",
    "            ax.annotate(r'l = -180째', xy=(1, .5), xytext=(10, 0), horizontalalignment='left', **kw)\n",
    "            ax.annotate(r'l = 180째', xy=(0, .5), xytext=(-10, 0), horizontalalignment='right', **kw)\n",
    "        \n",
    "        if sp.coord != 'G' and plot_gp:\n",
    "            sp.plot_gp(ax, lw=gp_lw, **gp_kw)\n",
    "            sp.plot_gc(ax, **gp_kw)\n",
    "        kw = dict(color='.5', alpha=.5)\n",
    "        ax.grid(**kw)\n",
    "    \n",
    "    @staticmethod\n",
    "    def equatorial_to_galactic(m, rot=180):\n",
    "        r = hp.Rotator(rot=rot, coord='CG')\n",
    "        return r.rotate_map_pixel(m)\n",
    "\n",
    "    @staticmethod\n",
    "    def equatorial_to_galactic_coords(theta, phi, rot=180):\n",
    "        r = hp.Rotator(rot=rot, coord='CG')\n",
    "        return r(theta, phi)\n",
    "    \n",
    "    @staticmethod\n",
    "    def galactic_to_equatorial(m, rot=180):\n",
    "        r = hp.Rotator(rot=rot, coord='CG', inv=True)\n",
    "        return r.rotate_map_pixel(m)\n",
    "\n",
    "    @staticmethod\n",
    "    def galactic_to_equatorial_coords(theta, phi, rot=180):\n",
    "        r = hp.Rotator(rot=rot, coord='CG', inv=True)\n",
    "        return r(theta, phi)\n",
    "    \n",
    "    def convert_theta_phi_to_mpl_coords(self, theta, phi, convert=True):\n",
    "        if self.sp.coord == 'G' and convert:\n",
    "            theta, phi = self.equatorial_to_galactic_coords(theta, phi)\n",
    "        x, y = self.sp.thetaphi_to_mpl(theta, phi)\n",
    "        return x, y\n",
    "        \n",
    "    def convert_ra_dec_to_mpl_coords(self, ra, dec):\n",
    "        theta = np.pi/2. - dec\n",
    "        phi = ra\n",
    "        return self.convert_theta_phi_to_mpl_coords(theta=theta, phi=phi)\n",
    "\n",
    "    def draw_equator(self, ax=None, color='0.6', s=1, **kwargs):\n",
    "        if ax is None:\n",
    "            ax = self.ax\n",
    "        phi = np.linspace(0., 2*np.pi, 10000)\n",
    "        dec = np.zeros_like(phi)\n",
    "        x, y = self.convert_ra_dec_to_mpl_coords(ra=phi, dec=dec)\n",
    "        return ax.scatter(x, y, marker='.', color=color, s=s)\n",
    "\n",
    "    def plot_catalog(self, ax=None, sp=None, marker='x', color='red', keys=None, labels=None, cat_dict=None, **kwargs):\n",
    "        \n",
    "        if ax is None:\n",
    "            ax = self.ax\n",
    "        if sp is None:\n",
    "            sp = self.sp\n",
    "        \n",
    "        if cat_dict is None:\n",
    "            cat_dict = self.cat_dict\n",
    "            \n",
    "        if keys is None:\n",
    "            keys = list(cat_dict.keys())\n",
    "        if labels is None:\n",
    "            labels = keys\n",
    "            \n",
    "        for cat_str, label in zip(keys, labels):\n",
    "            cat = cat_dict[cat_str]\n",
    "            x, y = self.convert_ra_dec_to_mpl_coords(\n",
    "                ra=np.deg2rad(cat.ra_deg), dec=np.deg2rad(cat.dec_deg))\n",
    "            ax.scatter(x, y, marker=marker, color=color, label=label, **kwargs)\n",
    "    \n",
    "    def plot_hotspots(self, ax=None, sp=None, marker='x', color='0.8', **kwargs):\n",
    "        if ax is None:\n",
    "            ax = self.ax\n",
    "        if sp is None:\n",
    "            sp = self.sp\n",
    "            \n",
    "        # plot hottest spots\n",
    "        for res_str in ['ipix_max_north', 'ipix_max_south']:\n",
    "            theta, phi = hp.pix2ang(128, self.ss_results[res_str])\n",
    "            x, y = self.convert_theta_phi_to_mpl_coords(theta=theta, phi=phi)\n",
    "            ax.scatter(x, y, marker=marker, color=color, **kwargs)\n",
    "    \n",
    "    def plot_fermi_sources(self, ax=None, sp=None, marker='+', color='1.0'):\n",
    "        \n",
    "        if ax is None:\n",
    "            ax = self.ax\n",
    "        if sp is None:\n",
    "            sp = self.sp\n",
    "            \n",
    "        for key, (ra_deg, dec_deg) in self.fermi_sources.items():\n",
    "            x, y = self.convert_ra_dec_to_mpl_coords(\n",
    "                ra=np.deg2rad(ra_deg), dec=np.deg2rad(dec_deg))\n",
    "            ax.scatter(x, y, marker=marker, color=color)\n",
    "    \n",
    "    def get_contour(self, skymap, quantiles=[0.5], geodesic='planar'):\n",
    "        \"\"\"Get contours\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        contours_by_level : list(list(list(point)))\n",
    "            The contours for each level\n",
    "            Outermost list indexes by level\n",
    "            Second list indexes by contours at a particular level\n",
    "            Third list indexes by points in each contour\n",
    "            Points are of the same form as sample_points\n",
    "        \"\"\"\n",
    "        nside = hp.get_nside(skymap)\n",
    "        theta, phi = hp.pix2ang(nside=nside, ipix=np.arange(hp.nside2npix(nside)))\n",
    "        \n",
    "        if self.sp.coord == 'G':\n",
    "            skymap = SkymapPlotter.equatorial_to_galactic(skymap)\n",
    "        \n",
    "        # compute PDF levels for provided quantiles \n",
    "        contour_map = ContourSkymap(skymap=skymap)\n",
    "\n",
    "        levels = []\n",
    "        for quantile in quantiles:\n",
    "            levels.append(contour_map.quantile_to_pdf_value(quantile))\n",
    "        \n",
    "        # compute sample points in which to compute the contours\n",
    "        if geodesic == 'spherical':\n",
    "            sample_points = np.stack((theta, phi), axis=1)\n",
    "        elif geodesic == 'planar':\n",
    "            x, y = self.convert_theta_phi_to_mpl_coords(theta=theta, phi=phi, convert=False)\n",
    "            sample_points = np.stack((x, y), axis=1)\n",
    "        else:\n",
    "            raise ValueError('Unknown geodesic: {}'.format(geodesic))\n",
    "\n",
    "        contours = contour_compute.compute_contours(\n",
    "            sample_points=sample_points, samples=contour_map.prob_values, levels=levels, geodesic=geodesic)\n",
    "        return contours\n",
    "\n",
    "    \n",
    "    def plot_template_contour(\n",
    "                self, template_str, smearing_deg=5., quantiles=[0.5], ls=['-'], color=[None], geodesic='planar',\n",
    "        ):\n",
    "        assert len(quantiles) == len(ls)\n",
    "        assert len(quantiles) == len(color)\n",
    "        \n",
    "        template = get_smeared_template(template_str, smearing=smearing_deg)\n",
    "        contours = self.get_contour(skymap=template, quantiles=quantiles, geodesic=geodesic)\n",
    "        for ls_i, color_i, contour in zip(ls, color, contours):\n",
    "            for contour_i in contour:\n",
    "                if geodesic == 'spherical':\n",
    "                    x, y = self.convert_theta_phi_to_mpl_coords(theta=contour_i[:, 0], phi=contour_i[:, 1], convert=False)\n",
    "                elif geodesic == 'planar':\n",
    "                    x, y = contour_i[:, 0], contour_i[:, 1]\n",
    "                else:\n",
    "                    raise ValueError('Unknown geodesic: {}'.format(geodesic))\n",
    "                if len(x) > 2:\n",
    "                    self.ax.plot(x, y, ls=ls_i, color=color_i)\n",
    "        return contours\n",
    "    \n",
    "    def plot_template_contour_points(\n",
    "                self, template_str, level, \n",
    "                smearing_deg=5, color='0.2', delta=0.01, \n",
    "                marker='.', s=1,\n",
    "                ax=None, sp=None,\n",
    "            ):\n",
    "        contour_map = ContourSkymap(get_smeared_template(template_str, smearing=smearing_deg))\n",
    "        theta, phi = contour_map.contour(level=level, delta=delta)\n",
    "        x, y = self.convert_theta_phi_to_mpl_coords(theta=theta, phi=phi)\n",
    "        self.ax.scatter(x, y, marker=marker, s=s, color=color)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-digit",
   "metadata": {},
   "source": [
    "## Test Template Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_pi0_raw_ = cg.template_repo.get_template('Fermi-LAT_pi0_map')\n",
    "template_kra5_raw_, energy_bins = cg.template_repo.get_template(\n",
    "    'KRA-gamma_5PeV_maps_energies', per_pixel_flux=True)\n",
    "template_kra5_raw = np.sum(template_kra5_raw_, axis=1)\n",
    "\n",
    "# normalize\n",
    "pix_area = hp.nside2pixarea(hp.get_nside(template_pi0_raw_))\n",
    "template_pi0_raw = template_pi0_raw_ / np.sum(template_pi0_raw_) / pix_area\n",
    "template_kra5_raw = template_kra5_raw_ / np.sum(template_kra5_raw_) / pix_area\n",
    "\n",
    "# create a different, rotated PDF \n",
    "template_pi0_raw_rotated_ = SkymapPlotter.equatorial_to_galactic(template_pi0_raw_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-planning",
   "metadata": {},
   "source": [
    "##### Create trial runners with same flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_pi0 = get_template_tr(template=template_pi0_raw_)\n",
    "tr_pi0_rotated = get_template_tr(template=template_pi0_raw_rotated_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.allclose(tr_pi0.llh_models[0].pdf_ratio_model.models[0].template, template_pi0_raw_))\n",
    "print(np.allclose(tr_pi0_rotated.llh_models[0].pdf_ratio_model.models[0].template, template_pi0_raw_rotated_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = 0.5\n",
    "\n",
    "template_pi0_tr = tr_pi0.llh_models[0].pdf_ratio_model.models[0].template\n",
    "template_pi0_rotated_tr = tr_pi0_rotated.llh_models[0].pdf_ratio_model.models[0].template\n",
    "\n",
    "# combine before acceptance and smearing\n",
    "template_combined_raw = w1 * template_pi0_tr + (1 - w1) * template_pi0_rotated_tr\n",
    "tr_combined = get_template_tr(template=template_combined_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "smearing_deg = 7\n",
    "template_pi0 = get_smeared_template(tr_pi0, smearing=smearing_deg)\n",
    "template_pi0_rotated = get_smeared_template(tr_pi0_rotated, smearing=smearing_deg)\n",
    "\n",
    "template_combined_post1 = w1 * template_pi0 + (1 - w1) * template_pi0_rotated\n",
    "template_combined = get_smeared_template(tr_combined, smearing=smearing_deg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "skymap_plotter = SkymapPlotter(\n",
    "    skymap=template_pi0, cmap='viridis', \n",
    ")\n",
    "skymap_plotter.ax.set_title('Map 1')\n",
    "skymap_plotter.fig.savefig('{}/template_stacking_map1.png'.format(plot_dir))\n",
    "\n",
    "skymap_plotter = SkymapPlotter(\n",
    "    skymap=template_pi0_rotated, cmap='viridis', \n",
    ")\n",
    "skymap_plotter.ax.set_title('Map 2')\n",
    "skymap_plotter.fig.savefig('{}/template_stacking_map2.png'.format(plot_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-concentrate",
   "metadata": {},
   "outputs": [],
   "source": [
    "skymap_plotter = SkymapPlotter(\n",
    "    skymap=template_combined_post1, cmap='viridis', \n",
    ")\n",
    "skymap_plotter.ax.set_title('Combination after AC')\n",
    "skymap_plotter.fig.savefig('{}/combination_after_accceptance.png'.format(plot_dir))\n",
    "\n",
    "skymap_plotter = SkymapPlotter(\n",
    "    skymap=template_combined, cmap='viridis', \n",
    ")\n",
    "skymap_plotter.ax.set_title('Combination before AC')\n",
    "skymap_plotter.fig.savefig('{}/combination_before_accceptance.png'.format(plot_dir))\n",
    "\n",
    "skymap_plotter = SkymapPlotter(\n",
    "    skymap=np.log10(template_combined/template_combined_post1), cmap='viridis', \n",
    ")\n",
    "skymap_plotter.ax.set_title('Acceptance Comparison Ratio')\n",
    "skymap_plotter.fig.savefig('{}/acceptance_order.png'.format(plot_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-seminar",
   "metadata": {},
   "source": [
    "## Check effect of smearing before/after combination\n",
    "\n",
    "As demonstrated below, smearing can be applied before or after building the mixture model. This is essentially the same appart from numerical differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = np.deg2rad(20)\n",
    "t1 = get_smeared_template('pi0', smearing=0)\n",
    "t2 = get_smeared_template('kra5', smearing=0)\n",
    "\n",
    "t1_s = hp.smoothing(t1, sigma=sigma)\n",
    "t2_s = hp.smoothing(t2, sigma=sigma)\n",
    "\n",
    "t_combined_s_pre = t1_s * w1 + (1. - w1) *t2_s\n",
    "t_combined_s_post = hp.smoothing(t1 * w1 + (1. - w1) *t2, sigma=sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "skymap_plotter = SkymapPlotter(\n",
    "    skymap=t_combined_s_pre, cmap='viridis', \n",
    ")\n",
    "skymap_plotter = SkymapPlotter(\n",
    "    skymap=t_combined_s_post, cmap='viridis', \n",
    ")\n",
    "skymap_plotter = SkymapPlotter(\n",
    "    skymap=np.log10(t_combined_s_pre/t_combined_s_post), cmap='viridis', \n",
    ")\n",
    "skymap_plotter.ax.set_title('Smearing Comparison')\n",
    "skymap_plotter.fig.savefig('{}/smearing_order.png'.format(plot_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-elephant",
   "metadata": {},
   "source": [
    "## Test StackedTemplatePDFRatioModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-husband",
   "metadata": {},
   "source": [
    "#### Define test injection template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-bubble",
   "metadata": {},
   "outputs": [],
   "source": [
    "def catalog_as_template(catalog, cat_dict=cat_dict, nside=64):\n",
    "    template = np.zeros(hp.nside2npix(nside))\n",
    "    pix_area = hp.nside2pixarea(nside)\n",
    "    \n",
    "    # set pixels corresponding to source locations to 1\n",
    "    for ra_deg, dec_deg in zip(cat_dict[catalog].ra_deg, cat_dict[catalog].dec_deg):\n",
    "\n",
    "        # transform to other coordinates and set to 1\n",
    "        theta = np.pi/2. - np.deg2rad(dec_deg)\n",
    "        phi = np.deg2rad(ra_deg)\n",
    "        \n",
    "        ipix = hp.ang2pix(nside=nside, theta=theta, phi=phi)\n",
    "        template[ipix] = 1\n",
    "        \n",
    "    # normalize\n",
    "    template = template / np.sum(template) / pix_area\n",
    "    return template\n",
    "\n",
    "def get_template_component(component, sigma=None):\n",
    "    \n",
    "    if component == 'pi0':\n",
    "        template = cg.template_repo.get_template('Fermi-LAT_pi0_map')\n",
    "    \n",
    "    elif component in ['snr', 'pwn', 'unid']:\n",
    "        template = catalog_as_template(component)\n",
    "    \n",
    "    elif component == 'random':\n",
    "        template_pi0_raw_ = cg.template_repo.get_template('Fermi-LAT_pi0_map')\n",
    "        \n",
    "        def equatorial_to_galactic(m, rot=180):\n",
    "            r = hp.Rotator(rot=rot, coord='CG')\n",
    "            return r.rotate_map_pixel(m)\n",
    "        \n",
    "        template = equatorial_to_galactic(template_pi0_raw_)\n",
    "    else:\n",
    "        raise ValueError()\n",
    "    \n",
    "    # smear template \n",
    "    if sigma is not None:\n",
    "        template = hp.smoothing(template, sigma=sigma)\n",
    "        \n",
    "    # normalize template\n",
    "    pix_area = hp.nside2pixarea(hp.get_nside(template))\n",
    "    template = template / np.sum(template) / pix_area\n",
    "    \n",
    "    return template\n",
    "\n",
    "def get_test_injection_template(w, sigma=None):\n",
    "    template1 = get_template_component('unid', sigma=sigma)\n",
    "    template2 = get_template_component('snr', sigma=sigma)\n",
    "    return template1 * w + (1. - w) * template2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = np.deg2rad(3)\n",
    "inj_weight = 0.8\n",
    "\n",
    "templates = [get_template_component(c, sigma=sigma) for c in ['snr', 'unid']]\n",
    "injection_template = get_test_injection_template(inj_weight, sigma=sigma)\n",
    "\n",
    "skymap_plotter = SkymapPlotter(\n",
    "    skymap=injection_template, cmap='viridis', \n",
    ")\n",
    "\n",
    "skymap_plotter.ax.set_title('Injected | w = {:3.2f}'.format(inj_weight))\n",
    "skymap_plotter.fig.savefig('{}/injected_template.png'.format(plot_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-carnival",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, template_i in enumerate(templates):\n",
    "    skymap_plotter = SkymapPlotter(\n",
    "        skymap=template_i, cmap='viridis', \n",
    "    )\n",
    "\n",
    "    skymap_plotter.ax.set_title('Component {}'.format(i))\n",
    "    skymap_plotter.fig.savefig('{}/component_{:03d}.png'.format(plot_dir, i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-feeling",
   "metadata": {},
   "source": [
    "#### Define trial runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_stacked_template_tr(templates, injection_template, gamma=2.7, cutoff_tev=np.inf, cpus=20, **kwargs):\n",
    "    \n",
    "    cutoff_gev = cutoff_tev * 1000.\n",
    "    flux = cy.hyp.PowerLawFlux(gamma, energy_cutoff=cutoff_gev)\n",
    "    \n",
    "    # create list of template model kwargs\n",
    "    template_kwarg_list = []\n",
    "    for template in templates:\n",
    "        template_kwarg_list.append({\n",
    "            'template': template,\n",
    "            'flux': flux,\n",
    "        })\n",
    "    \n",
    "    injection_template_kwargs = {\n",
    "        'template': injection_template,\n",
    "        'flux': flux,\n",
    "        'sigmas': [0],\n",
    "    }\n",
    "    \n",
    "    gp_conf = {\n",
    "        'template_kwarg_list': template_kwarg_list,\n",
    "        'flux': flux,\n",
    "        'randomize': ['ra'],\n",
    "        'fitter_args': dict(gamma=gamma),\n",
    "        'sigsub': True,\n",
    "        'update_bg': True,\n",
    "        'fast_weight': False,\n",
    "        'injection_template_kwargs': injection_template_kwargs,\n",
    "        **kwargs\n",
    "    }\n",
    "    tr = cy.get_trial_runner(gp_conf, ana=ana, mp_cpus=cpus)\n",
    "    return tr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-occasions",
   "metadata": {},
   "source": [
    "#### Get Trial Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-expression",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_stacked = get_stacked_template_tr(\n",
    "    templates=templates, injection_template=injection_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-projector",
   "metadata": {},
   "source": [
    "#### Test one fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-passport",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_func(**params):\n",
    "    n_models = 2\n",
    "    weights = np.empty(n_models)\n",
    "    for i in range(n_models):\n",
    "        weights[i] = params['weight_{:04d}'.format(i)]\n",
    "\n",
    "    exp_weights = np.exp(weights)\n",
    "    weight_norm = np.sum(exp_weights)\n",
    "    print('weight_norm', weight_norm)\n",
    "    return (weight_norm - 1)**2\n",
    "\n",
    "#prior_func(**fit[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = tr_stacked.get_one_trial(n_sig=1000, seed=None)\n",
    "fit = tr_stacked.get_one_fit_from_trial(trial, flat=False, )\n",
    "#fit = tr_stacked.get_one_fit_from_trial(trial, flat=False, weight_0000=0.01, weight_0001=0.5)\n",
    "fit\n",
    "\n",
    "weights = cy.pdf.StackedTemplateSpacePDFRatioModel.compute_weights(2, **fit[1])\n",
    "#weights = np.array([fit[1]['weight_0000'], fit[1]['weight_0001']])\n",
    "#exp_weights = np.exp(weights)\n",
    "#weights = exp_weights / np.sum(exp_weights)\n",
    "#weights /= np.sum(weights)\n",
    "weights, fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-translation",
   "metadata": {},
   "source": [
    "## Test bias in fitted weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-chemical",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "n_trials = 100\n",
    "n_weights = 10\n",
    "n_sigs = np.linspace(0, 300, 7)\n",
    "seed = 1337\n",
    "n_cpus = 20\n",
    "inj_weights = np.linspace(0, 1, n_weights)\n",
    "\n",
    "results = np.zeros((n_weights, len(n_sigs), n_trials))\n",
    "\n",
    "for i, inj_weight_i in tqdm(enumerate(inj_weights), total=n_weights):\n",
    "    \n",
    "    # get injection weight\n",
    "    injection_template_i = get_test_injection_template(w=inj_weight_i, sigma=sigma)\n",
    "    \n",
    "    # get injection trial runner\n",
    "    tr_inj = get_stacked_template_tr(\n",
    "        templates=templates, injection_template=injection_template_i, sigmas=[0])\n",
    "    \n",
    "    # get trials\n",
    "    print('Running pool with {} cpus'.format(n_cpus))\n",
    "    for j, n_sig in enumerate(n_sigs):\n",
    "        def compute_trial(j):\n",
    "            inj_trial = tr_inj.get_one_trial(n_sig=n_sig, seed=seed + j)\n",
    "            fit = tr_stacked.get_one_fit_from_trial(inj_trial, flat=False, )\n",
    "            weights = cy.pdf.StackedTemplateSpacePDFRatioModel.compute_weights(2, **fit[1])\n",
    "            return weights[1]\n",
    "\n",
    "        with Pool(n_cpus) as p:\n",
    "            weights_i = list(tqdm(p.imap(compute_trial, range(n_trials)), total=n_trials))\n",
    "        results[i, j, :] = weights_i\n",
    "        p.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for j, nsig in enumerate(n_sigs):\n",
    "    fig, ax = plt.subplots(figsize=(9, 6))\n",
    "    inj_weights_ext = np.ones_like(results[:, j]) * inj_weights[:, np.newaxis]\n",
    "\n",
    "    plot_bias(\n",
    "        ax=ax, x_fit=results[:, j].flatten(), y_true=inj_weights_ext.flatten(), \n",
    "        label=r'$n_\\mathrm{inj}$ ' + '= {}'.format(nsig),\n",
    "    )\n",
    "    ax.set_xlabel('True UNID/SNR Ratio')\n",
    "    ax.set_ylabel('Injected UNID/SNR Ratio')\n",
    "    ax.legend()\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    fig.savefig('{}/template_weight_bias_nsig_{}.png'.format(plot_dir, nsig))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "for j, nsig in enumerate(n_sigs):\n",
    "    if j % 2 == 0: continue\n",
    "    inj_weights_ext = np.ones_like(results[:, j]) * inj_weights[:, np.newaxis]\n",
    "\n",
    "    plot_bias(\n",
    "        ax=ax, x_fit=results[:, j].flatten(), y_true=inj_weights_ext.flatten(), \n",
    "        label=r'$n_\\mathrm{inj}$ ' + '= {}'.format(nsig),\n",
    "    )\n",
    "ax.set_xlabel('Injected UNID/SNR Ratio')\n",
    "ax.set_ylabel('Fitted UNID/SNR Ratio')\n",
    "ax.legend()\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "fig.savefig('{}/template_weight_bias.png'.format(plot_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-meeting",
   "metadata": {},
   "source": [
    "## Can Stacking Catalogs explain GP results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-blank",
   "metadata": {},
   "source": [
    "##### Create stacking catalog templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "nside = hp.get_nside(template_pi0_raw_)\n",
    "pix_area = hp.nside2pixarea(nside)\n",
    "\n",
    "stacking_templates_dict = {}\n",
    "for catalog in ['snr', 'pwn', 'unid']:\n",
    "    template_i = np.zeros(hp.nside2npix(nside))\n",
    "    \n",
    "    # set pixels corresponding to source locations to 1\n",
    "    for ra_deg, dec_deg in zip(cat_dict[catalog].ra_deg, cat_dict[catalog].dec_deg):\n",
    "\n",
    "        # transform to other coordinates and set to 1\n",
    "        theta = np.pi/2. - np.deg2rad(dec_deg)\n",
    "        phi = np.deg2rad(ra_deg)\n",
    "        \n",
    "        ipix = hp.ang2pix(nside=nside, theta=theta, phi=phi)\n",
    "        template_i[ipix] = 1\n",
    "        \n",
    "    # normalize\n",
    "    template_i = template_i / np.sum(template_i) / pix_area\n",
    "    \n",
    "    stacking_templates_dict[catalog] = template_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing = 7.\n",
    "for catalog in ['snr', 'pwn', 'unid']:\n",
    "    skymap_plotter = SkymapPlotter(\n",
    "        skymap=hp.smoothing(stacking_templates_dict[catalog], sigma=np.deg2rad(smoothing)), cmap='viridis', \n",
    "    )\n",
    "    skymap_plotter.ax.set_title('Catalog {} | {:2.0f}째'.format(catalog, smoothing))\n",
    "    skymap_plotter.fig.savefig('{}/catalog_{}_{:2.0f}deg.png'.format(plot_dir, catalog, smoothing))\n",
    "\n",
    "skymap_plotter = SkymapPlotter(\n",
    "    skymap=hp.smoothing(template_pi0_raw, sigma=np.deg2rad(smoothing)), cmap='viridis', \n",
    ")\n",
    "skymap_plotter.ax.set_title('$\\pi^0$ Template | {:2.0f}째'.format(smoothing))\n",
    "skymap_plotter.fig.savefig('{}/catalog_pi0_{:1.0f}deg.png'.format(plot_dir, smoothing))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-integral",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-color",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "catholic-russia",
   "metadata": {},
   "source": [
    "## Scratch Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_pdf = tr_dict['pi0'].llh_models[0].pdf_ratio_model.models[0]\n",
    "space_pdf.template / template_pi0_0deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_pdf._acc_model(space_pdf.template)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2.3_py3-v4.1.0_csky",
   "language": "python",
   "name": "tensorflow2.3_py3-v4.1.0_csky"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
